# This is a small example showing how to tweak the communication location
# to lower the communication between the host and the GPU

from pyps import *
import re

program = "jacobi"

# Just in case it existed before:
workspace.delete(program)

w = workspace([ program + ".c",
		os.path.join(os.environ["P4A_ACCEL_DIR"], "p4a_stubs.c") ],
	      name = program,
	      activates = [ "C_PARSER",
			    "TRANSFORMERS_INTER_FULL",
			    "INTERPROCEDURAL_SUMMARY_PRECONDITION",
			    "PRECONDITIONS_INTER_FULL" ],
	      verboseon=True)
w.all_functions.display(PRETTYPRINT_SEQUENTIAL_STYLE = "do")

w.set_property(ABORT_ON_USER_ERROR = True,
	       PRETTYPRINT_STATEMENT_NUMBER = True,
	       FOR_TO_DO_LOOP_IN_CONTROLIZER = True,
	       MUST_REGIONS = True,
	       #Warning: assume that there is no aliasing between IO
	       #streams ('FILE *' variables):
	       ALIASING_ACROSS_IO_STREAMS = False
	       )

#	       MUST_REGIONS = True

# Skip module name of P4A runtime:
skip_p4a_runtime_and_compilation_unit_re = re.compile("P4A_.*|.*!")
def is_not_p4a_runtime(module):
	#print module.name
	return not skip_p4a_runtime_and_compilation_unit_re.match(module.name)

mn = w.filter(is_not_p4a_runtime)

#for i in mn:
#	print i.name

mn.loop_normalize(
	# Loop normalize for the C language and GPU friendly
	LOOP_NORMALIZE_ONE_INCREMENT = True,
	LOOP_NORMALIZE_LOWER_BOUND = 0,
	# It is legal in the following by construction:
	LOOP_NORMALIZE_SKIP_INDEX_SIDE_EFFECT = True)

mn.privatize_module()

mn.display(With="PRINT_CODE_REGIONS")


# mn.localize_declaration()

# mn.display(With="PRINT_CODE_PRECONDITIONS")

mn.coarse_grain_parallelization()
# Some output:
mn.display()

# First, only generate the launchers to work on them later. They are
# generated by outlining parallel loops
mn.gpu_ify(GPU_USE_WRAPPER = False,
	   GPU_USE_KERNEL = False)
# Some output:
mn.display()

# Isolate kernels by using the fact that all the generated kernels have
# their name beginning with "p4a_":
kernel_launcher_filter_re = re.compile("p4a_kernel_launcher_.*[^!]$")
kernel_launchers = w.filter(lambda m: kernel_launcher_filter_re.match(m.name))

# Add iteration space decoration and insert iteration clamping into the
# launchers:
kernel_launchers.gpu_loop_nest_annotate()
# Some output:
kernel_launchers.display()

# Unfortunately this information is lost by the current outliner, so
# rebuid it... :-(
kernel_launchers.privatize_module()
kernel_launchers.coarse_grain_parallelization()

# End to generate the wrappers and kernel contents, but not the launchers
# that have already been generated:
kernel_launchers.gpu_ify(GPU_USE_LAUNCHER = False)

# Some output:
w.all_functions.display()
#w.compilation_units.display()

#setproperty KERNEL_LOAD_STORE_ALLOCATE_FUNCTION "P4A_ACCEL_MALLOC"
#setproperty KERNEL_LOAD_STORE_DEALLOCATE_FUNCTION "P4A_ACCEL_FREE"
#setproperty KERNEL_LOAD_STORE_LOAD_FUNCTION "P4A_COPY_TO_ACCEL"
#setproperty KERNEL_LOAD_STORE_STORE_FUNCTION "P4A_COPY_FROM_ACCEL"

#kernels.display()

# Add communication around all the call site of the kernels:
# Use a more specific communication location:
#kernel_launchers.kernel_load_store()
w["p4a_kernel_launcher_0"].kernel_load_store()
w["compute"].kernel_load_store()
kernel_launchers.display()

#kernel_launchers.gpu_loop_nest_annotate()
#kernel_launchers.display()

# Inline back the kernel into the wrapper, since CUDA can only deal with
# local functions if they are in the same file as the caller (by inlining
# them, by the way... :-) )
#kernel_filter_re = re.compile("p4a_kernel_\\d+$")
#kernels = w.filter(lambda m: kernel_filter_re.match(m.name))
# Should be no longer useful since the outliner generate now all the
# functions in the same compilation unit:
#kernels.inlining()

# Display the wrappers to see the work done:
kernel_wrapper_filter_re = re.compile("p4a_kernel_wrapper_\\d+$")
kernel_wrappers = w.filter(lambda m: kernel_wrapper_filter_re.match(m.name))
kernel_wrappers.display()

# Instead, do a global loop normalization above:
#kernels.loop_normalize()
#kernels.use_def_elimination()


#w.all.suppress_dead_code()
#w["main"].display()

w["main"].prepend_comment(PREPEND_COMMENT = "// Prepend here P4A_init_accel")

#w.all_functions.display(PRETTYPRINT_SEQUENTIAL_STYLE = "do")
#gdfgaeg
# Unsplit resulting code, without OpenMP pragma since we want to generate
# GPU code :-) :
w.all.unsplit(PRETTYPRINT_SEQUENTIAL_STYLE = "do")

# Generating P4A code:
os.system("cd " + program + ".database; $P4A_ACCEL_DIR/p4a_post_processor.py Src/*.c")
