Stars-pm is a particle-mesh N-body cosmological simulation, written by
Dominique Aubert and Mehdi Amini.


Here we present 3 different executions of the same C sequential code:

- the native one: sequential execution using the FFTW3 library for
  accelerated FFT on multiprocessors;

- automatic parallelization with p4a for parallel execution on multicores
  with OpenMP that is automatically generated by p4a combined with the
  already parallelized multithread FFTW3 library;

- automatic parallelization with p4a --cuda for parallel execution on
  nVidia GPU + multithread FFTW3 library that is already parallelized.


There is a simple Makefile used to launch the different phases.

You need to have the fftw3f library installed (the libfftw3-dev package on
Debian/Ubuntu) to be able to link the code, and optionally OpenGL and/or
GTK for visualization.

For the sequential execution

  make seq : build the sequential program from the C sources

  make run-seq : build first if needed, then run the sequential program

For the OpenMP parallel execution on multicores:

  (same as previously with -openmp instead of -seq)

For the CUDA parallel execution on nVidia GPU:

  (same as previously with -cuda instead of -seq or -openmp)


To get an output you might add opengl=1 and/or gtk=1 on cmd line, for instance
"make run-seq opengl=1".
You might also run "make clean" first to force rebuilding.


You can set the P4A_OPTIONS variable to pass some options to p4a.

  For example, globally with an:
  export P4A_OPTIONS='--nvcc-flags="-gencode arch=compute_20,code=sm_20 -DP4A_DEBUG"'
  or locally with:
  make P4A_OPTIONS='--nvcc-flags="-DP4A_DEBUG"' run_cuda


To run this example on GPU that does not support double precision, you
should compile it with make USE_FLOAT=1 or the results are just garbage
(because if nvcc has a single precision fall-back, the communication
correctly computed by Par4All are still in... double. So trouble begins...).
Of course the results are slightly different in single precision compared
to double precision anyway.
