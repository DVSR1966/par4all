\documentstyle[12pt]{article}
\input{/usr/share/local/lib/tex/macroslocales/Dimensions.tex}

\newcommand{\titre}{PROJET PIPS \\
		RAPPORT DE SYNTHESE FINALE}
\newcommand{\auteur}{
        	Franc,ois IRIGOIN \\
        	Pierre JOUVELOT \\
\vspace{0.5cm}
{\it Le pre'sent document a e'te' e'tabli en exe'cution du contrat
No.~88.017.01 passe' par la Direction des Recherches, Etudes et
Techniques (De'le'gation Ge'ne'rale pour l'Armement)}
}
\newcommand{\docdate}{De'cembre 1990}
\newcommand{\numero}{E134}

\begin{document}
\input{/usr/share/local/lib/tex/macroslocales/PageTitre.tex}

{\it Le pre'sent document a e'te' e'tabli en exe'cution du contrat
No.~88.017.01 passe' par la Direction des Recherches, Etudes et
Techniques (De'le'gation Ge'ne'rale pour l'Armement)}

\vspace{2cm}

Ce document pre'sente le rapport final de la convention DRET/ARMINES
87.017 (bon de commande 88.017.01) de'crivant la re'alisation d'un
paralle'liseur automatique et interproce'dural de programmes scientifiques.
Ce paralle'liseur a e'te' appele' PIPS\footnote{Paralle'liseur
Interproce'dural de Programmes Scientifiques}. Il prend
en entre'e des programmes Fortran 77 se'quentiel et fournit en sortie
des programmes e'quivalents dont le paralle'lisme a e'te' explicite' par
des instructions DOALL et des instructions vectorielles Fortran~90.

Le plan de ce rapport est standard. Apre`s avoir rappele' l'objet de
l'e'tude, nous en montrerons l'inte're^t. Nous en de'taillerons ensuite
le de'roulement puis en pre'senterons les re'sultats essentiels avant de
conclure et de pre'senter les perspectives ouvertes par ce travail.

\section{Objet de l'e'tude}

Cette e'tude rentre dans le cadre de'fini formellement par les deux rubriques
suivantes:
\begin{itemize}
\item
	{\em Domaine II}: Etude d'outils logiciels de programmation et
d'exploitation des calculateurs scientifiques.
\item
	{\em The`me II.1}: Adaptation automatique de programmes
scientifiques aux calculateurs paralle`les.
\end{itemize}
Plus pre'cisement, son objectif a` long terme est d'e'tudier le
potentiel des analyses interproce'durales pour l'optimisation de la
compilation de programmes Fortran. Deux types d'analyses sont effectue'es,
une analyse se'mantique permettant, entre autres, de propager des
constantes interproce'duralement, et une analyse du paralle'lisme
implicite.

Pour ce faire, un paralle'liseur source a` source Fortran a e'te'
re'alise'.  Il est comple'te' par une bibliothe`que de transformations
de base (distribution de boucle, privatisation, e'change de boucles) et
par les phases d'analyses interproce'durales.

\section{Inte're^t de l'e'tude}

Le domaine de la recherche des outils de programmation des calculateurs
scientifiques du type {\em supercalculateur} connai^t un de'veloppement
croissant depuis l'arrive'e des machines vectorielles du type CRAY-1
dans le milieu des anne'es 70. Ces superordinateurs, et leur
programmation efficace, sont une des clefs de la mai^trise technologique
de nombreux secteurs vitaux pour la De'fense Nationale, que cela soit
dans le domaine de la simulation de processus physiques (e.g., e'tude
des e'coulements fluides ou analyse de structures) ou de nouveaux
produits (e.g., conception et validation de circuits inte'gre's).

L'inte're^t strate'gique de ce type d'architectures, la difficulte'
intrinse`que de leur programmation et les proble`mes que posent la
de'tection et l'exploitation efficace du paralle'lisme, qui est
indispensable pour obtenir les performances attendues de ces
machines, justifient les recherches en cours visant a` faciliter leur
utilisation.

En particulier, le de'veloppement d'outils sophistique's d'aide a` la
programmation, qu'ils soient purement automatiques ou interactifs,
s'ave`re e^tre un point de passage oblige' pour mai^triser le cou^t et
faciliter la conception de logiciels qui tirent parti des
caracte'ristiques architecturales de ces machines comportant
plusieurs processeurs
vectoriels, avec une me'moire hie'rarchique, globale ou partage'e.

\subsection{Objectifs de la recherche}

Les superordinateurs apparaissant sur le marche' offrent des facilite's
d'exe'cution paralle`le qui s'e'loignent du mode vectoriel (dit SIMD)
pre'sent sur les machines de la classe du CRAY-1, mode dont
l'exploitation automatique par compilateur, dit {\em vectorisation}, est
relativement bien mai^trise' maintenant. 

Les architectures les plus re'centes offrent aussi la possibilite'
d'exe'cuter des ta^ches diffe'rentes sur des processeurs multiples; ces
multiprocesseurs permettent ainsi des exe'cutions de type MIMD dont la
ge'ne'ration automatique est plus difficile a` mettre en place. En
effet, les overheads associe's au paralle'lisme MIMD sont ge'ne'ralement
plus importants que ceux qui sont associe's aux instructions
vectorielles. Il faut donc rechercher du paralle'lisme de grain moins fin
et donc tester un nombre beaucoup plus important de de'pendances.

Les objectifs principaux de la recherche effectue'e dans le cadre de
ce contrat sont multiples:
\begin{itemize}
\item
	Etudier et concevoir un compilateur effectuant la {\em
paralle'lisation} des programmes et non plus leur simple vectorisation,
\item
	Etudier la faisabilite' d'une paralle'lisation de grain
grossier, au niveau des proce'dures utilise'es dans les langages
scientifiques, 
\item
	Etudier l'importance des analyses se'mantiques sophistique'es
qui seront la clef des compilateurs a` venir.
\end{itemize}
Mais ils visent tous l'obtention automatique de paralle'lisme de
grain moyen ou fin.

Les retombe'es secondaires sont aussi importantes, qu'il s'agisse
de profiter de l'analyse se'mantique interproce'durale pour ame'liorer
le choix des transformations ou de mettre les re'sultats des analyses
automatiques a` la disposition des programmeurs pour qu'ils puissent
comprendre pourquoi les sections de code qu'ils croyaient paralle`les
ne sont pas reconnues telles par le compilateur. Par exemple,
la propagation interproce'durale de constante permet de mieux choisir
les boucles vectorielles et paralle`les en fonction des nombres d'ite'rations
des boucles. Le calcul automatique des effets des proce'dures sur la me'moire
et leur affichage permettent de voir rapidement quels COMMONs et quelles
variables sont modifie's par une proce'dure et par toutes celles qu'elle
appelle directement ou indirectement.

\subsection{Historique des e'tudes ante'rieures}

Les acteurs principaux sur ce terrain sont ame'ricains, ainsi que les
machines cibles. Apre`s les travaux de pionniers
de David Kuck a` l'Universite' d'Urbana-Champaign (Illinois), travaux
qui ont commence' avec le projet ILLIAC~IV, qui ont conduit au
de'veloppement du premier vectoriseur de recherche (Projet Parafrase) et
qui ont abouti a` la cre'ation du CSRD (Center for Supercomputing
Research and Development), les groupes de Ken Kennedy a` l'Universite'
de Rice (Texas) et de Michael Burke a` IBM Yorktown Heights (New York)
ont poursuivi et de'veloppe' cet axe de recherche avec toute une famille
de projets a` Rice, allant du vectoriseur/paralle'liseur PFC (Parallel
Fortran Compiler) a` l'environnement de programmation paralle`le $R^N$
et un grand projet a` Yorktown Heights, PTRAN (Parallel Translator).

Ce domaine a donne' lieu a` la cre'ation de startups comme Pacific
Sierra ou Kuck Associates, Inc. qui commercialisent, depuis le de'but
des anne'es 80, des compilateurs pour machines vectorielles. Il s'agit
le plus souvent de pre'-compilateurs ou me^me de compilateurs source a` source
effectuant la de'tection du paralle'lisme et son explicitation a` l'aide
de directives propres au constructeur de la machine cible. Pacific Sierra
fournit actuellement le paralle'liseur de Cray Research.

Les techniques mises au point dans ces centres ont, par ailleurs, e'te'
utilise'es abondamment dans les compilateurs de'veloppe's en interne
par des socie'te's comme Alliant ou Convex.

Ayant perc,u l'importance strate'gique de ce domaine, la DRET a lance' un
certain nombre de projets de recherche pour y soutenir la recherche
francaise. De`s les anne'es 70, le projet VESTA, de'veloppe' au sein du
Centre de Recherches de CII-Honeywell Bull avec la collaboration du
Pr.~Feautrier, pre'voit la conception d'un compilateur vectoriseur pour
Fortran. Ecrit en PL1, ce prototype n'a pas connu de suites imme'diates,
en partie du fait de l'absence de machines cibles franc,aises.

Plus re'cemment, le projet VATIL, de'veloppe' a` l'INRIA par l'e'quipe
du Pr.~Lichnewsky, a poursuivi dans cette voie de recherche par la
re'alisation d'un vectoriseur e'crit en Le-Lisp. Ce vectoriseur a e'te'
progressivement enrichi et transforme' en un paralle'liseur.

\subsection{Re'sultats acquis ante'rieurement}

L'essentiel des travaux effectue's pre'ce'demment dans le domaine de la
compilation pour superordinateurs e'tait axe' vers la vectorisation des
applications scientifiques. Les re'sultats primordiaux concernaient la
cre'ation de graphes de de'pendances aussi pre'cis que possible entre
instructions en vue de de'tecter celles qui sont vectorisables. 

La notion me^me de vectorisation e'tait incompatible avec le traitement
des appels de proce'dure puisqu'un call vectoriel n'a pas grand sens.
Les travaux en matie`re d'interproce'duralite' ont donc commence' au
de'but des anne'es 1980 en utilisant l'expansion de proce'dure et
les calculs d'effets {\em atomiques}: la modification d'un e'le'ment
de tableau est conside're'e comme une modification du tableau complet.

Les premiers re'sultats plus pre'cis ont e'te' de'crits dans la the`se
de Re'mi Triolet (1984) et ce sont eux qui sont a` l'origine du projet.
Depuis, plusieurs autres me'thodes ont e'te' pre'sente'es, dont beaucoup
sont des variations base'es sur la me'thode de Re'mi Triolet. Ces variations
consistent en des compromis varie's entre la pre'cision et la vitesse
d'analyse. La plupart de ces me'thodes n'ont pas e'te' comple`tement
imple'mente'es et aucune comparaison valable n'a encore pu e^tre effectue'e.

La gestion des boucles imbrique'es, base'e sur les notions d'e'change de
boucles et de partitionnement, n'a pas encore e'te' e'tudie'e de
manie`re approfondie. Seules des transformations e'le'mentaires ont e'te'
propose'es mais leur enchai^nement reste proble'matique. Des me'thodes
plus globales ont e'te' de'veloppe'es par Francois Irigoin en 1988, puis
inde'pendamment par une e'quipe de Stanford (Monica Lam) et chez Intel
par Uptal Banerjee.

Ces me'thodes n'ont pas semble' apporter grand-chose dans le domaine de
de la paralle'lisation interproce'durale.  Elles devront ne'anmoins
e^tre prise en compte pour obtenir de bons re'sultats pour une machine
cible particulie`re.

\section{De'roulement de l'e'tude}

Le projet PIPS (Paralle'liseur Interproce'dural de Programmes
Scientifiques) s'est de'roule' sur 2 ans. Un certain laps de temps a
tout d'abord e'te' ne'cessaire pour de'finir de manie`re tre`s pre'cise
les objectifs et pour obtenir la livraison des machines ne'cessaires au
projet.  Etant donne'es les inconnues qui frappaient les machines cibles
potentielles de l'e'poque (Marie, Isis, Marisis), il a e'te' convenu
de`s le de'part de ne pas cibler PIPS pour une machine particulie`re,
mais de le conside'rer comme un paralle'liseur ge'ne'rique, transformant
un source Fortran-77 en une version optimise'e, e'crite en un Fortran-77
e'tendu permettant de spe'cifier le paralle'lisme de'tecte'. Ce
paralle'liseur contient aussi une bibliothe'que de transformations qui
ne sont pas syste'matiquement applique'es puisqu'en l'absence de machine
cible aucune fonction de cou^t ne permet d'en de'terminer
l'opportunite'.

Une collaboration entre l'Ecole des Mines et l'ONERA a e'te' instaure'e
pour de'finir les constructions Fortran-77 qui pourraient ne pas e^tre
traite'es en vue de diminuer le volume de code ne'cessaire a` la
re'alisation de PIPS. Ces restrictions,
de'crites dans le rapport CAII-E103, ne concernent que les ENTRY,
les BLOCK DATA, les GOTO calcule's et assigne's, les RETURN calcule's,
les INQUIRE et les acce`s aux sous-chai^nes de caracte`res.
Elles ne devaient pas imposer des
contraintes trop se've`res sur les types de benchmarks susceptibles
d'e^tre traite's par PIPS. Il s'est ave're' que les programmes de
benchmark de l'ONERA e'taient analyse's par PIPS sans modification
pre'alable une
fois accepte' l'ajout des ordres non standards BUFFERIN et BUFFFEROUT.

Outre les diffe'rents lots de'crits dans la section suivante, une
pre'sentation et une premie`re de'monstration de PIPS ont e'te'
effectue'es en Avril 1990, en pre'sence de membres de l'Ecole des Mines,
de la DRET, de l'INRIA, de l'Universite' Pierre et Marie Curie et du CEA
(l'ONERA e'tant excuse'). Une autre re'union de point a eu lieu en
juillet 90. 

Ces deux re'unions ont permis de mettre en e'vidence l'inade'quation de
la structure initiale du projet. Le fonctionnement purement {\em batch}
qui e'tait pre'vu s'est re've'le' largement incompatible avec les
analyses interproce'durales qui conduisent tre`s naturellement a` faire
intervenir l'utilisateur dans le processus de paralle'lisation.
De plus, pour des raisons de temps de re'ponse, le fonctionnement
interactif impose un mode de travail
incre'mental dans lequel seuls les effets induits par les modules
modifie's sont recalcule's.
Les modifications conside'rables qu'a entrai^ne' cet ajustement de
l'objectif ont engendre' un certain retard. Le surcroi^t
de travail n'a cependant pas e'te' impute' a` la DRET malgre' l'inte're^t
e'vident de l'ope'ration pour l'exploitation du projet PIPS par d'autres
e'quipes de'pendant largement de la De'fense (CEA, ONERA) ou de la
recherche franc,aise (IRISA, Universite' Pierre et Marie Curie).

En outre, une autre pre'sentation a e'te' organise'e au cours du
workshop {\em International Workshop on Compilers for Parallel
Computers} mis en place par l'Ecole des Mines et l'Universite' Pierre et
Marie Curie auxquels ont assiste' des repre'sentants des e'quipes PTRAN
de IBM Yorktown Heights, du CSRD, de Cray France et du groupe de
compilation de Cray Research.  Deux de'monstrations du syste`me ont
ensuite e'te' organise'es a` Fontainebleau pour les chercheurs de Cray
Research et d'IBM et ont donne' lieu a` des e'changes de vues informels
sur l'avenir des analyses interproce'durales.

\subsection{Rappel des diffe'rentes e'tapes}

Les e'tapes marquantes du projet PIPS sont de'crites rapidement dans
cette section. Outre les rapports d'avancement et les rapports finals,
certaines dates clefs sont e'voque'es.

\begin{description}
\item[Fortran - Mars 1988]
	Au vu des programmes fournis par l'ONERA (AILE, CR2CNF, OA118 et
TMINES), une de'finition pre'cise du sous-Fortran utilise' par PIPS est
e'labore'e. Il s'ave`re que la majeure partie des instructions et
de'clarations Fortran peut e^tre utilise'e telle quelle. Par ailleurs,
on explique comment un certain nombre de constructions plus rares (par
exemple les GOTO assigne's) peuvent e^tre, de manie`re
quasi-automatique, transforme'es dans PIPS Fortran. Ceci est de'crit
dans le
document CAII-E103 et son annexe pre'sentant les {\em syntax charts} de
Fortran modifie's.
\item[Rapport d'Avancement 1 - Mars 1988]
	Le Lot 1 de'crit la structure ge'ne'rale de l'ana\-lyseur lexical
de PIPS, complexe du fait du caracte`re peu orthogonal de la syntaxe de
Fortran. Une pre'sentation rapide de l'outil de ge'nie logiciel NewGen,
utilise' intensivement dans PIPS et de'veloppe' en interne a` l'Ecole
des Mines, ainsi que de l'e'bauche de la Repre'sentation Interme'diaire
(RI) de PIPS est effectue'e avant d'aborder la description des analyses
syntaxiques et se'mantiques.
\item[Rapport d'Avancement 2 - De'cembre 1988]
	Une pre'sentation de'taille'e de NewGen est donne'e avant une
de'finition exhaustive de la RI de PIPS. Est pre'cise'e, en particulier,
la manie`re dont la syntaxe Fortran est de'crite par les structures
NewGen de la RI. La RI n'evoluera que de manie`re marginale au cours de
la vie du projet PIPS. Enfin, une description succinte des structures de
donne'es utilise'es dans la phase d'analyse se'mantique est donne'e.
\item[Rapport d'Avancement 3 - Mars 1989]
	L'essentiel de ce rapport d'avancement est de pre'ciser l'e'tat
de l'imple'mentation du frontal de PIPS, base' sur les de'finitions
donne'es dans les rapports pre'ce'dents. En ce qui concerne les phases
d'analyse, les proble`mes the'oriques a` aborder, ainsi que ceux,
pratiques, d'interface avec NewGen sont de've\-loppe's.
\item[Rapport Final ``Analyse Lexicale/Syntaxique Intra'' - Mai 1989]
	Ce gros rapport\\
contient l'ensemble du code repre'sentant le
frontal intraproce'dural de PIPS, avec une description comple`te de la
RI. Par l'utilisation d'une RI tre`s simple et orthogonale (utilisation
maximale de la notion de fonction dans la repre'sentation des structures
de Fortran), le volume de programmes e'crit a e'te' limite' par rapport
a` une approche plus classique.
\item[Rapport Final ``Analyse Syntaxique Inter'' - Mai 1989]
	Ce lot de'crit la phase d'e'di\-tion de liens permettant de
terminer l'analyse syntaxique d'un programme Fortran (ce rapport inclut
le listing du programme). A noter que ce module a e'te' prototype' une
premie`re fois en CommonLISP (listing non fourni), profitant ainsi des
possibilite's de NewGen, avant d'e^tre re'crit, dans sa version
de'finitive, en C.
\item[Rapport d'avancement 4 - Septembre 1989]
	Ce rapport interme'diaire de'crit et donne le listing du
constructeur de graphe de contro^le structure' utilise' dans PIPS. Cette
structure de donne'es nouvelle permet de repre'senter de manie`re
hie'rarchique un programme pouvant contenir des branchements, permettant
ainsi de localiser finement les parties non-paralle'lisables (du fait de
leur non-structuration). En ce qui concerne l'analyse se'mantique, les
modifications apporte'es a` l'algorithme d'Halbwachs sont de'crites,
essentiellement pour prendre en compte l'aliasing et ame'liorer les
performances. 
\item[Rapport d'Avancement 5 - De'cembre 1989]
	Y sont de'crites les phases d'analyse se'\-mantique et de
de'tection de paralle'lisme. De manie`re plus pre'cise, les additions a`
la RI ne'cessaires pour prendre en compte l'analyse se'mantique sont
pre'sente'es (via la notion de {\em transformer}). La construction du
graphe {\em use-def} est de'crite, ainsi que son utilisation pour la
privatisation de variables locales (les impacts sur l'algorithme de
paralle'lisation d'Allen et Kennedy sont pre'sente's). 
\item[Rapport d'Avancement 6 - Mars 1990]
	L'essentiel de ce lot concerne la paralle'lisation
interproce'durale. Sa puissance peut e^tre bien perc,ue par un exemple
d'utilisation de la routine SAXPY extraite de la librairie BLAS; cet
exemple, traite' par PIPS, est pre'sente' dans le rapport.
\item[Pre'sentation - 24 Avril 1990]
	L'e'quipe PIPS a organise' une pre'sentation du projet a`
diverses personnalite's de la DRET (Ph. Sarazin), du CEA (G. Meurant), de
l'INRIA (W. Jalby) et de Paris 6 (P. Feautrier). Une de'monstration en
temps-re'el du paralle'liseur avait e'te' pre'pare'e, en utilisant les
programmes de tests de l'ONERA (P. Leca, excuse'). Cette journe'e a e'te'
un succe`s, de nombreux participants exprimant leur inte're^t dans le
projet et souhaitant obtenir une version de PIPS, une fois celui-ci
termine'. 
\item[Pre'sentation - Mai 1990]
	Une seconde e'dition de la pre'sentation du 24 Avril a e'te'
organise'e au cours du mois de Mai pour Cray France. Toujours a` la
recherche des derniers de'veloppements concernant la paralle'lisation
d'applications, Cray a montre' son inte're^t pour le projet PIPS. En
particulier, nous avons pu tester le re'sultat du pre'processeur du Cray
sur les benchmarks utilise's par PIPS (voir ci-dessous). A noter que le
Cray YMP est une des machines envisage'es comme cibles de PIPS. Le
pre'processeur de Cray Research est d'origine Pacific Sierra. Il
de'tecte le paralle'lisme et l'exprime a` l'aide de directives
compatibles avec le compilateur Cray qui ge'ne`re le code vectoriel et
optimise aussi le code scalaire.
\item[Rapport d'Avancement 7 - Juin 1990]
	Ce rapport pre'sente les dernie`res modifications de PIPS,
essentiellement pour des proble`mes de performances (diminution de la
taille du graphe de de'pendances).
\item[Workshop - 3 au 5 De'cembre 1990]
	L'Ecole des Mines et l'Universite' Paris 6 ont organise' en
commun l'{\em International Workshop on Compilers for Parallel
Computers} a` Paris. De nombreux chercheurs internationaux (Europe et
USA essentiellement) y ont participe'. On notera en particulier des
repre'sentants de IBM Yorktown Heights (Michael Burke, Jeanne Ferrante,
Larry Carter), du CSRD de l'Universite' d'Illinois (Luddy Harrison) et
de Cray Research US (Irene Qualters). Outre une pre'sentation en
confe'rence du projet PIPS par Franc,ois Irigoin, deux de'monstrations
du paralle'liseur ont e'te' organise'es pour l'e'quipe PTRAN d'IBM et la
responsable De'velop\-pement Logiciel de Cray US; ces deux pre'sentations
ont e'te' appre'cie'es. La pre'sence des repre'sentants de Cray US
donnait suite a` la rencontre pre'ce'dente avec Cray France; des
collaborations ulte'rieures sont possibles sur ce sujet prometteur.
\end{description}

Une lettre envoye'e par Michel Lenci (re'fe'rence 5020/ML du 27
Septembre 1990) e'voque les raisons du retard de quelques mois pris par
le projet PIPS, essentiellement pour la raison du de'veloppement, non
pre'vu par le contrat DRET mais ne'cessaire vu l'e'volution des
environnements de programmation, d'une interface interactive sous X
Window ayant entrai^ne' une remise en cause de la structure globale de
PIPS. Ceci est de'crit dans le rapport CAII-E133 remis a` la DRET.  De
plus, un des membres de l'e'quipe, Re'mi Triolet, a de'cide' de prendre
une anne'e sabbatique, ce qui n'a fait que confirmer ce retard de quatre
mois, retard accepte' par la DRET par lettre en date du 24 novembre 1990.

\subsection{Difficulte's, faits significatifs et re'sultats}

L'essentiel du project PIPS s'est de'roule' selon l'e'che'ancier
caracte'ristique des projets de recherche, c'est-a`-dire pour lesquels
une approche de prototypage est pre'fe're'e a` un sche'ma classique du
type {\em waterfall} avec des phases se'pare'es de spe'cification,
de'veloppement et test. Cette approche s'est re've'le'e facilite'e par
l'utilisation du logiciel NewGen, qui permet une e'volution en douceur
des structures de donne'es centrales.

La repre'sentation interme'diaire de PIPS a e'te' con\c{c}ue de manie`re
extre^mement soigne'e de`s le de'part. Elle n'a e'te' significativement
modifie'e qu'au cours de l'anne'e 1990 pour permettre de faire cohabiter
les approches oriente'es batch (objet du contrat) et interactive
(souhaite'e par les utilisateurs et ne'cessaire vu l'e'volution des
environnements de programmation paralle`le). Cette remise a` jour avait
pour principal objectif de permettre un meilleur de'couplage des
diffe'rentes phases de PIPS, pour en faciliter l'utilisation ``a` la
carte{}''. Ceci e'tait e'galement utile pour permettre des
de'veloppements paralle`les sur PIPS, comme de nouvelles phases
d'analyse ou de transformations.

Les avantages e'voque's pre'ce'demment se voient ne'anmoins entache's
d'un inconve'nient qu'il convient de noter. La version interactive de
PIPS utilise le partage de structures de donne'es en me'moire et ne
passe donc plus, comme la version batch, par des fichiers externes. Il
s'ensuit qu'un soin particulier doit e^tre apporte' a` la gestion de la
me'moire (le langage d'imple'mentation, C, n'offrant pas de {\em garbage
collector}), induisant des risques supple'mentaires d'erreur et
alourdissant la ta^che de programmation et de mise au point.

Un autre aspect du projet a e'te' l'insistance sur des performances
raisonnables. Cela a exclu l'utilisation de langages de programmation
plus conviviaux comme Lisp (quoique NewGen permette, d'une certaine
manie`re, de les concilier avec l'objectif d'efficacite') au profit de
C. Les performances obtenues, uniques dans ce domaine en France, ont
requis un cou^t de programmation plus important qu'il est habituel dans
ce type de projet.

\section{Re'capitulation des re'sultats}

Le paralle'liseur PIPS a tenu ses promesses. 

Des programmes re'els, tel que le programme TMINES de l'ONERA de calcul
d'e'coulement potentiel dans une tuye`re et comportant plus de 1000
lignes de code Fortran, ont e'te' analyse's avec succe`s en utilisant
une variante de l'algorithme de paralle'lisation d'Allen et Kennedy. Le
code ge'ne're' s'est montre' aussi bon que celui produit par FPP, le
pre'processeur paralle'liseur de Cray. L'utilisation de l'analyse
se'mantique interproce'durale sur TMINES ne permet pas de de'tecter plus
de paralle'lisme qu'une analyse locale. Par contre, elle devrait
permettre de mieux calibrer la phase de ge'ne'ration de code, la
propagation des constantes interproce'durale permettant de mieux
connai^tre les bornes supe'rieures des boucles et donc de de'cider a`
meilleur escient quelles boucles doivent e^tre paralle`les ou
vectorielles. Bien e'videmment, FPP n'est pas capable de paralle'liser
des programmes ne'cessitant des propagations interproce'durales
d'informations qui sont effectue'es par PIPS.

Cette exe'cution sur des codes re'e'ls se fait, de plus, avec des
performances acceptables; ainsi TMINES est paralle'lise' en un peu plus
de dix minutes, sachant que la somme d'informations glane'es sur le
comportement dynamique du programme n'a pas d'e'quivalent dans
l'ensemble des paralle'liseurs existants, que cela soit dans les milieux
industriels ou de recherche. Ces informations pourront e^tre d'un
inte're^t majeur pour les phases de ge'ne'ration de code qui passeraient
derrie`re PIPS.

La re'alisation de PIPS a permis un test en vrai grandeur de la
bibliothe`que mathe'matique de calcul en nombre entiers de'veloppe'e a`
l'Ecole des Mines, en collaboration avec le projet $C^3$. Ces routines
sont au coeur des algorithmes de de'cision utilise's par PIPS pour la
construction du graphe de de'pendances. Ces tests de de'pendance
utilisent les informations interproce'durales propage'es par l'analyse
se'mantique.

\section{Conclusion}

Malgre' un retard de quelques mois, essentiellement du^ a` un enrichissement
du cahier des charges, le projet PIPS a abouti aux re'sultats
escompte's. Des programmes re'els ont e'te' paralle'lise's (ce qui est
une premie`re en France) et des techniques sophistique'es d'analyse
statique de programmes, pre'sente'es auparavant dans des congre`s
internationaux, ont e'te' imple'mente'es et sont ainsi a` la disposition
du monde scientifique franc,ais (le CEA ayant, par exemple, montre' son
inte're^t pour une re'utilisation de PIPS). La collaboration entre
l'Ecole des Mines et l'Universite' Pierre et Marie Curie a e'te'
renforce'e, comme le montre l'organisation conjointe d'un workshop
international sur les compilateurs pour machines paralle`les a` Paris. 

\section{Perspectives ulte'rieures}

PIPS apparai^t comme une plateforme puissante pour le de'veloppement
d'environnement de programmation paralle`le. Par la richesse des
informations recueillies par l'analyseur se'mantique interproce'durale
et la structure modulaire du paralle'liseur lui-me^me au niveau de son
imple'mentation, l'addition de modules annexes devrait e^tre
particulie`rement aise'e. Ainsi, une interface utilisateur interactive
graphique est un {\em must}, un prototype sous X Window System ayant
e'te' de'veloppe' a` cet effet pour les besoins propres de l'Ecole des
Mines.  Il serait souhaitable de de'velopper cet aspect, re'pondant
ainsi a` un besoin des utilisateurs qui demandent une facilite' plus
importante d'intervention interactive dans le processus de
paralle'lisation.

En aval de cet axe de recherche, PIPS e'tant un paralle'liseur
source/source, une phase de ge'ne'ration de code pour une machine-cible
donne'e semble e^tre du plus haut inte're^t. Suite aux contacts avec
diffe'rentes utilisateurs (ONERA, CEA) et constructeurs (Cray France et
US), la machine la plus ge'ne'ralement e'voque'e, en l'absence de
candidats franc,ais, est le Cray YMP.

\end{document}
