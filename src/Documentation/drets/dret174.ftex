\documentstyle[12pt]{article}
\input{/usr/share/local/lib/tex/macroslocales/Dimensions.tex}

\newcommand{\titre}{PROJET PIPS-2 \\
		RAPPORT DE SYNTHESE FINALE}
\newcommand{\auteur}{
		Corinne ANCOURT \\
        	Franc,ois IRIGOIN \\
        	Pierre JOUVELOT \\
\vspace{0.5cm}
{\it Le pre'sent document a e'te' e'tabli en exe'cution du contrat
No.~87.017, reconduction 1991, passe' par la Direction des Recherches, Etudes et
Techniques (De'le'gation Ge'ne'rale pour l'Armement)}
}
\newcommand{\docdate}{Avril 1993}
\newcommand{\numero}{E174}

\begin{document}
\input{/usr/share/local/lib/tex/macroslocales/PageTitre.tex}

{\it Le pre'sent document a e'te' e'tabli en exe'cution du contrat
No.~87.017.01, reconduction 1991, passe' par la Direction des Recherches, Etudes et
Techniques (De'le'gation Ge'ne'rale pour l'Armement)}

\vspace{2cm}

Ce document pre'sente le rapport final de la convention DRET/ARMINES
87.017 (bon de commande 87.017.01.018, reconduction 1991) de'crivant l'adaptation du
paralle'liseur automatique et interproce'dural de programmes
scientifiques (PIPS) aux superordinateurs vectoriels a` me'moire
partage'e dont les machines Cray sont de bons repre'sentants.

Le paralle'liseur PIPS\footnote{Paralle'liseur
Interproce'dural de Programmes Scientifiques} qui a e'te'
essentiellement de'veloppe' avec le soutien de la DRET prend
en entre'e des programmes Fortran 77 se'quentiel et fournit en sortie
des programmes e'quivalents dont le paralle'lisme est explicite' par
des instructions DOALL et/ou des instructions vectorielles Fortran~90.

De nombreuses phases lui ont e'te' ajoute'es afin de passer d'une simple
mise en e'vidence du paralle'lisme implicite a` une exploitation
optimale de ce paralle'lisme pour une machine particulie`re. La phase la
plus remarquable est la ge'ne'ration de code compatible avec le
compilateur Fortran de Cray. Ceci permet d'effectuer une e'tude
expe'rimentale des apports de PIPS par rapport a` un produit commercial
comme le pre'processeur de Pacific Sierra, FPP.

Le plan de ce rapport est standard. Apre`s avoir rappele' l'objet de
l'e'tude, nous en montrerons l'inte're^t. Nous en de'taillerons ensuite
le de'roulement puis en pre'senterons les re'sultats essentiels avant de
conclure et de pre'senter les perspectives ouvertes par ce travail.

\section{Objet de l'e'tude}

Cette e'tude rentre dans le cadre de'fini formellement par les deux rubriques
suivantes:
\begin{itemize}
\item
	{\em Domaine II}: Etude d'outils logiciels de programmation et
d'exploitation des calculateurs scientifiques.
\item
	{\em The`me II.1}: Adaptation automatique de programmes
scientifiques aux calculateurs paralle`les.
\end{itemize}
Plus pre'cisement, son objectif est de permettre une e'valuation et,
e'ventuellement, une exploitation des avance'es effectue'es en matie`re
de paralle'lisation automatique de Fortran lors du pre'ce'dent contrat
dans le domaine des analyses interproce'durales. Deux types d'analyses
sont effectue'es: une analyse se'mantique permettant, entre autres, de
propager des constantes interproce'duralement, et une analyse du
paralle'lisme implicite. Une phase d'exploitation du paralle'lisme pour
machine Cray termine le processus de paralle'lisation.

Pour ce faire, le paralle'liseur source a` source Fortran initial s'est
vu ajoute' une phase de ge'ne'ration de code Fortran Cray incluant des
primitives de micro-tasking.  Plusieurs transformations de programme qui
n'avaient pas e'te' se'lectionne'es lors de la phase initiale parce
qu'elles ne permettaient pas d'augmenter le paralle'lisme implicite ont
e'te' imple'mente'es pour en permettre une meilleur exploitation
(e'valuation partielle, de'roulage de boucles,...). Les phases d'analyse
(analyses lexicale et syntaxique, pre'dicats, re'gions, test de
de'pendance) ont e'te' ame'liore'es  au fur et a` mesure que des
proble`mes sont apparus. Enfin, des transformations de'ja`
imple'mente'es comme l'e'change de boucle ou la me'thode hyperplane ont
e'te' mieux inte'gre'es au prototype, tandis que l'importance pratique
de la de'tection des re'ductions nous ont conduit a` en re'aliser une
premie`re version prototype en Common LISP.

\section{Inte're^t de l'e'tude}

Le domaine de la recherche des outils de programmation des calculateurs
scientifiques du type {\em supercalculateur} connai^t un de'veloppement
croissant depuis l'arrive'e des machines vectorielles du type CRAY-1
dans le milieu des anne'es 70. Ces superordinateurs, et leur
programmation efficace, sont une des clefs de la mai^trise technologique
de nombreux secteurs vitaux pour la De'fense Nationale, que cela soit
dans le domaine de la simulation de processus physiques (e.g., e'tude
des e'coulements fluides ou analyse de structures) ou de nouveaux
produits (e.g., conception et validation de circuits inte'gre's).

L'inte're^t strate'gique de ce type d'architectures, la difficulte'
intrinse`que de leur programmation et les proble`mes que posent la
de'tection et l'exploitation efficace du paralle'lisme, qui est
indispensable pour obtenir les performances attendues de ces
machines, justifient les recherches en cours visant a` faciliter leur
utilisation.

En particulier, le de'veloppement d'outils sophistique's d'aide a` la
programmation, qu'ils soient purement automatiques ou interactifs,
s'ave`re e^tre un point de passage oblige' pour mai^triser le cou^t et
faciliter la conception de logiciels qui tirent parti des
caracte'ristiques architecturales de ces machines comportant
plusieurs processeurs
vectoriels, avec une me'moire hie'rarchique, globale ou partage'e.

\subsection{Objectifs de la recherche}

Les superordinateurs apparaissant sur le marche' offrent des facilite's
d'exe'cution paralle`le qui s'e'loignent du mode vectoriel (dit SIMD)
pre'sent sur les machines de la classe du CRAY-1, mode dont
l'exploitation automatique par compilateur, dit {\em vectorisation}, est
relativement bien mai^trise' maintenant. 

Les architectures les plus re'centes offrent aussi la possibilite'
d'exe'cuter des ta^ches diffe'rentes sur des processeurs multiples; ces
multiprocesseurs permettent ainsi des exe'cu\-tions de type MIMD dont la
ge'ne'ration automatique est plus difficile a` mettre en place. En
effet, les overheads associe's au paralle'lisme MIMD sont ge'ne'ralement
plus importants que ceux qui sont associe's aux instructions
vectorielles. Il faut donc rechercher du paralle'lisme de grain moins fin
et donc tester un nombre beaucoup plus important de de'pendances.

Les objectifs principaux de la recherche effectue'e dans le cadre de
ce contrat sont multiples:
\begin{itemize}
\item
	Etudier et concevoir un compilateur effectuant la {\em
paralle'lisation} efficace des programmes et non plus la simple mise en
e'vidence de paralle'lisme implicite,
\item
	Etudier l'inte're^t d'une paralle'lisation de grain
grossier, au niveau des proce'dures utilise'es dans les langages
scientifiques, 
\item
	Etudier l'impact des analyses interproce'durales
qui semblent devoir s'imposer dans les compilateurs/optimiseurs de demain.
\end{itemize}
Ils visent tous a` e'valuer la qualite' de l'exploitation qui peut e^tre
faite automatiquement du paralle'lisme de grain moyen ou fin pre'sent
dans les programmes scientifiques.

Les retombe'es secondaires sont aussi importantes, qu'il s'agisse des
environnements de programmation paralle`les ou de la compilation pour
machines massivement paralle`le a` me'moire re'partie. Dans le premier
cas, les re'sultats des analyses interproce'durales effectue'es par PIPS
peuvent e^tre fournis interactivement a` l'utilisateur afin de guider
et/ou de valider ses choix de programmation ou de transformations de
programme. Dans le deuxie`me cas, PIPS constitue une plate-forme ide'ale
de prototype de compilateur, qui dispose de toutes les informations
ne'cessaires a` la ge'ne'ration de code re'parti et qui peut-e^tre
relativement facilement comple'te' pour ge'ne'rer automatiquement les
transferts de donne'es indispensables pour ce type d'architecture.

\subsection{Historique des e'tudes ante'rieures}

Les acteurs principaux sur ce terrain sont ame'ricains, ainsi que les
machines cibles. Apre`s les travaux de pionniers
de David Kuck a` l'Universite' d'Urbana-Champaign (Illinois), travaux
qui ont commence' avec le projet ILLIAC~IV, qui ont conduit au
de'veloppement du premier vectoriseur de recherche (Projet Parafrase) et
qui ont abouti a` la cre'ation du CSRD (Center for Supercomputing
Research and Development), les groupes de Ken Kennedy a` l'Universite'
de Rice (Texas) et de Michael Burke a` IBM Yorktown Heights (New York)
ont poursuivi et de'veloppe' cet axe de recherche avec toute une famille
de projets a` Rice, allant du vectoriseur/paralle'liseur PFC (Parallel
Fortran Compiler) a` l'environnement de programmation paralle`le $R^N$
et un grand projet a` Yorktown Heights, PTRAN (Parallel Translator).

Les de'veloppements les plus re'cents ont e'te' effectue's dans le
domaine de l'e'valuation de la paralle'lisation automatique (PTRAN), des
environnements de programmation (projet PFC a` Rice), et de la
compilation pour machines a` me'moire re'partie (projet SUPERB,
universite' de Bonn puis de Vienne, projet Fortran~D, universite's de
Rice et Syracuse associe'es au Caltech). De nouvelles e'quipes ont aussi
aborde' ce domaine, comme le groupe de John Hennessy a` Stanford (projet
SUIF) ou comme le LIP (Ecole Normale de Lyon).

Ce domaine a permis le de'veloppement de petites socie'te's comme
Pacific Sierra ou Kuck Associates, Inc. qui commercialisent depuis le
de'but des anne'es 80 des compilateurs pour machines vectorielles, puis
pour machines paralle`les a` me'moire partage'e. Il s'agit le plus
souvent de pre'-compilateurs ou me^me de compilateurs source a` source
effectuant la de'tection du paralle'lisme et son explicitation a` l'aide
de directives propres au constructeur de la machine cible. Pacific
Sierra fournit actuellement le paralle'liseur de Cray Research, FPP,
tandis que plusieurs socie'te's proposent des environnements de
programmation paralle`le comme Forge~90 (Applied Research, startup de
Pacific Sierra) et comme Express. En France, la socie'te' Connexite'
propose un outil de ce genre, Foresys, qui doit e^tre rapidement e'tendu
en un paralle'liseur, Partita.

Les techniques mises au point dans les centres de recherche ont, par
ailleurs, e'te' utilise'es abondamment dans les compilateurs
de'veloppe's en interne par des socie'te's comme Alliant ou Convex.

Ayant perc,u l'importance strate'gique de ce domaine, la DRET a lance'
un certain nombre de projets pour y soutenir la recherche francaise.
De`s les anne'es 70, le projet VESTA, de'veloppe' au sein du Centre de
Recherches de CII-Honeywell Bull avec la collaboration du Pr.~Feautrier,
pre'voit la conception d'un compilateur vectoriseur pour Fortran. Ecrit
en PL1, ce prototype n'a pas connu de suites imme'diates, en partie du
fait de l'absence de machines cibles franc,aises.

Ensuite, le projet VATIL, de'veloppe' a` l'INRIA par l'e'quipe
du Pr.~Lichnewsky, a poursuivi dans cette voie de recherche par la
re'alisation d'un vectoriseur e'crit en Le-Lisp. Ce vectoriseur a e'te'
progressivement enrichi et transforme' en un paralle'liseur. Il a e'te'
dote' d'une interface multifene^tre dans le cadre des projets GIPE et
GIPE-2 et sert de base au produit de Connexite'.

Enfin, des travaux plus the'oriques sont en cours au MASI (universite'
Paris~6) sous la direction de Mr. le Professeur Paul Feautrier. Les
objectifs sont beaucoup plus ambitieux mais ceci n'est possible qu'au
prix de restrictions sur l'ensemble et sur la taille des programmes
traite's. Un prototype en Le-Lisp a e'te' re'alise' pour montrer la
viabilite' de l'approche.

\subsection{Re'sultats acquis ante'rieurement}

L'essentiel des travaux effectue's pre'ce'demment dans le domaine de la
compilation pour superordinateurs e'tait axe' vers la vectorisation et
la paralle'lisation intra-proce'durale des
applications scientifiques. Les re'sultats primordiaux concernaient la
cre'ation de graphes de de'pendances aussi pre'cis que possible entre
instructions en vue de de'tecter celles qui sont vectorisables ou paralle'lisables.

La notion me^me de vectorisation e'tait incompatible avec le traitement
des appels de proce'dure puisqu'un call vectoriel n'a pas grand sens.
Les travaux en matie`re d'inter\-pro\-ce'\-du\-ralite' ont donc commence' au
de'but des anne'es 1980 en utilisant l'expansion de proce'dure et
les calculs d'effets {\em atomiques}: la modification d'un e'le'ment
de tableau est conside're'e comme une modification du tableau complet.

Les premiers re'sultats plus pre'cis ont e'te' de'crits dans la the`se
de Re'mi Triolet (1984) et ce sont eux qui sont a` l'origine du projet.
Depuis, plusieurs autres me'thodes ont e'te' pre'sente'es, dont beaucoup
sont des variations base'es sur la me'thode de Re'mi Triolet. Ces variations
consistent en des compromis varie's entre la pre'cision et la vitesse
d'analyse. La plupart de ces me'thodes n'ont pas e'te' comple`tement
imple'mente'es et aucune comparaison valable n'a encore pu e^tre effectue'e.

La gestion des boucles imbrique'es, base'e sur les notions d'e'change de
boucles et de partitionnement, n'a pas encore e'te' e'tudie'e de
manie`re approfondie. Seules des transformations e'le'mentaires ont e'te'
propose'es mais leur enchai^nement reste proble'matique. Des me'thodes
plus globales ont e'te' de'veloppe'es par Francois Irigoin en 1988, puis
inde'pendamment par une e'quipe de Stanford (Monica Lam) et chez Intel
par Uptal Banerjee.

Ces me'thodes n'ont pas encore apporte'es grand-chose dans le domaine 
de la paralle'lisation interproce'durale du fait de difficulte's non
pre'vues, comme l'existence d'{\em output dependence} ne'cessitant des
privatisations de tableaux.  Elles doivent ne'anmoins
e^tre prises en compte pour obtenir de bons re'sultats pour toute machine
ayant une me'moire non-uniforme, qu'il s'agisse de registres, de cache
ou de me'moire re'partie.

\section{De'roulement de l'e'tude}

Le projet PIPS-2 (Paralle'liseur Interproce'dural de Programmes
Scientifiques, adaptation aux multiprocesseurs Cray) s'est de'roule' sur
1 an. Le point qui s'est re've'le' le plus de'licat et qui nous a fait
perdre beaucoup de temps a e'te' l'acce`s a` une machine Cray.

Une collaboration entre l'Ecole des Mines et le CEA a e'te' instaure'e
pour nous fournir un peu de temps machine Cray. La premie`re machine
e'tait une machine de la CISI, accessible via le re'seau Transpac en
e'mulant un terminal sur e'cran bit-map. Les transferts de fichiers se
sont ave're's e^tre extre^mement lents, dans les deux sens, et le nombre
d'expe'riences pre'vues a e'te' limite' au maximum.

Dans une deuxie`me phase, le CEA militaire nous a donne' acce`s a` une
de ses propres machines, un Cray~Y-MP. Malheureusement, cette machine se
trouve en zone de se'curite' verte et les transferts de fichiers doivent
e^tre effectue's par porteur spe'cial depuis la zone orange.

Une pre'sentation et une premie`re de'monstration de la nouvelle version
de PIPS ont e'te' effectue'es en janvier 1993. Le syste`me a aussi e'te'
pre'sente' a` quelques socie'te's industrielles. L'une d'entre elles,
Connexite', envisage d'ailleurs d'inte'grer certaines des
fonctionalite's de PIPS dans son environnement de programmation
paralle`le, FORESYS.

\subsection{Rappel des diffe'rentes e'tapes}

Les e'tapes marquantes du projet PIPS-2 sont de'crites rapidement dans
cette section. Outre les rapports d'avancement et les rapports finals,
certaines dates clefs sont e'voque'es.

\begin{description}

\item[Etat d'Avancement 1 - Janvier 1992]
	Un rapport a e'te' joint a` cet e'tat d'avancement. Il pre'sente
rapidement les algorithmes utilise's pour effectuer la de'tection des
re'ductions ge'ne'ralise'es, le remplacement des constantes (e'valuation
partielle du code), la se'lection du paralle'lisme pour le Cray Y-MP et
pour le de'roulage de boucle. La de'tection des re'ductions est
imple'mente'e en CommonLisp. Elle a permis de valider l'utilisation de
NewGen pour le de'veloppement d'applications multiparadigmes.

\item[Rapport Interme'diaire - Avril 1992]
	Le rapport interme'diaire pre'sente la ge'ne'ration de code
paralle`le avec des directives Cray CFT77 et son imple'mentation dans
PIPS. Le code ge'ne're' a pu e^tre syntaxiquement ve'rifie' sur un
ordinateur Cray de la CISI. Le rapport rappelle aussi les
fonctionalite's de la phase d'e'valuation partielle puis de'taille son
imple'mentation. Il contient aussi l'algorithme code' en LISP pour la
de'tection des re'ductions ge'ne'ralise'es, des exemples d'application
de cette phase et une description des fonctions auxquelles est fait
appel a` l'exe'cution ({\em run-time support}).

\item[Etat d'avancement 2 - Juillet 1992]
	Les travaux effectue's pendant cette pe'riode sont de trois
natures diffe'rentes:
\begin{itemize}
\item
	Tout d'abord, des expe'riences ont e'te' effectue'es sur Cray
Y-MP pour valider et invalider les optimisations pre'vues. Elles ont
permis de montrer que l'augmen\-ta\-tion de localite' au niveau registre qui
avait e'te' pre'vue ame'liorait bien les performances mais ne pouvait
pas e^tre exploite' par la version courante du compilateur Fortran
CFT77.
\item
	Ensuite, la de'tection des re'ductions ge'ne'ralise'es a e'te'
ame'liore'e et inte'gre'e a` l'envi\-ron\-ne\-ment multifene^tre de
PIPS. Bien qu'elle soit code'e en CommonLisp, elle peut e^tre appele'e
depuis l'interface WPIPS, code'e en C, et partager des structures de
donne'es avec les autres phases de PIPS.
\item
	Enfin, le portage de PIPS sous UNICOS a e'te' commence'. Les
premiers re'sultats ont montre' que l'inte're^t escompte' de ce portage
en terme de performance e'tait illusoire vu la nature des algorithmes
utilise's dans PIPS. La compilation globale de PIPS sur un Cray Y-MP
charge' comme celui qui a pu e^tre utilise' au CEA prend de quatre a`
cinq fois plus de temps que sur une station de travail SparcStation~2.
Cray Research est d'ailleurs en train de porter son environnement de
de'veloppement sur stations de travail afin de limiter l'usage des
machines Cray aux seuls activite's pour lesquelles elles sont efficaces,
a` savoir les calculs nume'riques.  Les efforts de portage sous UNICOS
et CRAY ont donc e'te' abandonne's.
\end{itemize}
Un portage vers RS/6000 et AIX a e'te' brie`vement e'tudie'.
Nous nous sommes alors rendus compte que l'environnement de
de'veloppement de PIPS e'tait moins portable que le code C lui-me^me.
Les utilitaires utilise's pour compiler, analyser, ge'rer et valider le
code de PIPS sont souvent propres a` SUNOS. A tout le moins, certaines
de leurs options le sont.

\item[Dernier trimestre - juillet 92 a` la fin du contrat]
	Cette dernie`re pe'riode a eu pour objectif la re'alisation
d'expe'riences sur Cray avec les benchmarks de l'ONERA et du CEA.
L'essentiel du temps a e'te' consacre' au durcissement de PIPS pour que
toutes les options puissent e^tre utilise'es sur des programmes
complets. Les efforts ont porte' sur plusieurs phases ante'rieures du
paralle'liseur (analyse syntaxique, calcul des re'gions, calculs des
pre'conditions, interface utilisateur multifene^tre), sur l'outil de
ge'nie logiciel NewGen et sur les nouvelles phases de ge'ne'ration de
code paralle`le pour Cray CFT77.

% input from Corinne

\item[Participation a` des confe'rences]
	PIPS a e'te' pre'sente' en de'monstration a` la confe'rence {\em Third
International Workshop on Compilers for Parallel Computers} qui a eu
lieu a` Vienne en juillet 92. Les exemples traite's ont permis de mettre
en e'vidence l'inte're^t du couplage de l'analyse se'mantique
interproce'durale et de l'e'valuation partielle.

	Les analyses interproce'durales de PIPS ont aussi e'te'
pre'sente'es au {\em Workshop on Environments and Tools for Parallel
Scientific Computing} qui a e'te' organise' conjointement par le CNRS et
la NSF a` Saint-Hilaire du Touvet en septembre 1992.

\item[Pre'sentation a` la DRET]
	Les re'sultats obtenus ainsi que les proble`mes rencontre's ont
e'te' pre'sente's a` la DRET lors d'une re'union le 19 janvier. Une
de'monstration de PIPS a e'te' effectue'e en utilisant les codes de
l'ONERA et du CEA qui servaient a` son e'valuation. Les nouvelles phases
de'veloppe'es dans le cadre de ce contrat ont e'te' toutes utilise'es.
L'inte're^t des analyses interproce'durales et de l'e'valuation
partielle a e'te' particulie`rement mis en e'vidence.

\end{description}

\subsection{Difficulte's, faits significatifs et re'sultats}

\paragraph{Difficulte's}
La difficulte' principale que nous avons rencontre'e a e'te' l'acce`s a`
une machine Cray. Aussi bien le transfert de fichiers par e'mulation de
terminal que le transfert de fichiers par porteur ne permettent pas
d'effectuer d'expe'riences satisfaisantes. Il nous semble maintenant
indispensable d'avoir acce`s a` la machine cible par un re'seau
supportant TCP-IP comme RENATER avant d'envisager d'e'valuer PIPS
expe'rimentalement.

D'autre part, l'utilisation de PIPS en mode interproce'dural sur des
applications com\-ple`\-tes a mis en e'vidence des erreurs de programmation
qui e'taient reste'es invisibles lors des essais effectue's dans le
cadre du premier contrat PIPS. Le temps ne'cessaire a` leur correction a
e'te' conside'rable et n'avait pas e'te' pre'vu dans le de'roulement des
travaux. De nombreux composants pre'-existants de PIPS ont e'te'
retouche's pour en ame'liorer la correction et, dans certains cas, la
vitesse d'exe'cution: l'analyse syntaxique, le calcul des re'gions, le
calcul des pre'conditions, l'interface utilisateur et l'outil de gestion
des structures de donne'es, NewGen. Le de'tail des modifications
effectue'es est consigne' dans un document. Le re'sultat obtenu le plus
spectaculaire a e'te' une re'duction du temps de stockage des donne'es
ge're'es par NewGen pour le benchmark AILE de 2h30 a` moins de 5 minutes.

\paragraph{Re'sultats expe'rimentaux}
De nombreux proble`mes techniques ont aussi e'te' mis en e'vidence dans
le prototype PIPS. Tout d'abord, les traitements des erreurs et des
exceptions dans les programmes source entrai^nent de mauvais re'sultats
d'analyse et de transformation. Les effets de contro^le devraient non
seulement e^tre ajoute's au syste`me actuel mais il faudrait encore
savoir les traiter de manie`re satisfaisante.

Les expe'riences ont aussi montre' que les hypothe`ses faites sur la
bonne structuration des programmes Fortran n'e'taient pas
satisfaisantes. En effet, bien que le paralle'lisme ne soit exploitable
que dans les boucles, c'est le programme tout entier qui doit e^tre
analyse'. L'absence de la construction \verb+IF+...\verb+ELSE+...\verb+ENDIF+
dans les normes Fortran~IV et Fortran~66 ont conduit les utilisateurs a`
utiliser e'norme'ment de \verb+GOTO+s. Une bonne utilisation de PIPS
ne'cessite donc l'utilisation pre'alable d'un restructureur comme Forge~90
qui est propose' commercialement ou comme celui qui est inclus dans
Toolpack et qui se trouve dans le domaine public.

Un certain nombre de restrictions effectue'es dans la de'finition du
Fortran d'entre'e de Pips se sont re've'le'es fastidieuses a` e'liminer
manuellement\footnote{Toutes les restrictions de Fortran introduites
lors du projet pre'ce'dent peuvent e^tre contourne'es par des
re'e'critures syntaxiques.}. Par exemple, il serait utile d'accepter des
de'claration de COMMON de longueurs variables d'une proce'dure a` une
autre ainsi que les ope'rations sur les sous-chai^nes de caracte`res.

Les expe'riences mene'es sur les benchmarks de l'ONERA ont aussi montre'
que les complexite's spatiale (coefficients supe'rieurs a` $2^{31} - 1$,
grand nombre d'ine'galite's) et temporelle des calculs d'enveloppes
convexes e'taient prohibitives. Un nouvel algorithme, l'algorithme de
Chernikova, a e'te' utilise' a` la place de l'algorithme de Halbwachs
qui avait e'te' programme' initialement. Le remplacement a pu e^tre
effectue' rapidement gra^ce a` l'IRISA qui a mis a` notre disposition
une version code'e en C de cet algorithme. Cependant les re'sultats
obtenus sont plus difficiles a` interpre'ter par l'utilisateur. Un
travail supple'mentaire est encore ne'cessaire.

\paragraph{Comparaison avec FPP}
Une comparaison des transformations effectue'es par le pre'\-pro\-ces\-seur
FPP de'veloppe' par Pacific-Sierra et revendu par Cray comme frontal de
son compilateur CFT77 a e'te' faite. Voici la liste des transformations
qui e'taient disponibles dans FPP lorsque nous avons effectue' notre
e'tude comparative:

\begin{itemize}

\item Re'ordonnancement des instructions d'une boucle: e'galement effectue' par
PIPS;

\item Aggre'gation de boucles: cette transformation permet d'augmenter
le nombre d'ite'\-ra\-tions de boucles paralle`les et donc de mieux utiliser
le paralle'lisme vectoriel et inter\-pro\-ces\-seurs, spe'cialement quand les
tableaux re'fe'rence's au sein des boucles peuvent e^tre line'arise's;
cette transformation n'a pas e'te' pre'vue dans PIPS mais les benchmarks
de l'ONERA montrent qu'elle est be'ne'fique;

\item Distribution de boucles: e'galement effectue'e par PIPS;

\item Reconnaissance des re'currences line'aires du premier ordre: non
pre'vue dans PIPS; l'utilite' de cette transformation n'a pas e'te' mise
en e'vidence sur les benchmarks;

\item Reconnaissance des ope'rations vectorielles: ce type de
pattern-matching peut donner de tre`s bons re'sultats dans des cas
particuliers parce qu'il permet d'utiliser des routines de bibliothe`que
optimise'es manuellement; l'objectif de PIPS est d'obtenir
automatiquement un code de qualite' comparable; cette reconnaissance ne
fait donc pas partie du projet;

\item Echange de boucles: e'galement effectue'e par PIPS;

\item Conversion de boucle IF en boucle DO: non imple'mente' dans PIPS;
aucune utilisation de cette transformation n'a e'te' trouve'e dans les
benchmarks du CEA et de l'ONERA; les boucles re'alise'es a` l'aide de IF
sont des boucles WHILE et non des boucles DO; l'inte're^t de leur
paralle'lisation est douteux puisqu'il s'agit en ge'ne'ral de boucles de
convergence fondamentalement ite'ratives;

\item Epluchage de boucle ({\em Loop Peeling}): cette transformation
permet de simplifier les corps de boucles vectoriels quand seule la
premie`re ite'ration ou la dernie`re se comporte diffe'remment des
autres; par exemple, un test est effectue' a` la premie`re ite'ration
pour initialiser une structure de donne'es; une application ou` cette
transformation pourrait se re've^ler utile nous a e'te' soumise mais
elle date des anne'es 60; les benchmarks du CEA et de l'ONERA semblent
plus re'cents et ne pas comporter ce type de construction; l'application
de cette transformation dans PIPS n'a pas e'te' pre'vue;

\item Tests et codes alternatifs: il s'agit de produire deux versions
d'une me^me partie d'un code, une optimise'e et une non-optimise'e. La
version non-optimise'e est toujours correcte tandis que la version
optimise'e ne l'est que parfois, en fonction d'un crite`re e'valuable
dynamiquement; PIPS n'applique pas cette tactique mais profite largement
du calcul des pre'conditions pour e'valuer statiquement le crite`re et
choisir, au moment de la compilation, la bonne version; une application
de sismique contenait un tel cas, et PIPS a pu re'soudre statiquement
le proble`me;

\item Privatisation de tableau: c'est la transformation qui manque le
plus a` PIPS pour effectuer de la paralle'lisation interproce'durale et
pour obtenir du paralle'lisme de grain moyen; les ame'liorations
apporte'es au calcul des re'gions pendant l'e'te 92 en rendent possible
une imple'mentation tre`s ge'ne'rale, beaucoup plus que celle de FPP
dont nous ne connaissons pas les limites mais dont l'algorithme doit
e^tre base' sur du pattern-matching et e^tre donc peu robuste;

\item Reconnaissance et paralle'lisation des re'ductions: PIPS dispose 
e'galement de cette transformation mais la comparaison est difficile;
les techniques de pattern-matching ne permettent pas de de'finir des
crite`res d'applicabilite' clairs;

\item Minimisation des acquisitions/libe'rations des processeurs: ceci
n'a pas e'te' mis en oeuvre dans PIPS parce que le temps perdu pour
exe'cuter du code sur Cray via Transpac ou le CEA n'a pas permis
d'effectuer une validation quantitative de cette optimisation;

%%
\item De'tection des variables inductives: ces variables peuvent e^tre
remplace'es par des expressions qui sont des fonctions des indices de
boucles. Elles sont remplace'es soit directement dans  les expressions
du nid de boucles les re'fe'renc,ant, soit par des variables {\em
prive'es} qui  autorisent une e'ventuelle paralle'lisation. Cette
transformation s'est ave're'e utile pour les benchmarks du CEA et de
l'ONERA. Elle n'est pas encore imple'mente'e dans PIPS. 

%%
\item Paralle'lisation en pre'sence de tests: elle s'applique a` des
tests simples (test servant a` traduire une  fonction
e'le'mentaire telle que le calcul d'un maximum et de'tecte' par
pattern-matching)  ou  a` des  tests plus complexes devant se traduire
par un masquage des instructions vectorielles ou paralle`les. Cette
transformation n'e'tait pas pre'vue dans PIPS. Les benchmarks du CEA ont
montre' qu'elle e'tait be'ne'fique.

\end{itemize}

Globalement, toutes les transformations importantes, qui ont un impact
e'vident sur les benchmarks du CEA et de l'ONERA, sont disponibles dans
FPP et dans PIPS, a` l'exception de la privatisation de tableau qui
manque chez PIPS. Les atouts de PIPS, c'est-a`-dire ses analyses
interproce'durales, ne sont pas visibles dans une telle comparaison car
ils ame'liorent essentiellement l'applicabilite' de chaque
transformation, la de'cidabilite' de l'application ainsi que la
se'lection des meilleurs parame`tres d'application.

%% ({\em Corinne, as-tu quelque chose a` dire a` propos des listings?}).

L'e'tude de la comparaison des listings re'sultant des expe'riences
effectue'es sur FPP et PIPS a montre' que:
\begin{itemize}

\item L'analyse interproce'durale de PIPS permet d'extraire le
paralle'lisme implicite de certaines  boucles faisant des appels de
proce'dure. Ce paralle'lisme  n'est pas  de'tecte' par FPP. Il est
difficile, pour le moment, sans mesures expe'rimentales, d'estimer le
gain apporte' par cette paralle'lisation. 

\item Certaines transformations doivent e^tre inte'gre'es a` PIPS. Il
s'agit de la privatisation des tableaux et la de'tection des variables
inductives. La richesse de la structure de l'environnement de
programmation de PIPS permet de les  inte'grer simplement aux autres
transformations. 

\item Certaines optimisations sont encore ne'cessaires pour mieux cibler
les caracte'ristiques vectorielles de la machine CRAY. Il s'agit
essentiellement de la normalisation des boucles, de la de'tection de
certaines fonctions e'le'mentaires (MAX,MIN), la line'a\-ri\-sa\-tion de
tableaux et de la ge'ne'ration d'instructions paralle`les {\em masque'es}.

\item La grande majorite' des boucles sont paralle'lise'es par FPP et PIPS. 

\end{itemize}

%%

L'expansion ou la privatisation de tableau devrait e^tre ajoute'e aux
transformations propose'es par PIPS. Elle est utile non seulement pour
les multiprocesseurs a` me'moire partage'e mais encore davantage pour
les multiprocesseurs a` me'moire re'partie puisqu'elle permet d'allouer
le tableau correspondant en me'moire locale et d'e'viter tout transfert.

%%
La de'tection des variables inductives s'est ave're'e utile pour les
benchmarks du CEA et de l'ONERA. Toutes les structures ne'cessaires a`
son imple'mentation dans l'environnement de programmation de PIPS e'tant
disponibles, cette transformation sera prochainement inte'gre'e aux
transformations propose'es par PIPS.
%%

\paragraph{Interproce'duralite'}
L'inte're^t du couplage de l'analyse se'mantique et de l'e'valuation
partielle a e'te' mis en e'vidence tout d'abord par la simplification
des codes qu'il permet: e'limination de code mort, bornes de boucles
nume'riques, etc... Ensuite, l'e'valuation partielle permet de
line'ariser certaines expressions et donc d'obtenir de meilleurs
re'sultats lors d'une {\em deuxie`me} application de PIPS sur le code
partiellement e'value'. Enfin, un troisie`me inte're^t est le
de'couplage qu'il cre'e entre les phases d'analyse et les phases de
transformations de PIPS. Il rend possible l'utilisation de PIPS en
pre'processeur d'un autre paralle'liseur comme FPP.

Enfin, il faut noter que des expe'riences effectue'es aux Etats-Unis ont
montre' que la puissance du test de de'pendance initialement introduit
dans PIPS n'e'tait pas obtenue au de'triment de la vitesse. Les nouveaux
projets de paralle'liseurs utilisent donc des tests similaires.

L'inte're^t des diffe'rentes techniques utilise'es dans PIPS a e'te' mis
en e'vidence par plusieurs e'tudes expe'rimentales de paralle'liseurs.
Ces e'tudes ont e'te' effectue'es aux Etats-Unis au CSRD, a` Rice et a`
Stanford. Tout d'abord, les pre'conditions permettent de s'affranchir de
la substitution en avant dont l'application syste'matique est ne'faste
en moyenne. Deuxie`\-me\-ment, la re'organisation des nids de boucles
est calcule'e directement a` partir du co^ne de de'\-pen\-dance globale
du nid alors que de nombreux syste`mes explorent tous les e'changes
possibles.  Le nombre d'e'changes possibles croissant exponentiellement,
ces syste`mes abandonnent la recherche d'une bonne re'organisation
apre`s un certain temps, fixe' arbitrairement. Troisie`\-me\-ment, les
informations interproce'durales sont trouve'es ne'cessaires.
Quatrie`ment, le choix des boucles a` paralle'liser doit se fonder sur
les nombres d'ite'rations qui sont connus plus souvent qu'on ne le
pensait, surtout en pre'sence de pre'conditions interproce'durales.

\section{Re'capitulation des re'sultats}

Le paralle'liseur PIPS a e'te' conside'rablement durci durant ce
contrat. L'ensemble des programmes de benchmarks qui nous ont e'te'
soumis, ONERA, CEA et Perfect Club, ont e'te' inte'gralement traite's
par PIPS.  Les programmes de l'ONERA et du CEA ont pu e^tre analyse's
interproce'duralement dans leur inte'gralite'.

L'e'tude du pre'processeur FPP a montre' que PIPS posse'dait les
transformations essentielles mais qu'il serait utile d'en ajouter
quelques autres. La lecture de rapports d'e'valuation de paralle'liseurs
ame'ricains montre que les phases de'veloppe'es dans PIPS sont utiles et
encore du domaine du prototype expe'rimental. Le projet PIPS est en
avance par rapport a` ses concurrents ame'ricains.

Le portage de PIPS sous UNICOS a e'te' abandonne', faute d'inte're^t
ve'ritable. L'ame'\-lio\-ra\-tion exponentielle des performances des stations
de travail rend l'utilisation scalaire d'une CPU de Cray sans objet.

La production de Fortran Cray a bien e'te' imple'mente'e.
Les sorties de PIPS ont e'te' envoye'es au CEA et ont e'te' accepte'es
par le compilateur Cray CFT~77. Les se'jours de longue dure'e
qu'effectue aux Etats-Unis notre correspondant au CEA n'ont pas encore
permis d'effectuer de mesures comparatives pre'cises.

\section{Conclusion}

Malgre' un retard de quelques mois, essentiellement du^ aux difficulte's
que nous avons rencontre'es pour effectuer les e'tudes expe'rimentales
pre'vues, le projet PIPS-2 a abouti aux re'sultats escompte's. Des
programmes re'els ont e'te' analyse's interproce'duralement et
paralle'lise's, ce qui est encore exceptionnel pour un prototype de
recherche franc,ais, et les techniques sophistique'es d'analyse statique
de programmes, pre'sente'es auparavant dans des congre`s internationaux,
ont e'te' expe'rimente'es avec succe`s en de'pit de leur complexite'
the'orique.

La collaboration entre
l'Ecole des Mines et l'Universite' Pierre et Marie Curie a e'te'
poursuivie, comme le montre l'organisation conjointe d'un se'minaire
re'gulier sur la compilation pour machines paralle`les.

\section{Perspectives ulte'rieures}

PIPS apparai^t comme une plate-forme puissante pour le de'veloppement
d'environnement de programmation paralle`le. Par la richesse des
informations recueillies par l'analyseur se'mantique interproce'dural
et la structure modulaire du paralle'liseur lui-me^me au niveau de son
imple'mentation, l'addition de modules annexes s'est re've^le'e
particulie`rement aise'e. 

L'interface utilisateur interactive graphique est indispensable pour
analyser efficacement des programmes qu'on ne connai^t pas a priori. Le
prototype sous X Window qui a e'te' de'veloppe' a` cet effet pour les
besoins propres de l'Ecole des Mines devrait maintenant e^tre repris par
un industriel.

En aval de cet axe, PIPS fournit une excellente plate-forme pour aborder
les proble`mes que pose la compilation pour machines a` me'moire
re'partie et, plus particulie`rement, le langage HPF (High Performance
Fortran). Les analyses et transformations ne'cessaires sont pour la
plupart de'ja` re'alise'es et une premie`re expe'rience de re'partition
automatique de code a e'te' effectue'e dans le cadre du projet PUMA
(ESPRIT 2701). Il serait dommage de ne pas profiter de cet acquis pour
relever le de'fi qu'HPF pose actuellement a` la communaute' de la
compilation et du calcul scientifique.

\end{document}
