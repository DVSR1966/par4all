\documentstyle[12pt,A4,french,verbatim]{article}
\input{/usr/share/local/lib/tex/macroslocales/Dimensions.tex}
\newcommand{\titre}{RAPPORT D'AVANCEMENT No 1 \\
COMPILATION POUR MACHINES A MEMOIRE REPARTIE
}
\newcommand{\auteur}{
~Corinne ANCOURT \\
Fabien COELHO \\
Franc,ois IRIGOIN \\
Ronan KERYELL 
 }
\newcommand{\docdate}{Juin 1994}
\newcommand{\numerocri}{E184}
\begin{document}
\sloppy
\input{/usr/share/local/lib/tex/macroslocales/PageTitre.tex}



\section*{Introduction}

L'objectif ge'ne'ral de cette e'tude est de de'velopper les techniques
ne'cessaires a` la compilation de machines a` me'moire re'partie. 
Cette e'tude s'effectue en partie en collaboration avec l'e'quipe de Paul
Feautrier du Masi. Ce rapport de'crit l'e'tat d'avancement des
diffe'rentes ta^ches qui sont a` la charge du CRI, c'est a` dire:
\begin{enumerate} 
\item Interface du langage de sortie FORTRAN 77 augmente'
d'appels a` une bibliothe`que de communication 
\item De'veloppement de techniques d'analyse statique de complexite' en
temps;
\item  De'finition des pragmas;
\item  Extension du langage d'entre'e;
\item Compilation de structures de donne'es dynamiques, comme les
indirections;
\item Compilation de structures de contro^le dynamiques, comme les 
conditionnelles, 
\item De'veloppement de techniques de partitionnement pour des
boucles non-parfaitement imbrique'es ;
\end{enumerate}

Les deux premie`res ta^ches sont acheve'es, les trois suivantes sont en
cours de de'veloppement et les deux dernie`res n'ont pas encore
de'bute'. Nous de'taillons maintenant les re'sultats obtenus pour
chacune des cinq premie`res. La description des travaux de'ja` effectue's
dans le cadre du projet PUMA n'a pas lieu d'e^tre dans ce rapport. Pour
plus de de'tails sur ces travaux, il est conseille' de  se rapporter a`
l'article \cite{AnIr92}.


\section{De'finition des pragmas}

L'ensemble des techniques de'ja` de'veloppe'es en matie`re de
paralle'lisation automatique par les e'quipes du Masi et d'Armines
repre'sente un support important pour l'obtention rapide d'un prototype
de compilation pour machines a` me'moire distribue'e. Il est important
que les deux prototypes PAF et PIPS puissent profiter des meilleurs
re'sultats obtenus par l'ensemble des techniques. Nous avons de'termine'
les informations inte'ressantes qui seront e'change'es entre PAF et
PIPS. Plus pre'cise'ment, il s'agit des {\it pre'conditions} et des {\it
re'gions}, calcule'es par PIPS et disponibles sous forme de commentaire
dans les programmes, qui seront utilise'es par PAF et des {\it
re'ductions}, de'tecte'es par PAF, qui seront utilise'es par PIPS. Le
format d'e'changes des re'ductions choisi est celui de'crit dans le
premier rapport d'avancement re'dige' par M. Barreteau, P. Feautrier et
X. Redon. La prochaine e'tape consiste a` de'terminer le format
d'e'changes des pre'conditions et des re'gions.


\section{Extension du langage d'entre'e}
Dans le cadre du projet PUMA, le langage d'entre'e e'tait tre`s
restreint. L'e'tude portait uniquement sur la ge'ne'ration de code
distribue' pour les nids de boucles {\em paralle`les} et parfaitement
imbrique'es englobant une se'quence d'affectations. L'extension de ce
langage d'entre'e aux structures de donne'es dynamiques, telles que les
indirections, ou aux structures de contro^le dynamiques, telles que les
conditionnelles n'avait pas e'te' aborde'e. De me^me, aucune strate'gie
de distribution des parties se'quentielles du code n'avait e'te'
de'veloppe'e. Cette e'tude est maintenant en cours. Les premie`res
e'tapes ont e'te' la de'finition d'un sche'ma de communication adapte'
aux nouvelles structures ainsi que le de'veloppement et l'inte'gration
d'une transformation de programme nomme'e {\it atomizer} ne'cessaire,
plus particulie`rement, au traitement des indirections.


\subsection{Sche'ma de communication adapte' aux nouvelles
structures} 

La premie`re e'tape de distribution/paralle'lisation d'un programme,
 compose' uniquement d'un ensemble de boucles paralle`les et
 parfaitement imbrique'es, consiste a` regrouper les calculs en ta^ches
 paralle`les de taille raisonnable (relative a` la taille des caches ou
 aux lignes de bancs me'moire, par exemple). Une fois les calculs
 regroupe's en ta^ches paralle`les, l'e'tape suivante est la
 ge'ne'ration des communications ne'cessaires a` l'exe'cution des
 ta^ches sur les diffe'rents processeurs. Pour ce type de code, la
 strate'gie choisie consistait, dans le cadre du projet PUMA, a`
 transfe'rer l'ensemble des e'le'ments re'fe'rence's en lecture
 (respectivement en e'criture) avant (respectivement apre`s)
 l'exe'cution de chacune des ta^ches paralle`les. Cependant, l'extension
 de notre langage d'entre'e impose un sche'ma de communication plus
 complet.

Diffe'rentes strate'gies de communication peuvent e^tre utilise'es pour
transfe'rer les e'le'ments utiles a` l'exe'cution des ta^ches sur les
processeurs selon les diffe'rentes structures du programme.  Celle que
nous avons choisi est la suivante:

\begin{description}
\item [Affectation simple:]
~\newline
 \begin{itemize}
\item les e'le'ments   re'fe'rence's en lecture
sont transfe're's avant l'exe'cution de cette instruction, pas
ne'cessairement juste avant, mais le plus souvent regroupe's avec ceux de
structures plus englobantes, de manie`re a` favoriser des possibilite's
d'effectuer concurremment communications et calculs.
\item Les  e'le'ments  scalaires re'fe'rence's en e'criture sont
transfe're's juste apre`s l'exe'cution, tandis que les e'le'ments de
tableaux modifie's sont regroupe's avec ceux d'une structure plus
englobante pour favoriser les possibilite's de transferts d'e'le'ments
contigus, moins cou^teux. 
\end{itemize}

\item [Une se'quence d'affectations:]

 ~\newline
\begin{itemize}
\item l'ensemble des e'le'ments  re'fe'rence's en lecture
 est transfe're' avant l'exe'cution de cette se'quence, si aucun des
termes des indices des fonctions d'acce`s aux e'le'ments d'un tableau ne
de'pend d'une variable scalaire qui est modifie'e dans cette se'quence
line'aire (voir Figure 1).  Sinon, une communication en re'ception est
ge'ne're'e juste avant l'instruction re'fe'renc,ant le tableau.

\begin{center}

\begin{figure}[hpt]
\begin{verbatim}
                                 A = ...
                                 C = T(A)
\end{verbatim}
\caption{Se'quence d'affectations 1}
\label{prog1}
\end{figure}
\end{center}


\item  Les  e'le'ments  scalaires re'fe'rence's en e'criture sont
transfe're's juste apre`s l'exe'cution, tandis que les e'le'ments de
tableaux modifie's sont regroupe's au niveau de la se'quence
d'instructions.

\end{itemize}

 Il faut noter que les variables qui sont {\it prive'es}\footnote{Une
variable est prive'e a` un nid de boucles, si sa valeur en entre'e de
boucle et sa valeur en sortie ne sont pas utilise'es dans le nid de
boucles en dehors de cette boucle; c'est le cas des variables
temporaires.}  a` une se'quence d'instructions n'impose une
communication qu'apre`s exe'cution de la se'quence d'instructions et pas
avant.  L'exemple \ref{prog2} pre'sente le type de communications
ge'ne're'es pour une se'quence d'affectations.

\begin{center}
\begin{figure}[hpt]
\begin{verbatim}
                                        CALL RECEIVE_4(A)
                                        CALL RECEIVE_4(B)
          F=A                           F = A
                                        CALL SEND_4(F)
          D=B                           D = B 
                                        CALL SEND_4(D)
                                        CALL RECEIVE_4(M(F,F))
          E=M(F,F)                      E = M(F,F)            
                                        CALL SEND_4(E)
\end{verbatim}
\caption{Communications - Se'quence d'affectations}
\label{prog2}
\end{figure}
\end{center}

\item [Les nids de boucles totalement paralle`les:] 
 Les e'le'ments de tableaux ou scalaires re'fe'rence's en lecture
(respectivement en e'criture) sont transfe're's globalement
avant (respectivement apre`s) l'exe'cution. Il n'y a pas de conflits
me'moire entre les acce`s aux donne'es re'fe'rence'es puisque les
exe'cutions sont paralle`les.


\item [Les nids de boucles totalement se'quentielles:] Les calculs
se'quentiels sont exe'cute's sur un seul processeur. Tous les
e'le'ments re'fe'rence's en lecture (respectivement en e'criture)
peuvent e^tre  transfe're'es globalement
avant (respectivement apre`s) l'exe'cution du nid de boucles, car les
de'pendances sont respecte'es par la se'quentialite' de l'exe'cution.

\item [Les nids de boucles totalement se'quentielles - Pipeline'es:] Si
le volume des donne'es est trop important pour la me'moire locale des
processeurs, une division du domaine de
calculs en blocs d'ite'rations plus petits s'impose. Ces blocs seront
exe'cute's sur diffe'rents processeurs. Les communications et les
calculs sont alors pipeline's, dans tous les cas ou` cela est possible,
de manie`re a` minimiser le temps global d'exe'cution. Les re'fe'rences
qui ne causent pas de de'pendances correspondent aux donne'es qui
pourront e^tre communique'es de manie`re concurrente avec des calculs.

\item [Les nids de boucles mixtes:] On impose un seul niveau de
concurrence: on ne ge'ne'rera pas a` la fois du code paralle`le et
pipeline' au sein d'un me^me nid de boucles.

Toutes les re'fe'rences internes au nid de boucles paralle`les ou
pipeline'es sont communique'es avant (respectivement apre`s) pour les
re'fe'rences en lecture (respectivement en e'criture).  Les re'fe'rences
externes seront communique'es selon le sche'ma de communication des
boucles se'quentielles non pipeline'es. Comme les se'quences
se'quentielles ne sont exe'cute'es que sur un seul processeur, ces
parties de code sont traite'es comme des parties inde'pendantes des
boucles paralle`les et des communications conservant la cohe'rence de la
me'moire globale doivent e^tre ge'ne're'es a` la fin et au de'but des
parties qui sont paralle`les.

\item [les conditionnelles:] Par de'faut, les deux branches de la
conditionnelle sont traite'es de manie`re inde'pendante selon les
structures pre'ce'demment de'crites auxquelles elles appartiennent. 
Toutefois, il est possible d'effectuer quelques optimisations pour les
deux cas suivants:
\begin{itemize}
\item La conditionnelle est une ine'quation line'aire de'pendante d'un
indice de boucle. Dans ce cas il est possible d'introduire cette 
contrainte dans le domaine d'ite'rations et de ge'ne'rer un ou deux  nouveaux nids
de boucles et leurs communications sans conditionnelle. Les nids de
boucles traduiront respectivement la branche vraie et la branche fausse
de la contrainte. 

\item La conditionnelle est une fonction line'aire inde'pendante des
termes contenus  dans les deux branches du test. Cette contrainte est
alors extraite du nid de boucles et place'e a` l'exte'rieur. Les
communications sont ge'ne're'es pour chacune des branches
inde'pendamment. Toutefois, le  test est effectue' en dehors du nid de
boucles et pas une fois pour chacune des valeurs du domaine
d'ite'rations. 
\end{itemize}

\end{description}


\section{Structures de donne'es dynamiques: les indirections}

 L'{\it atomizer} est une transformation de programme qui {\it atomise}
toutes les re'fe'rences d'un programme, c'est a` dire caracte'rise
l'acce`s de chacune des variables du programme par une suite
d'ope'rations trois adresses, similaires a` celles qui sont utilise'es
dans le langage interme'diaire d'un compilateur.
 

\begin{center}
\begin{figure}[hpt]
\begin{verbatim}
                                      ITMP1 = I             
                                      ITMP2 = J
                                      ITMP3 = A(ITMP1, ITMP2)
                                      ITMP4 = ITMP1 -1
                                      ITMP5= ITMP2 +1
       B(I-1,J+1)=A(I,J)              B(ITMP4,ITMP5) = ITMP3
       C(A(I,J),J) = I                C(ITMP3,ITMP2) = ITMP1
\end{verbatim}
\caption{Atomizer}
\label{prog3}
\end{figure}
\end{center}

   Cette transformation de programme simplifie les phases d'analyse et
de ge'ne'ration des communications dans les cas ou` il y a des
indirections (et des entre'es/sorties), puisque les variables
temporaires cre'e'es par l'atomizer repre'sentent les diffe'rentes
ope'rations ou communications qui devront e^tre effectue'es pour
finaliser l'envoi ou la re'ception d'un acce`s indirect aux e'le'ments
d'un tableau.

L'exemple \ref{prog3} pre'sente les diffe'rentes variables temporaires
obtenues lorsqu'on applique cette transformation. Toutes les
ope'rations faisant intervenir des variables  non temporaires
repre'sentent l'ensemble des communications a` effectuer.

Cette transformation de programme  a e'te' inte'gre'e a` Pips et sera
utilise'e pour la ge'ne'ration des communications dans les cas ou` il y a
des indirections.



\section{ Interface du langage de sortie FORTRAN 77 avec  une bibliothe`que de communication }

Afin de pouvoir tester notre approche sur diffe'rents types
d'architecture, nous avons choisi PVM comme  bibliothe`que de communication. 

PVM est a` l'heure actuelle la bibliothe`que de communication la plus
utilise'e pour les re'seaux de stations de travail. Elle est surtout
utilise'e dans le domaine de la recherche mais est aussi adopte'e par
les industriels. Citons quelques industriels qui l'ont implante'e sur
leur multiprocesseur respectif: CRAY sur le T3D, IBM pour leurs re'seaux
de RS6000 et Fujitsu sur l'AP1000.

Une fois le code distribue' (Fortran 77 + Primitives de communications),
une interface permet de traduire 
les appels aux communications en primitives PVM. Une validation du code
ainsi ge'ne're' avec l'interface PVM peut ensuite e^tre effectue'e sur
un re'seau de stations de travail.

La dernie`re partie de l'annexe pre'sente cette interface. Les primitives de 
communication pre'sentes dans le code ge'ne're' par PUMA sont traduites
par des appels a` des primitives de la bibliothe`que de communications
PVM. Les fonctions utiles au lancement des diffe'rentes
ta^ches en paralle`le sur les processeurs sont aussi donne'es et
commente'es. 


\section{De'veloppement de techniques d'analyse statique de complexite' en
temps}

Le calcul de la complexite' des ta^ches paralle`les  a` exe'cuter sur
les diffe'rents processeurs est utile, en autres, pour e'valuer  le bon 
e'quilibrage ``cou^ts des communications'' et ``cou^ts des calculs''.


L'estimation statique de la complexite' des programmes se'quentiels a
de'ja` fait l'objet de nombreuses recherches. L'originalite' des travaux
du CRI est due a` l'utilisation de pre'conditions et au traitement des
appels de proce'dures. Ils sont maintenant inte'gre's a` Pips. Du point
de vue the'orique, cette e'tude 

\begin{itemize}
\item  a e'tendu l'ensemble des cas traite's aux cas ou` le programme
contient des tests, 

\item introduit des parame`tres symboliques utiles a` l'expression des
parame`tres que l'on ne peut (ou veut) pas e'valuer dans le programme, 

\item et  tient compte des
pre'conditions interproce'durales fournies par les phases d'analyses de
Pips.
\end{itemize}

Des expe'riences ont e'te' mene'es sur des machines se'quentielles et
paralle`les pour valider l'approche choisie.

L'exemple \ref{prog5} de'taille le calcul de la complexite' d'une
sous-routine de calcul par Cholesky. Le cou^t de chacune des ope'rations
e'le'mentaires est suppose'e ici unitaire, mais d'autres tables
approprie'es a` diffe'rents processeurs peuvent e^tre choisies. Le
re'sultat global est ici de'pendant de la variable $N$ puisque cette
constante n'est pas fixe'e par le programme.

\begin{figure}[hpt]
\verbatiminput{complexity.tex}
\caption{Complexite' statique}
\label{prog5}
\end{figure}


\section{Validation}

Une  proce'dure de validation du code ge'ne're' a e'te' installe'e. Elle
teste (1) la correction du code ge'ne're' en la comparant avec  une version
de re'fe'rence, ainsi que (2) la cohe'rence 
des nouvelles versions qui doivent pre'server les re'sultats des
versions ante'rieures. Les programmes de test sur lesquels sont
applique's cette proce'dure ont un  langage d'entre'e relatif  aux diffe'rentes
versions de notre prototype. Actuellement,  nous ge'ne'rons un code
distribue' pour les programmes contenant:
\begin{itemize}
\item  un ou plusieurs nids de boucles parfaitement imbrique's englobant une
se'quence d'affectations,
\item  des se'quences d'affectations (partie a` exe'cution se'quentielle) et de nids de
boucles parfaitement imbrique's (englobant  une se'quence d'affectations),
\end{itemize}

Les de'clarations des tableaux locaux sont ve'rifie'es par une
validation portant sur des programmes dont les sous-ensembles
d'e'le'ments re'fe'rence's sont  disjoints ou  se recouvrent. Le
deuxie`me exemple de l'annexe illustre le cas ou` ils sont disjoints.

\section*{Conclusion}

N'ayant pas rencontre's  de difficulte's majeures lors de l'e'tude
des diffe'rentes ta^ches de'crites pre'ce'demment, la re'alisation de
notre contrat  progresse comme pre'vu. Il nous
faut maintenant terminer ou aborder les diffe'rents points suivants:
\begin{itemize}
\item  Extension du langage d'entre'e (imple'mentation du sche'ma de communications);
\item Compilation de structures de donne'es dynamiques, comme les
indirections (utilisation de l'atomizer);
\item Compilation de structures de contro^le dynamiques, comme les 
conditionnelles, 
\item De'veloppement de techniques de partitionnement pour des
boucles non-parfaitement imbrique'es ;
\end{itemize}

L'annexe donne deux exemples de code distribue' ge'ne're's par notre
prototype: l'addition de matrices et la transposition. Pour chacun de
ces exemples, la sous-routine exe'cute'e par les processeurs de calcul
pre'ce`de celle exe'cute'e par les processeurs e'mulant la me'moire
partage'e.

\newpage
\section*{Annexe}
\subsection*{Premier exemple: L'addition de matrices }
\verbatiminput{add.tex}
\newpage
\subsection*{Deuxie`me exemple: La transposition de matrice}

\verbatiminput{transp.tex}

\newpage
\subsection*{Interface avec la bibliothe`que de communications PVM}
\verbatiminput{pvm-interface.tex}
\begin{thebibliography}{99}
\bibitem[AnIr92]{AnIr92}
C. Ancourt, F. Irigoin,
`` Automatic Code Distribution '',
{\it The Third Workshop on Compilers for Parallel Computers (CPC'92) },
Vienna, Austria, July 6-9, 1992
\end{thebibliography}

\end{document}
