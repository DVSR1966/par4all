%
%% $RCSfile: developer_guide.tex,v $ (version $Revision$)
%% $Date: 1996/10/17 22:36:12 $, 
% PIPS development environment documentation; translated and updated from 
% dret146.f.tex
%

%% titlepage,
\documentclass[a4paper]{article}

\usepackage{psfig,amstext,alltt,html}

\title{\bf {\Huge PIPS} \\ Development Environment}

\author{
\begin{tabular}{rl}
  François & IRIGOIN \\ 
  Pierre & JOUVELOT \\
  Rémi & TRIOLET \\
  Arnauld & LESERVOT \\
  Alexis & PLATONOFF \\
  Ronan & KERYELL \\
  Fabien & COELHO \\
  Béatrice & CREUSILLET \\
  Corinne & ANCOURT
\end{tabular}
}

\date{August 1996}

\renewcommand{\indexname}{Index}
\makeindex

\begin{document}
\maketitle

\begin{latexonly}
  \clearpage
  \tableofcontents  
\end{latexonly}

\newpage
\section*{Introduction}

This document aims at presenting PIPS' development environment. It is
not linearly organized: PIPS is made of several, sometimes
interdependent, components.  This paper thus begins with a
presentation of PIPS directories.  Then the shell environment is
described. The next two chapters are devoted to two external tools on
which PIPS relies: NewGen and the linear library.
Section~\ref{sec:makefiles} will then present PIPS' make file policy.
Sections~\ref{sec:library_internal_organization}
and~\ref{sec:pass_organization} are devoted to PIPS libraries and
passes. The next section briefly describes some conventions usually
respected when developing in PIPS\@. The last two sections describe
the {\em bug policy\/} of PIPS and some save and restore information.

This manual is not exhaustive. You can add your own sections and update
existing ones if you find missing or erroneous information.

The reader is supposed to be a PIPS user~\cite{Pips:96a}, and to have read
the reports about NewGen~\cite{Jouv:89,Jouv:90}. A good understanding of {\tt
  pipsmake} mechanisms would also be helpful.

\section{Shell environment (sh, ksh, bash, csh, tcsh)}
\label{sec:shell}

Many environment variables are used by PIPS executables and utilities. They
mainly describe PIPS directory hierarchy, and compilation options. All
these variables are initialized by the script
\verb+/projects/Pips/pipsrc.sh+ for \verb+sh+, \verb+ksh+ and \verb+bash+,
and by \verb+/projects/Pips/pipsrc.csh+ for \verb+csh+ and \verb+tcsh+. Both
scripts are automatically derived from a reference file \verb+pipsrc.ref+
maintained in the \verb+Scripts/env+ directory of the sources (see
Section~\ref{sec:directories} for a description of the directory hierarchy
which holds the PIPS and related softwares).

Two variables are of special interest: \verb+$PIPS_ROOT+ which stores the
root of PIPS current version, and \verb+$PIPS_ARCH+.

\subsection{PIPS architecture (\texttt{PIPS\_ARCH})}

It holds the current architecture. if not set \verb+.+ (dot) is
assumed. A PIPS
architecture is to be understood not as strictly as a computer
architecture. It simply a set of tools (compilers, linkers, but also
compiler options\ldots) to be used for compiling PIPS. Thus you can have
several pips architectures that compile and run on a very same machine.

This set of tools is defined in the corresponding
\begin{quote}
  \verb+$PIPS_ROOT/Include/makefile_macros.$PIPS_ARCH+
\end{quote}
 configuration file,
where usual \verb+CC+, \verb+CFLAGS+ and so make macros are defined.
This configuration file is automatically included by all makefiles, hence
changing this variable results in different compilers and options to be
used when compiling or running pips. Object files, libraries
and binaries related to different pips architecture cannot be mixed and
overwritten one by the other: they are stored in a subdirectory depending
on the architecture, \emph{à la} PVM. Thus pips versions are always
compiled and linked with libraries compiled for the same architecture.

Here are examples of pips architectures (distinct \verb+$PIPS_ARCH+
values) used: %%$
\begin{description}
\item[.]: default version used locally, so as to be compatible with the
 past. \verb+gcc+, \verb+flex+ and \verb+bison+ are used.
\item[DEFAULT]: default compilers and options expected to run on any
  machine (\verb+CC=cc+, and so on). The C compiler is expected to support
  ANSI features, includes and so.
\item[GNU]: prefer gnu tools, as \verb+gcc+, \verb+flex+, \verb+bison+,
  \verb+g77+.
\item[SUN4]: SUN SUNOS 4 compilers \verb+acc+,\verb+lex+, \verb+yacc+,
  \verb+f77+, etc.
\item[GNUSOL2LL]: version for SUN Solaris 2 compiled with gnu softwares and
  using ``long long'' (64 bits) integers in the mathematical computations
  of the C3/Linear library.
\item[GPROF]: a gnu version compiled with -pg (which generates a trace
  file that can be exploited by \verb+gprof+ for extracting profiling
  information)
\item[IBMAIX]: the compilers and options used on IBM AIX workstations. 
\end{description}



\section{PIPS directories}
\label{sec:directories}

This section describes the directory hierarchy of PIPS\@. 
Here at CRI, École des mines de Paris, Pips resides in
\verb+/projects/Pips+ (\verb|$PIPS_DIR|). %% $
This directory is owned by the \verb+pips+ user.
From this directory, several sub directories can be found. The most
important is the \verb+Production+ directory which contains the main copy
of Pips, including \emph{all} sources, compiled libraries and executables,
documentation, include files, and so on. In the \verb+Development+
directory you can find a development copy of the sources in which new
codes are developed. Once correct, they are installed in the main
(Production) hierarchy and will become the reference version.

The sub-directories are described below. Almost at each level,
\verb+Makefile+s ensure the coherency of the system, and facilitate the
installation of developments into the production hierarchy.

The \verb+Bin+, \verb+Share+, \verb+Runtime+ and \verb+Doc+ directories
offer a working pips \emph{running} environment.

The organisation of the Newgen (\verb+/projects/Newgen+) and C3/Linear 
(\verb+/projects/C3/Linear+) is very similar to this one.

\subsection{Production (\texttt{PIPS\_ROOT})}

This directory contains the current reference versions of library and
passes. You can find the following subdirectories:

\subsubsection{Bin}

Pips current binaries that can be executed. These binaries include
\texttt{pips} (the main program), \texttt{tpips} (the same program with a
interactive interface based on the GNU readline library) and \texttt{wpips}
(the window interface). It also includes other architecture-dependent
executables. Binaries for different architectures can be stored in
different sub-directories depending on the value of \verb+$PIPS_ARCH+ %%$
which describes the current architecture, as discussed in
Section~\ref{sec:shell}. 
    
\subsubsection{Share}

Non architecture-dependent executables needed or used by pips. They
include shell (sh and csh), sed, awk, perl and lisp scripts! Examples:
\begin{itemize}
\item  \verb+Init, Select, Perform, Display, Pips+:
  \index{Init}\index{Select}\index{Perform}\index{Display}\index{Pips}
  batch interface for PIPS; it is described in PIPS Web pages. 
  
\item \verb+epips+: a shell to launch the emacs pips interface (which
  uses \verb+wpips+ and \verb+emacs+)
  
\item \verb+stf-workspace+: \index{stf-workspace} calls Toolpack
  restructurer \verb+stf+ on each Fortran file in a workspace; also
  directly available as a PIPS transformation.
  
\item and others.
\end{itemize}

Also some configuration files, automatically generated from
the \LaTeX{} documentation in \verb+$PIPS_ROOT/Src/Documentation+. %% $
Important files are \verb+pipsmake.rc+, \verb+properties.rc+ and
\verb+wpips.rc+. 

\subsubsection{Doc}

Pips documentation, namely many postscript files describing various
aspects of PIPS, the internal data structures and so on.  Important
documents: pipsmake-rc (the dependence rules between pips interprocedural
analyses), developer\_guide (this document!), ri (the description of the
pips Intermediate Representation).

The \verb|Doc/manl| subdirectory contains local (obsolete?) man pages. 
\verb+$PIPS_ROOT/Doc+ can be added to user MANPATH variables. %%$
  
\subsubsection{Html}

Html documentation of PIPS. Some real html files, and some generated from
\LaTeX{} files.
    
\subsubsection{Runtime}

Environments needed for executing pips-compiled files.  Namely
\texttt{hpfc} and \texttt{wp65} use a PVM-based runtime and also
\texttt{xPOMP} the graphical user programming interface.  This directory
includes the files needed for executing the generated files (as header and
make files or compiled libraries), but not necessarily the corresponding
sources.

\subsubsection{Src}

PIPS Sources. Having a copy of the \verb+Src+ subtree is enough for fully
recompiling PIPS, including the documentation, configuration files and
various scripts used for running and developping the PIPS sofware.

\begin{description}
\item[Src/Documentation]:
  This directory contains the sources of the documentation of
  PIPS. From some of these are derived automatically header and
  configuration files. 
  
  The \verb+newgen+ sub-directory contains the description (in \LaTeX{})
  of the internal data structures used in the project, as they are used
  in the development and production hierarchies. 
  %%
  The local makefile transforms the \verb+*.ftex+ or \verb+*.tex+ files
  describing PIPS data structures into NewGen and header files, and
  exports them to the \verb+$PIPS_ROOT/Include+ directory. %%$
  Thus the documentation actually \emph{is} the sources for the data
  structures. 
  
  The \verb|wpips-epips-user-manual| sub-directory contains the user
  manual. 
  
  The \verb|pipsmake| sub-directory contains the definition of the
  dependences between the different interprocedural analyses as a
  \LaTeX{} file, from which are derived the \verb+pipsmake.rc+
  configuration file used by PIPS at runtime.
  
\item[Src/Passes]: This directory contains the sources of the
  different passes, in several sub-directories named from the passes
  (\verb+pips+, \verb+tpips+, \verb+wpips+). If you add a pass, it is
  mandatory that the name of the directory is the name of the pass (or
  redefine the TARGET macro in the config.makefile).
  
\item[Src/Libs]: This directory contains the source of the several
  libraries of PIPS\@.  It is divided into sub-directories named from
  the libraries. The name of the subdirectory must be the name of the
  library.
  
\item[Src/Scripts]:
  This directory contains the source of the shell scripts which are
  useful for PIPS, the linear library and NewGen. It is further
  divided into several directories. In each sub-directory a local
  \verb+Makefile+ performs automatic tasks such as the installation of
  the sources where expected (usually \verb+$PIPS_ROOT/Share+ or
  \verb+$PIPS_ROOT/Utils+, depending whether the scripts is used for
  \emph{running} or \emph{developping} PIPS.
  
\item[Src/Runtimes]: This directory contains the sources of the
  libraries used when executing codes generated by PIPS; in fact,
  there are only two libraries: The first for the HPF compiler
  \verb+hpfc+, and the second one for the WP65 project.

\end{description}

\subsubsection{Utils}

Other architecture independent tools and files used for \emph{developing}
pips (as opposed to \emph{running} it).
    
\begin{description}
\item[make-pips]: \label{make-pips}\index{make-pips} Runs {\tt gmake}
  in all the libraries and passes of PIPS, Newgen and Linear. See
  \verb+make-pips -h+ for a full description of the available options. 
  This shell-scripts simply forwards the targets specified on its
  command line to the many directories of PIPS. Since all these
  directories contain similar automatically generated makefiles, 
  one can rely on the same targets to be defined everywhere for 
  cleaning or recompiling the PIPS software.
  
  Intermediate node directories in the Pips tree contain a special 
  Makefile which just forward targets to its sub-directories or a
  subset of these. It also reports success or failures. 
  the \verb|make-pips| scripts uses this feature to perform its task.

  
\item[pips-makemake]: \index{pips-makemake}Automatic derivation of
  Makefiles. See \verb+pips-makemake -h+ for help.  
  
  This shell-script generates a makefiles which includes the local
  \verb+config.makefile+ file for additionnal macros and rules
  definitions. The generated makefile defines \emph{many} rules and
  macros. It redefines itself when the \verb|pips-makemake| script is
  updated, easing a lot the global maintainance. This very same
  shell-script is used for generating makefiles in the Pips, Newgen
  and Linear sofwares.
      
  Typical services automatically provided includes \verb|clean|,
  \verb|full-clean|, \verb|recompile| targets, generating dependence
  files, deriving automatically header files for libraries, installing
  files where needed, building local pips binaries with a local
  library and so on. It MUST be used with gmake (GNU make).
  
  It is very important that \emph{all} source directories conform to
  the use of \verb+pips-makemake+, so as to provide an homogeneous
  environment for PIPS developers all over the PIPS, Newgen and
  Linear sofwares. Thus developing in these environments is an easier
  task. 
  
  The documentation of this script is in the script. Well, it is the
  script. Without any option the script derives what to generate
  depending on the context (namelly, the current working directory),
  so that you do not need to worry about it. See examples around 
  your library for writing proper \verb+config.makefile+ files.
  Some hints are given in Section~\ref{sec:makefiles}.
      
\item[Validate]: \index{Validate} Non-regression tests; see ?!?;
  
  The arguments are names of subdirectories in
  \verb+$PIPS_ROOT/Validation+. %%$
  See \verb+Validate -h+ for some help and a list of options.
  
  Tests are organized on a library basis in \verb+Validation+
  while bugs are reported in the same way in \verb+Bugs+.  Bugs
  and non-regression tests are characterized by one or more Fortran
  programs which either core dump (for bugs) or must have a known result
  (tests).
      
  Set \verb+PIPSDBM_DEBUG_LEVEL+ to 5 to check data structures when
  they are stored and to 9 to check them when they are delivered; some
  data structures are not checked, among them, all that contain
  external types;
      
  Use \verb+accept+ to update reference files for validation; can be used
  with \verb+/usr/ucb/mail+: \verb+| xx accept+ where \verb+xx+ is the
  message number;
\end{description}


\begin{itemize}
\item \verb+bug-to-validate+: \index{bug-to-validate}When a bug is
  corrected, run \verb+bug-to-validate+ to move the bug case from
  \verb+Bugs/xxx+ to \verb+Validation/xxx+.
  
  Do not forget to update \verb+Documentation/pips-bugs.ftex+.
  
\item \verb+pips-experiment+: \index{pips-experiment}runs the same
  analyses and transformations on each module in a workspace.
  
\item \verb+print-dg-statistics+: \index{print-dg-statistics}exploits some
  of the statistics generated by the dependence graph computation when a
  specific property is set to {\tt TRUE}
  (\verb+RICE_DG_PROVIDE_STATISTICS+). 
  
\item there many other things in this directory; volunteers to write their
  documentation here are welcome!
  
\end{itemize}
    
\subsubsection{Include}

This directory contains all shared files needed for building PIPS.  It
includes C header files automatically generated from NewGen specifications
and for each library, and from some file in the documentation. Also pips
architecture configuration file that define makefile macros are there.

\subsubsection{Lib}

This directory contains PIPS compiled libraries ({\tt lib*.a}) ready
to be linked. They are stored under their \verb|$PIPS_ARCH| %% $
subdirectory.

\subsection{Development (\texttt{PIPS\_DEVEDIR})}

This directory contains the version of PIPS currently being developed. 
It is a mirror of the organization under \verb+$PIPS_ROOT/Src+. %%$
Each library is developped and tested under this subtree, linking by
default with the \emph{installed} libraries in
\verb+$PIPS_ROOT/Lib+. %%$

Thus new versions can be developed without interfering with other
developments. Once a new version of a library (or pass, or script, or
anything) is okay and validated, it is installed under the
\verb+$PIPS_ROOT/Src+ subtree and becomes the reference for all other
developers who may use its services. %%$

When developing or debugging several related libraries at the same
time, you can used the development version of these libraries by
using unix links (\texttt{ln -s}) to one of the directory under the
corresponding \verb|$PIPS_ARCH| subdirectory. When building %%$
a new binary, the linker takes these local libraries first. 

\subsection{Externals}
  
This directory contains libraries and headers external to the PIPS
software but that are used for building it. Namely, it consists of 
the GNU readline library with its headers and of malloc versions used
for debugging purposes. 

\subsection{Experiments}
  
This directory is a large piece of disk space to be used temporarily to
analyze large programs and to core dump large {\tt pips} processes; no
permanent, non-deductible information should be stored there;


\section{NewGen}
\label{sec:newgen}

NewGen is a software engineering tool, from which almost all PIPS data
structures are generated. It is described in ???. It is considered as an
external tool, and is independent from the PIPS project. However, it is
required for building pips from scratch, and the Newgen runtime library
(genC) must be linked to pips.

NewGen sources are in the directory \verb+$NEWGEN_DIR+. %% $
The global organization is similar to the PIPS organization.
(Production and Development, then under Production one can find Include,
Lib, Bin, Share, Doc\ldots). 
\verb+$NEWGEN_ROOT+ and \verb+$NEWGEN_ARCH+ refer to the current version
and architecture to be used. If \verb+$NEWGEN_ARCH+ is not defined, is
defaults to \verb+$PIPS_ARCH+ and then to \verb+.+ (dot), so that if one
develop or update Newgen as part of PIPS there is no trouble.

It may (alas!) sometimes be useful to consult them. Several
functionalities are useful when debugging: 
\begin{itemize}
  
\item \verb+gen_consistent_p()+ \index{gen\_consistent\_p}checks whether an
  existing NewGen data structure is (recursively) well formed. 
  
\item \verb+gen_defined_p()+ \index{gen\_defined\_p}checks whether an
  existing NewGen data structure is (recursively) completely defined.
  
\item \verb+gen_debug+ \index{gen\_debug}is an external variable to
  dynamically check the coherence of NewGen data structures.

  Activation:
  \begin{quote}
    \verb+ gen_debug |= GEN_DBG_CHECK;+
  \end{quote}
  Desactivation:
  \begin{quote}
    \verb+ gen_debug &= ~GEN_DBG_CHECK;+
  \end{quote}
  And when all else fails:
  \begin{quote}
    \verb+ gen_debug = GEN_TRAV_OBJ+
  \end{quote}
  
\item To print the type number of a NewGen object under \verb+dbx+ or \verb+gdb+:
  \begin{quote}
    \verb|print obj->i|
  \end{quote}
  
\item To print the name of an entity \verb+e+ (an entity is a PIPS data
  structure, see \verb+ri.f.tex+):
  \begin{quote}
    \verb|print (e+2)->s|
  \end{quote}
  
\item To print the label of a statement \verb+stmt+:
  \begin{quote}
    \verb|print ((stmt+1)->p+2)->s|
  \end{quote}
  
\item To print the domain of a NewGen Object from its number
  (\verb+obj->i+): 
  \begin{quote}
    \verb|print Domains[obj->i].name|
  \end{quote}
  
\end{itemize}

In the future, {\tt gdb} macros compatible with Newgen generated C macros
will be provided. (Well, we just need GNU people to add interactive macros
to gdb and then we will provide the macros:-)

Any way, with the Emacs debugger mode some keyboard accelerators can
be defined such as:
\begin{verbatim}
(add-hook 'gdb-mode-hook
 (function
  (lambda ()
   (gud-def gud-affiche-domain-pointe "p Domains[%e->i]" "d"
            "Display the domain (that is its type) of the NewGen object.")
   (gud-def gud-affiche-nom-entite "p (%e+2)->s" "e"
            "Display the name of an entity.")
   (gud-def gud-affiche-expression "p print_expression(%e)" "E"
            "Display an expression.")
   (gud-def gud-affiche-statement "p print_statement(%e)" "S"
            "Print a statement.")
  )
 )
)
\end{verbatim}
In such a way, typing \verb|^C ^A S| with the cursor on a variable of
type statement will ask gdb to display this statement.





\section{Linear library}
\label{sec:linear}

The linear library is also independent from PIPS. Its development was funded
by the French organization CNRS.


Its root directory is \verb+/projects/C3/Linear/+
(\verb+$LINEAR_DIR+). This directory is further divided into
similarily to Pips and Newgen.  Thus there are Production
(\verb+$LINEAR_ROOT+) and Development directories.
\verb+$LINEAR_ARCH+ (which defaults to \verb+$PIPS_ARCH+ and \verb|.|
(dot)) can be used for building the library.





\section{Makefiles}
\label{sec:makefiles}

The GNU {\tt make} utility is extensively used to ensure the coherency of
PIPS components. However, most {\tt Makefile}s are not written by hand,
but are automatically derived from configurations files called {\tt
  config.makefile}\index{config.makefile}. This automatic derivation, 
performed by the {\tt pips-makemake} utility, ensures that dependences and
installation procedures are respected. It also eases development a lot, by
providing a homogeneous environment all over the PIPS softwares.

The rationale for relying on GNU make rather than make is that in the
previous situation the software was relying heavily on SUN make special
features, thus was highly not portable. Now it is more portable, say as
much as the GNU softwares. The complex makefiles of PIPS rely on GNU
extensions such as conditionals for instance. 

{\tt make depend}\index{make!depend} must be used regularly to keep file
dependencies up-to-date. The local header file corresponding to the current
pass or library must have been created before, otherwise {\tt make depend}
selects the header file from \verb+$PIPS_ROOT/Include+, and the local header
will never be created. %% $

{\tt make test}\index{make!test}, {\tt make ttest}\index{make!ttest} and
{\tt make wtest}\index{make!wtest} generate local versions of PIPS
executables (respectively \verb+pips+, \verb+tpips+ and \verb+wpips+), to
verify that the local library or pass links properly with PIPS, linear and
NewGen, and to test the modifications.

{\tt make libxxx.a} just recompiles the local {\tt *.c} files, and creates
the local library file {\tt libxxx.a}. This is useful when making a lot of
changes to check the syntax; or when making changes in several directories
at the same time: in this case, the proper policy is to a) chose one of these
directories as the master directory, b) build the {\tt libxxx.a} in the other
directories, c) make symbolic links towards them in from the master
directory, d) and finally link in this last directory. If your pips
architecture is not \verb|.|, don't forget to link the proper libraries
in the proper sub-directory.

A typical example of {\tt config.makefile}\index{config.makefile}
file is provided in Figure~\ref{fig:config_makefile}.

\begin{figure}[p]
  \begin{center}
    \leavevmode
    \begin{verbatim}
#
# The following macros define your pass.
#
# Name of the target (default is the name of directory)
# TARGET=         parallelize
#
# Source, header and object files used to build the target
LIB_CFILES=  kennedy.c scan.c util.c dependence.c algebre.c \
                divar.c debug.c codegen.c scc.c
LIB_HEADERS= parallelize-local.h
LIB_OBJECTS= $(LIB_CFILES:.c=.o)
#
# that is all
#
\end{verbatim}
    \caption{Example of {\tt config.makefile}.}
    \label{fig:config_makefile}
  \end{center}
\end{figure} %% $


\section{Library internal organization}
\label{sec:library_internal_organization}

The source files for the library {\tt L} are in the directory {\tt
  Development/Libs/L}. 


A {\tt config.makefile}\index{config.makefile} must be created in this
directory. It can be copied from an existing library, but it must be updated
with the names of the local source and object files. Additionnal rules
compatible with the {\tt make} syntax can also be added. For local
lex and yacc files, use the \verb|$(PARSE)| and \verb|$(SCAN)| macros,
and do not forget to change the 'yy' prefixes through some sed script
to avoid name clashes when linking PIPS (which already includes several
parsers and lexers).

Running the command {\tt pips-makemake} then automatically derives from
the file {\tt config.makefile} the local {\tt Makefile}, which is fully
compatible with PIPS standards. Among others this {\tt Makefile} contains an
{\tt install} entry to install the library in the production hierarchy.
  
Great care must be taken when creating the library header file {\tt L.h}.
This file includes the local header file {\tt L-local.h} (which contains
macros, type definitions,\dots) and the external functions declared in the
local source files, which are automatically extracted using {\tt cproto}.

{\tt L.h} must never be directly modified\footnote{A warning should be added
  at the beginning.}. It is automatically generated when invoking {\tt make
  header}\index{make!header}, or when {\tt L-local.h} has been modified, but
not when the source files are modified. This avoids inopportune
recompilations when tuning the library, but can lead to coherency problems.

{\tt L.h} is automatically generated when invoking {\tt make
  install}\index{make!install}, before the actual installation in the
production hierarchy.


If a main program to test or use the library exists, then it necessarily is
a pass (see Section~\ref{sec:pass_organization}), or a main(). This rule is
generally not respected, and this induces cycles in case of a global
recompilation. (Is this up-to-date?)


\subsection{Libraries and data structures}
\label{subsec:libraries_and_data_structures}


PIPS data structures are managed by NewGen. For each data structure
declaration file in {\bf\tt Documentation/Newgen}, NewGen derives a header
file, which is placed in \verb+$PIPS_ROOT/Include+. %% $
For instance, the internal
representation (i.e. the abstract syntax tree) is called
\verb+ri+\index{ri}. It is described in the \LaTeX\ file  {\tt ri.f.tex} in
{\tt \bf Documentation/Newgen}. It is then automatically transformed into a
NewGen file {\tt ri.newgen}. And finally, NewGen produces an internal
description file {\tt ri.spec} and a header file {\tt ri.h}, which must be
included in each C file using the internal representation.

Thus, it is not possible to build a new library with the name {\tt ri},
because the corresponding header file would be called {\tt ri.h}. The
library in which higher order function concerning the {\tt ri} are placed,
is then called {\tt ri-util}. It should be the case for all the other sets
of data structures specified using NewGen. Such existing libraries are {\tt
  text-util} and {\tt paf-util}. However, mainly for historical
reasons,there are numerous exceptions. Many functions are in fact in the
library where they were first necessary. An example is the {\tt syntax}
library (the parser).



\subsection{Tags}
\label{subsec:tags}

Many macros and functions are available from the linear and NewGen
libraries, but also in PIPS. Their source code can be retrieved using the
{\em tag\/} mechanism under {\bf\tt emacs} or {\bf\tt vi}. Tags are
regularly recomputed (every hour) by the PIPS utility \verb+make-tags+.
This utility uses the environment variable \verb+PIPS_ETAGS+ which the
local {\tt etags} command, and stores the result in {\tt Pips/Tags/TAGS}.
They are made from the development source files of linear, NewGen and
PIPS. But anybody can build his/her own tag


\subsection{Library dependencies}

Library dependence cycles must be avoided. Links are not easy to manage when
a module $a$ from library $A$ calls a module $b$ form library $B$ which
itself calls a module $a'$ from library $A$. This situation also reflects a
bad logical organization of libraries. Therefore, PIPS libraries must be
organized as a DAG, i.e. they must have a partial order.


Several utilities, such as {\tt analyze\_libraries}, {\tt order\_libraries},
can be used to determine the dependences between libraries, a total order
compatible with the library partial order, and the possible cycles. The
results are stored in {\tt /tmp/libs.?} where the question mark stands for
several values:
\begin{itemize}
  \item u: uses, modules used by each library.
  \item d: defs, modules defined by each library
  \item j: join between uses and defs
  \item o: order between libraries
  \item etc...
\end{itemize}

\subsection{Installation of a new phase (or library)}


Some libraries implement functionalities which are accessible by the users
via the \verb+pipsmake+ mechanism. For a good comprehension of the material
contained in this subsection, the reader is referred to the corresponding
documentation.

A PIPS phase {\em myphase} is implemented as a C function named {\tt
  myphase} with a single argument, which is the name of the Fortran module
to analyze. It returns a boolean value, which indicates whether the
computation has performed well. It therefore resembles the following dummy
  function:
\begin{verbatim}
bool myphase(char *module_name)
{
  bool good_result_p = TRUE;

  /* some computation */
  ......
  return(good_result_p);
}
\end{verbatim}
This phase is usually located in a library named {\tt myphase}, but this is
not compulsory. It must set the global variables which are necessary for its
execution using \verb+properties+, and acquire the necessary resources by
invoking \verb+pipsdbm+. Directly invoking \verb+pipsmake+ is forbidden at
this level. 

Here are now the steps to install a new library named {\tt mylib}:
\begin{itemize}

\item Create a new directory {\tt mylib} in {\tt \$PIPS\_DEVEDIR/Lib} with
  the fiels {\tt mylib.c} (where the code for the C {\tt mylib()}, which
  corresponds to the phase to add, generally is) and  {\tt
    main.c} (with the empty function {\tt main()}).
  
\item In the directoty {\tt \$PIPS\_DEVEDIR/Lib/mylib}:
  
  \begin{itemize}
    
  \item Create a file {\tt config.makefile} (examples can be found in the
    other libraries). 
    
  \item Run the command {\tt pips-makemake} (option -l) to automatically 
    build the local {\tt Makefile} file.
    
  \item Then run the commands {\tt make libmylib.a} and {\tt make install}, to
    install the library in the {\bf \tt Production} hierarchy.  The file {\tt
      mylib.h} is installed in \verb|$PIPS_ROOT/Include|, %% $
    and {\tt mylib.a} in \verb|$PIPS_ROOT/Lib/$PIPS_ARCH|. The library
    functions are now accessible by the other libraries and passes.
    
    Notice that the local {\tt Makefile} uses the command {\tt cproto} 
    which must be installed, to automatically build the header file {\tt
    mylib.h}. To force this file to be build again, you must successively
    type {\tt touch mylib-local.h} and {\tt make header}. 
    
  \end{itemize}
  
\item In the directory {\tt \$PIPS\_DEVEDIR/Scripts/env}:
  
  \begin{itemize}
    
  \item Update the file {\tt pipsrc.ref}\index{pipsrc.ref}. It contains the
    shell environement variables for PIPS. To update it, just add the character
    string {\tt -lmylib} in the variable {\tt
      \$PIPS\_LIBS}. Notice that the order in which the libraries are added
    is importaant (l'ordre des bibliotheques est important; the new library
    must be added after the libraries which use its modules, but after the
    libraries whose modules it uses. 
    
  \item Run the {\tt make} command to automaticall build the files {\tt
    pipsrc.sh} and {\tt pipsrc.csh} respectively for {\tt sh} or {\tt ksh}
    and {\tt csh} or {\tt tcsh} shells. The command {\tt make install} then
    installs these scripts in \verb+$PIPS_UTILDIR+.
    
  \end{itemize}
  
\item In the directory {\tt \$PIPS\_DOCDIR}:
  
  \begin{itemize}
    
  \item declare the new phase to {\tt pipsmake} by adding the necessary
    rules in the file {\tt pipsmake-rc.f.tex}. Each rule describes the
    dependances between the input and output resources of each phase. Just
    have a look at hte other rules to build your owns. You can also add
    aliases to obtain nice menus in the \verb+wpips+ interface.
    
    For instance, for a phase {\em myphase} which reads a resource {\em res1}
    andproduces a resource {\em res2} for the current module, the rule and
    its alias are:

\begin{verbatim}
alias myphase 'My Phase'

myphase > MODULE.res2
        < PROGRAM.entities
        < MODULE.res1
\end{verbatim}
    
    Notice that libraries generally use the program entities, that is to say
    all the objects from the current Fortran program and which have a name.
    This resource is named {\tt PROGRAM.entities}.
    
  \item New {\em properties\/} may be necessary for the new phase. They must
    be delared in the file {\tt properties-rc.tex}.
    
  \item Run the command {\tt make all} to now derive from {\tt
      pipsmake-rc.tex} the files {\tt phases.h}, {\tt resources.h} and {\tt
      builder-map.h} and to copy them into {\tt \$PIPS\_INCLUDEDIR}; to also
    derive {\tt pipsmake.rc}, {\tt properties.rc} and {\tt wpips.rc}, and to
    copy them into {\tt \$PIPS\_LIBDIR}.
    
  \end{itemize}
  
\item In the directory {\tt \$PIPS\_BINSRCDIR}:

  Execute the command {\tt
  make-pips -r}, to recompile and install updated versions of {\tt pips},
  {\tt tpips} and {\tt wpips}.
  
\end{itemize}

It can also be necessary to update the shell scripts {\tt Init}, {\tt
  Build}, {\tt Select}, {\tt Perform}, and {\tt Display} in {\tt
  \$PIPS\_DEVEDIR/Scripts/drivers}.

This section did not deal with the case where a new resource is
introduced. This is the object of the next section.

\subsection{Dealing with a new resource}

A new resource is declared by its use or its production by one of the rules
in the file {\tt pipsmake-rc.tex} (see below). Here are now the steps to
follow to deal with a new resource {\tt myres} once the phase {\tt myphase}
from the library {\tt mylib} has been declared and installed as shown in the
previous section, that is to say that the function 
\begin{verbatim}
bool myphase(char *module_name)
\end{verbatim}
is available.

\begin{itemize}
  
\item In the directory {\tt \$PIPS\_DOCDIR}:
  
  \begin{itemize}
    
  \item Declare the new resource {\tt myres} by modifying the file {\tt
      pipsmake-rc.tex}. Each rule describes the
    dependances between the input and output resources of each phase. Just
    have a look at hte other rules to build your owns. You can also add
    aliases to obtain nice menus in the \verb+wpips+ interface.
    
    For instance, for a phase {\em myphase} which reads a resource {\tt
      another\_res} and produces a resource {\em my res} for the current
    module, the rule and its alias are:

\begin{verbatim}
alias myphase 'My Phase'

myphase > MODULE.myres
        < PROGRAM.entities
        < MODULE.another_res
\end{verbatim}
    
  \item Run the command {\tt make all} to now derive from {\tt
      pipsmake-rc.tex} the files {\tt phases.h}, {\tt resources.h} and {\tt
      builder-map.h} and to copy them into {\tt \$PIPS\_INCLUDEDIR}; to also
    derive {\tt pipsmake.rc}, {\tt properties.rc} and {\tt wpips.rc} and to
    copy them into {\tt \$PIPS\_LIBDIR}.
     
  \end{itemize}
  
\item In the directory {\tt \$PIPS\_DEVEDIR/Lib/pipsdbm}: 

  The new resource must be declared to the resource manager {\tt pipsdbm}:
  
  \begin{itemize}
    
  \item Update the file {\tt module.c} by adding the line
\begin{verbatim}
DBR_MYRES,    
\end{verbatim}
    in the array {\tt load\_order[]} which defines the order in which the
    resources must be unloaded when a module is closed (see the user manual).
    
  \item Update the file {\tt methods\_io.c} by adding the following line to
    the array {\tt method\_map[]}:
\begin{verbatim}
{DBR_MYRES,(chunk *(*)()) undefined_method, 
           undefined_method,
           undefined_method, 
           (bool (*)()) undefined_check},
\end{verbatim}
    The arguments are the reading, writing, freeing and consitency testing
    functions for the resource. Here they are undefined. But if the resource
    is a newgen type, the declaration is:
\begin{verbatim}
{DBR_MYRES, gen_read, 
            gen_write, 
            gen_free, 
            gen_consistent_p},
\end{verbatim}
    
  \item If the new resource is a file resource (and not a data structure),
    update the files {\tt disk.c} and {\tt module.c}.
    
  \item Run the commands {\tt make libpipsdbm.a} and {\tt make install}
    to update {\tt pipsdbm} and install it.
    
  \end{itemize}
  
\item In the directory {\tt \$PIPS\_BINSRCDIR}:

  Execute the command {\tt
  make-pips -r}, to recompile and install updated versions of {\tt pips},
  {\tt tpips} and {\tt wpips}.
  
\end{itemize}

\paragraph{Remark:} It is necessary to recompile PIPS before any test,
  because changing the header files generated from {\tt
  pipsmake-rc.tex} can lead to inconsistencies which only appear at run time
  (the database cannot be created for instance). 



\subsection{Modification or addition of a new NewGen data structure}

NewGen data strutures for PIPS are defined in \LaTeX{} files which are in
the directory \verb+$PIPS_DEVEDIR/Documentation/newgen+. 
These files include both the NewGen specifications, and the comments in
\LaTeX{} format. 
DDL\footnote{Newgen types are called {\em domains\/} and are defined using a
  high level specification language called DDL for {\em Domain Definition
    Language}.} files are automatically generated from the previous \LaTeX{}
files. When declaring a new data structure, two cases may arise:

\begin{enumerate}
  
\item The new data strucutre is defined in a {\em new\/} file {\tt
    mysd.ftex}:
  
  This file has to be declared in the local {\tt Makefile} (in {\tt
    \$PIPS\_DOCDIR/Newgen}) for its further installation in the {\bf\tt
    Production} hierarchy. It merely consists in adding its name {\tt
    mysd.f.tex} to the {\tt SOURCE\_FILES} list.

  Then, the macro instruction {\tt \#include "mysd.h"} must be added to the
  files 
\begin{verbatim}
$PIPS_DEVEDIR/Lib/top-level/newgen.c
$PIPS_DEVEDIR/Lib/pipsdbm/methods_io.c
\end{verbatim}
  It is not compulsory to immediately execute the command {\tt make install}
  in these directories. But it will be necessary before any global
  recompilation of PIPS (see below).
  

\item The new data structure is added to an already existing file {\tt 
    mysd.f.tex}: modifying this file is sufficient, and the above steps are
    not necessary. 
\end{enumerate}

Then, in both cases, the next steps have to be performed:
\begin{itemize}
  
\item In the directory {\tt \$PIPS\_DOCDIR/Newgen}, execute the command {\tt
    make} (which is equivalent to {\tt make
    c\_internal\_representation}). This command builds the DDL file {\tt
    mysd.newgen}, and copies it in the directory {\tt \$PIPS\_INCLUDEDIR}; then
    in this last directory, it executes the command {\tt newgen -c *.newgen}
    which builds the C header file corresponding to the DLL file. It also
    builds the {\tt specs.h} file. 

\item NewGen globally handles all the data structures defined in the
  project. Hence any minor modification of one of them, or any addition,
  potentially leads to a modification of all the interfaces which are
  generated. It is thus necessary to recompile everything in the {\bf \tt
  Production} directory. Do not forget tofirst install {\tt
  \$PIPS\_DEVEDIR/Lib/top-level} and {\tt \$PIPS\_DEVEDIR/Lib/pipsdbm} if
  they have been modified in a previous step. The command {\tt make-pips}
  achieves the global recompilation of PIPS. It is in the directory {\tt
  \$PIPS\_UTILDIR} (Cf Page~\pageref{make-pips}). 
\end{itemize}



\subsection{Changing the dynamic allocation library}

Errors which are the most difficult to find generally are dynamic allocation
errors: The allocated space is accesssed after being freed ({\em
  dangling pointer}), or a zone larger than the allocated zone is
referenced (too long copy of a character string for instance).

A first checking level is available with a set of SUN primitives ({\tt
  man malloc.h}), by linking the program with
\verb+/usr/lib/debug/malloc.o+. The choice of the dynamic allocation library
can be made in \verb+pipsrc.ref+, or in the curretn environment, but without
any guarantee for the link.

A second level, a lot more efficient, but also much slower, is offerd by a
public domain library, \verb+malloclib-pl11+. This library systematically
overwrites freed zones with a special pattern, and checks that string
operations are valid. It also records in which files allocations and
desallocations are performed.

To use it efficiently, all the source files which dynamically allocate or
free memory must include \verb+malloc.h+ with double quotes (and not $< \;
>$ signs). This is achieved in most cases because NewGen includes
\verb+malloc.h+. But some files, such as character strings manipulation
files, do not include {\tt GenC.h}: {\tt \#include "malloc.h"} must be added
to them.

PIPS must then be entirely recompiled (see \verb+make-pips+ on
Page~\pageref{make-pips}), as well as the libraries in {\tt
  \$PIPS\_EXTEDIR}, after renaming ({\tt mv}) \verb+dbmalloc.h+ into
\verb+malloc.h+ in {\tt \$PIPS\_EXTEDIR} and in the directories containing
the sources of the external libraries (NewGen and Linear). Before linking,
the environment variable \verb+PIPS_LIBS+ must have been modified, either in
the current environment, or in \verb+pipsrc.ref+, to include the correct
library. 

It is recommended to keep an version of PIPS linkeed with a reasonnably fast
library to be able to create large databases for the tests. To avoid
compiling and linking too many things each time, it is also recommended to
modify the shell variables \verb+$PIPS_BINDIR+ and \verb+$PIPS_LIBDIR+ to
keep both versions of PIPS.


\subsection{Global variables, modifications}

Global variables should be avoided, or at least carefully documented to
avoid disturbing already existing programs. 

If new functionalities are required, it is better to keep the existing
module as such, and to create a new one, with another name. 

For global variables, initialization, access and reset routines must be
provided. Do not forget that there may be several successive requests with
\verb+wpips+ or \verb+tpips+, whereas tests performs with shell interfaces
(for instance \verb+Build+) are much simpler.

\section{Organization of a PIPS pass}
\label{sec:pass_organization}


The source files for a pass {\tt p} can be found in the directory {\tt
  Development/Passes/p}. A pass, as opposed to a library, corresponds to an
  executable, which can be used by the users. 

In this directory, a local {\tt config.makefile} must be created. It must be
updated with the names of the source files. Then the local {\tt Makefile}
can be automatically derived using {\tt pips-makemake -p}. This {\tt
  Makefile} contains among others an {\tt install} entry to install the pass
in the {\bf\tt Production} hierarchy. 

The libraries used to build the pass are in the directories {\tt
  Production/Libs} and {\tt Externals}. The corresponding header files are
in {\tt Production/Include} and {\tt Externals}.

To maximize code reuse, it is recommended to limit code development at this
level to functionalities really specific to passes. Everything else should
be placed in libraries (for instance in {\tt top-level}).

At the library level, it is also possible to create local executables by
invoking {\tt make test}, {\tt make ttest} or {\tt make wtest}. 

If a pass and a library are simultaneously developed, {\tt misc} and {\tt
  parallelize} for instance, one of the library must be chosen for the link,
{\tt parallelize} for instance). It is then necessary to look for {\tt
  misc.h} and {\tt libmisc.a} in {\tt Development/Lib/misc} instead of {\tt
  Production/Libs/misc}. This can be done very simply in the
{config.makefile} file by giving the names of the libraries to use:
\begin{verbatim}
...
# List of libraries used to build the target
TARGET_LIBS=    -lprivatize -lusedef -lprettyprint -lsemantics \
                -ltransformer \
                -lcontrol -leffects -lnormalize \
                -lsc -lcontrainte -lvecteur -larithmetique \
                -lri-util ../../Libs/libmisc.a \
                -lproperties -lgenC /usr/lib/debug/malloc.o \
                -lproperties

$(TARGET): ../Lib/misc/misc.a
\end{verbatim}

\section{Conventions}
\label{sec:conventions}


libraries are named \verb|libXXX.a| where \verb|XXX| is the logical name of
the library: {\tt vecteur}, {\tt prettyprint}, {\tt misc},etc.

It is theoretically unuseful to put libraries in the Makefile dependencies,
because header files which are automatically generated are in these
dependencies, and are systematically modified each time an installation is
performed. However, this does not work if the pass {\tt p} calls the library
{\tt a} which needs the library {\tt b}, and if {\tt p} does not directly
needs the library {\tt b}: modifications to {\tt b} will not provoke the
link of {\tt p}. 

Each important library uses an environment variable \verb+XXX_DEBUG_LEVEL+
to control debugging messages. This rule hase an exception:
\verb+PARSER_DEBUG_LEVEL+ corresponds to the \verb+syntax+ library .

Level 0 corresponds to the normal behaviour.
The highest level is 8. Great care has to be brought to calls to
\verb+debug_on()+ and \verb+debug_off()+, because successive debug levels
are stored in a stack, and it could disturb its coherency. The debug of a
function of another library should not unconsciously be activated.  

\section{Bug policy}
\label{sec:bugs}

\subsection{Bug detection}

When a bug has been detected, a small Fortran program  ({\tt bug.f} for
instance) must be written to reproduce the bug. 

If the library {\tt xxx} is responsible for this bug, move bug.f in {\tt
  Tests/Bugs/xxx/}. This responsibility can be found using
\verb+XXX_DEBUG_LEVEL+ or a debugging tool.

Then record the new bug in {\tt \$PIPS\_DOCDIR/pips-bugs.f.tex}.

\subsection{Bug correction}

Go to the directory {\tt /Tests/Bugs/xxx}. In order to use the executable
of the library {\tt xxx}, create a symbolic link towards it ({\tt ln -s
  Development/Lib/xxx/pips} for instance).  Here are now the different steps
to perform:

\begin{itemize}
\item Find the sources responsible for the bugs and correct them (we assume
  that only one library is responsible for the bug; the case of multiple
  libraries is presented below). 

\item Run \verb+make test+ in {\tt Development/Lib/xxx} to build an executable.

\item Back in {\tt Tests/Bugs/xxx}, run:
\begin{verbatim}
Init -f bug.f bug
Display -m -v bug
\end{verbatim}
and verify that the bug has been eliminated.

\item In {\tt Development/Lib/xxx/}:
  \begin{itemize}
  \item Launch \verb+Validate Xxx+ to run the non regression tests specific
    to the library {\tt xxx}.
    
  \item Run \verb+Validate+ if the changes may affect the results in several
    phases.
    
  \item If the results are satisfactory, run \verb+make install+ to install
    the new sources in the {\bf\tt Production} hierarchy. Beware that this
    does not build new executables in {\tt \$PIPS\_BINDIR}. This can be done
    with the {\tt make-pips} command, but this is not compulsory, because
    this command is automatically run each night.
  \item 
  \end{itemize}
\end{itemize}

Once these operations have been done, the program {\tt bug.f} and the
results obtained for its parallelization must be added
to the non-regresson tests in the directory {\tt /Tests/Validation/Xxx}.
For that purpose, you can run the command \verb+bug-to-validate bug.f+.
But beware that this command is a script shell which provides a mere
parallelization of {\tt bug.f}. To transfer all the programs from the
directory {\tt Tests/Bugs/xxx} to {\tt /Tests/Validation/Xxx}, you can use the
command \verb+dir-to-validate+. Again, this is very convenient when the
desired test is the default test (see
Section~\ref{subsec:the_validation_directory}). 

\paragraph{Remark:} When several libraries are responsible for the bug, say
{\tt xxx1},\dots, {\tt xxxk}, chose one of the libraries to build the
executable by linking with the other libraries. Once the problems are fixed,
do not forget to run {\tt make install} in all the libraries.

\subsection{The {\bf \tt Validation} directories}
\label{subsec:the_validation_directory}

These directories {\tt /Tests/Validation/Xxx} contain the non-regression
tests for each significant library {\tt xxx}, as well as demonstration
programs, benchmarks, \dots.

For each Fortran file \verb+bug.f+, there exists a test file
\verb+bug.test+, and a sub-directory \verb+bug.result+ in which the results
are stored in a \verb+test+ file. All these files can be generated by
\verb+bug-to-validate bug.f+ when dealing with a bug in {\tt
  Tests/Bugs/xxx}. If this command has been used, the reuslt directory
contains the results of a mere parallelization. For more complex results,
a specific test file must be written, as well as a script inspired from
\verb+bug-to-validate+ to install the necessary files in the validation
directory. 

If the same test file is valid for a whole directory (ex : {\tt
  Validation/Flint}), a generic file \verb+default_test+ can be created in
this directory. In this file, the generic names for the program are
\verb+tested_file+ and \verb+TESTED_FILE+. Here is the {\tt default\_test}
script of \verb+Validation/Flint+:
\begin{verbatim}
#!/bin/sh
Init -d -f $PIPSDIR/Tests/Validation/Flint/tested_file.f \
           tested_file 2>/dev/null >/dev/null
Perform -m tested_file flinter 2>/dev/null 
cat tested_file.database/TESTED_FILE.flinted 
Delete tested_file 2>/dev/null
\end{verbatim}
Notice that if there exists a local test for the file ({\tt bug.test}), it
will be used first. The priority starts from local files to general ones. 

\subsection{Other validation}

The command \verb+Validate+ can be used to measure the impact of a
modification by comparing the new behavior of PIPS with the preceding one. 

To use it to check the parallelization process, put your test file, say
{\tt mytest.f} which contains the main program MAIN and a subroutine SUB, into
one of the directories in
\verb+~pips/Pips/Tests/Validation+ directory. You can also create your own
directory there if you want to ensure that a particular aspect of PIPS
behaves the correct way.

Once {\tt mytest.f} is in such a directory, say {\tt kludge}, you should do
the following thing.
\begin{verbatim}
Validation/kludge: Init -f mytest.f mytest
Validation/kludge: mkdir mytest.result
Validation/kludge: Display -m main > mytest.result/MAIN
Validation/kludge: Display -m sub > mytest.result/SUB
Validation/kludge: Delete mytest
\end{verbatim}

Check that the output in the MODULE1, MODULE2, ... files is what you
want ... and that's it!

After a while, if you want to check that PIPS still does that it was
supposed to do, go into Validation and type

\begin{verbatim}
Validate kludge
\end{verbatim}

If there is any problem, you will get a mail message that tells you want the
problem is. You can also type {\tt Validate} to check everything.

\begin{itemize}
\item \verb+Validate+ with no argument validates all the directories which
  are listed in
  the file {\tt Validation/defaults}.
  
\item When a directory of {\tt Validation} is validated, if for the program
  {\tt foo.f} there exists a file {\tt foo.test} it is executed; otherwise
  {\tt default\_test} is ran. The output is compared to {\tt foo.result/test}
  which must have been created before. The result can be as complex as
  desired, and not a mere parallelized version.

\item {\tt tpips} scripts can also be used. In this case, do not forget to
  build a local {\tt tpips} by invoking {\tt make ttest} after creating your
  local {\tt pips}.
\end{itemize}



\section{Miscellaneous}
\label{sec:misc}

To print a nice version of PIPS output, you can use \verb+tgrind+:
\begin{verbatim}
tgrind -lf extr_doall.f
\end{verbatim}


It is highly recommended to use the Emacs editor to benefit from the tags
which are updated every hour.

\newpage


{\small
\bibliographystyle{plain}
\bibliography{developer_guide}
}

\input{developer_guide.ind}

\end{document}
\end
