% PIPS Project
%
% $RCSfile: properties-rc.tex,v $ ($Date: 1995/09/08 18:17:53 $, )
% version $Revision$
% got on %D%, %T%
% $Id$
%
% Description des enchainements possibles des passes et analyses de PIPS
% pour properties
%
% Derivation rules and aliases must be included in verbatim environments. 
% Nothing else should appear in a verbatim environment.
% 
% Modifications

\batchmode
\documentstyle[11pt]{article}
\title{Properties \\
    Low Level Tuning of PIPS}
\author{Lei Zhou\thanks{E-mail: {\tt zhou@ensmp.fr}} \hspace{2cm} 
        Fran\c{c}ois Irigoin\thanks{E-mail: {\tt irigoin@ensmp.fr}} \vspace{1cm}\\
        Centre de Recherche en Informatique \\
        Ecole des Mines de Paris \\
        77305 Fontainebleau Cedex \\
        France \\}
\date{\today (Initial version: October 1991)}

\addtolength{\textwidth}{72pt}
\addtolength{\oddsidemargin}{-48pt}
\addtolength{\evensidemargin}{-48pt}
\addtolength{\textheight}{172pt}
\addtolength{\topmargin}{-60pt}

\begin{document}
\thispagestyle{empty}

\maketitle

% \begin{abstract}
% \end{abstract}

\section*{Introduction}

This paper describes global variables used to modify or fine tune PIPS
behavior. Since global variables are useful for some purposes, but
always dangerous, PIPS programmers are required to declare them
explictly as {\em properties}. Properties have an ASCII name and can
have boolean, integer or string values.

% The information here is machine and/or site independent.

Casual users should not use them. Properties are modified for them by
the user interface and/or the high-level functions.

Experimented users can modify properties by inserting a file called
\verb+properties.rc+ in their local directory. Of course, they cannot
declare new properties, since they would not be recognized by the PIPS
system. The local property file is read {\em after} the default property
file, \verb+Production/Lib/properties.rc+. Some user-specified property
values may be ignored because it is modified by a PIPS function before
it had a chance to have any effect. Unfortunately, there is no explicit
indication of usefulness for the properties in this report.

The default property file can be used to generate a custom version of
properties.rc. It is derived automatically from
\verb+Documentation/properties-rc.tex+.

Properties are listed on a source library basis, except for general
properties..

\section{Global Options}

Are DO loops bodies executed at least once (F-66 style), or not (Fortran~77)?
This is useful for use/def and semantics analysis.

\begin{verbatim}
ONE_TRIP_DO FALSE
\end{verbatim}

Shall we print phase timings

\begin{verbatim}
LOG_TIMINGS FALSE
\end{verbatim}

\section{Pipsmake}

Shall we log and report differences between resource read/write and
which are not declared to pipsmake

\begin{verbatim}
CHECK_RESOURCE_USAGE FALSE
\end{verbatim}

The rule activation process may delete from the database all the
derived resources from the newly activated rule

\begin{verbatim}
ACTIVATE_DEL_DERIVED_RES TRUE
\end{verbatim}


\section{Chains}

Update dependency graph with RR dependency arcs.
Useful for estimation of cache memory traffic. use/def related.

\begin{verbatim}
KEEP_READ_READ_DEPENDENCE FALSE
\end{verbatim}

Do we want to mask effects in loop bodies (dangerous with current
version of Allen \& Kennedy which assumes that all the edges are
present, the ones on private variables being eventually discarded
but with a current distribution)

\begin{verbatim}
CHAINS_MASK_EFFECTS FALSE
\end{verbatim}

Do we only keep dataflow (Def -- Use) dependences in the chain graph.

\begin{verbatim}
CHAINS_DATAFLOW_DEPENDENCE_ONLY FALSE
\end{verbatim}

\section{Prettyprinter Options}

Added for homogeneity reason; could be (easily) reduced to one?  In
fact, with many target machines in mind, we should have an integer flag
``architecture'', with two basic architectures, sequential and parallel.
Useless values: re-initialized in the C code.

\begin{verbatim}
PRETTYPRINT_PARALLEL FALSE

PRETTYPRINT_SEQUENTIAL TRUE
\end{verbatim}

Print parallel DO loops using FORTRAN 90 syntax. Useless value:
re-initialized in the C code.

\begin{verbatim}
PRETTYPRINT_FORTRAN90 FALSE
\end{verbatim}

Adds Cray (FMP + CFT77) compatible directives for parallelization.
Useless value: re-initialized in the C code.

\begin{verbatim}
PRETTYPRINT_CRAY FALSE
\end{verbatim}

Adds Connection Machine Fortran prettyprint.

\begin{verbatim}
PRETTYPRINT_CMFORTRAN FALSE
\end{verbatim}

Adds Cray-T3D CRAFT Fortran prettyprint.

\begin{verbatim}
PRETTYPRINT_CRAFT FALSE
\end{verbatim}

Add statement effects as comments in output; not implemented (that way) yet.

\begin{verbatim}
PRETTYPRINT_EFFECTS FALSE
\end{verbatim}

Transform DOALL loops into sequential loops with an opposed increment
not implemented

\begin{verbatim}
PRETTYPRINT_REVERSE_DOALL FALSE
\end{verbatim}

Print statement transformers as comments in code.

\begin{verbatim}
PRETTYPRINT_TRANSFORMER FALSE
\end{verbatim}

Print statement preconditions as comments in code.

\begin{verbatim}
PRETTYPRINT_EXECUTION_CONTEXT FALSE
\end{verbatim}

Print statement regions as comments in code.

\begin{verbatim}
PRETTYPRINT_REGION FALSE
\end{verbatim}

Print regions of scalars.

\begin{verbatim}
PRETTYPRINT_SCALAR_REGIONS FALSE
\end{verbatim}

Print statement blocks

\begin{verbatim}
PRETTYPRINT_BLOCKS FALSE
\end{verbatim}

Print unstructured blocks

\begin{verbatim}
PRETTYPRINT_UNSTRUCTURED FALSE
\end{verbatim}

Print all effects for all statements regardless of PRETTYPRINT\_BLOCKS
and PRETTYPRINT\_UNSTRUCTURED

\begin{verbatim}
PRETTYPRINT_ALL_EFFECTS FALSE
\end{verbatim}

Print empty statement blocks

\begin{verbatim}
PRETTYPRINT_EMPTY_BLOCKS FALSE
\end{verbatim}

Print statement ordering information

\begin{verbatim}
PRETTYPRINT_STATEMENT_ORDERING FALSE
\end{verbatim}

Print code with DO label and CONTINUE instead of DO-ENDDO. If FALSE, all
useless CONTINUE statements are NOT prettyprinted (ie. all those in
structured parts of the code). Warning: case TRUE, generated code may be
wrong after some code transformations like distribution...

\begin{verbatim}
PRETTYPRINT_ALL_LABELS FALSE
\end{verbatim}

Print code with DO label as comment.

\begin{verbatim}
PRETTYPRINT_DO_LABEL_AS_COMMENT FALSE
\end{verbatim}

Print private variables without regard for their use

\begin{verbatim}
PRETTYPRINT_ALL_PRIVATE_VARIABLES FALSE
\end{verbatim}


Print all the declarations even if it's not declared in the original program.
Added by LZ 22/10/91

\begin{verbatim}
PRETTYPRINT_ALL_DECLARATIONS FALSE
\end{verbatim}

Manage internal RETURNs correctly if set to TRUE.  This results in a
slightly ugly (but correct) prettyprint, compared to a nicer (but
possibly incorrect) default one.

\begin{verbatim}
PRETTYPRINT_INTERNAL_RETURN TRUE
\end{verbatim}

Print transformers, preconditions and regions in a format acceptd by Foresys and
Partita. 

\begin{verbatim}
PRETTYPRINT_FOR_FORESYS FALSE
\end{verbatim}

Whether to regenerate the commons in the declarations or not.

\begin{verbatim}
PRETTYPRINT_COMMONS TRUE
\end{verbatim}

To deal specifically with the prettyprint for hpfc

\begin{verbatim}
PRETTYPRINT_HPFC FALSE
\end{verbatim}

To output a code with a hierarchical view of the control graph with
markers instead of a flat one. It purposes a display with a graph
browser such as daVinci:
\begin{verbatim}
PRETTYPRINT_UNSTRUCTURED_AS_A_GRAPH FALSE
\end{verbatim}
and to have a decorated output with the hexadecimal adresses of the
control nodes:
\begin{verbatim}
PRETTYPRINT_UNSTRUCTURED_AS_A_GRAPH_VERBOSE FALSE
\end{verbatim}

\section{Semantic Analysis}

Perform ``meet'' operations for semantics analysis.

\begin{verbatim}
SEMANTICS_FLOW_SENSITIVE FALSE
\end{verbatim}

To be refined later; basically, use callee\'s transformers instead of
callee\'s effects when computing transformers bottom-up in the call graph;
when going top-down with preconditions, should we care about unique
call site and/or perform meet operation on call site preconditions ?

\begin{verbatim}
SEMANTICS_INTERPROCEDURAL FALSE
\end{verbatim}

Go all the Halbwachs way, compute inequalities instead of sticking
to equalities; implies SEMANTICS\_FIX\_POINT and SEMANTICS\_FLOW\_SENSITIVE.

\begin{verbatim}
SEMANTICS_INEQUALITY_INVARIANT FALSE
\end{verbatim}

CPU time and memory space are cheap: compute loop fixpoint for
transformers and preconditions; this implies SEMANTICS\_FLOW\_SENSITIVE.

\begin{verbatim}
SEMANTICS_FIX_POINT FALSE
\end{verbatim}

Output semantics results on stdout

\begin{verbatim}
SEMANTICS_STDOUT FALSE
\end{verbatim}

Debug level for semantics

\begin{verbatim}
SEMANTICS_DEBUG_LEVEL 0
\end{verbatim}

\section{Dependence Test (Ricedg)}

% Module code and list of called module names.

\subsection{Dependence Test Selection}

This property seems to be now obsolete. The dependence test choice is
now controlled directly and only by rules in pipsmake.rc.

\begin{verbatim}
DEPENDENCE_TEST "full"
\end{verbatim}

\subsection{Statistics}

Provide the following counts during the dependence test. There are three
parts: numbers of dependencies and independences (fields 1-10),
dimensions of referenced arrays and dependence natures (fields 11-25)
and the same information for constant dependencies (fields 26-40),
decomposition of the dependence test in elementary steps (fields 41-49),
use and complexity of Fourier-Motzkin's pair-wise elimination (fields
50, 51 and 52-68).

\begin{itemize}

  \item[1] array reference pairs, i.e. number of tests effected
    (used to be the number of use-def, def-use and def-def pairs on arrays);

  \item[2] number of independences found (on array reference pairs);

    {\bf Note:} field 1 minus field 2 is the number of array
    dependencies. 

  \item[3] numbers of loop independent dependences between references
    in the  same statement (not useful for program transformation
    and parallelization if statements are preserved); it should
    be subtracted from field 2 to compare results with other
    parallelizers;

  \item[4] numbers of constant dependences; 

  \item[5] numbers of exact dependences;

    {\bf Note:} field 5 must be greater or equal to field 4.

  \item[6] numbers of inexact dependences involved only by the 
           elimination of equation;
  \item[7] numbers of inexact dependences involved only by the F-M
           elimination;
  \item[8] numbers of inexact dependences involved by both elimination of
           equation and F-M elimination; 

    {\bf Note:} the sum of fields 5 to 8 and field 2 equals field 1

  \item[9] number of dependences among scalar variables;
  \item[10] numbers of dependences among loop index variables;
  \item[11-40] dependence types detail table with the dimensions [5][3]
               and constant dependence detail table with the
               dimensions [5][3]; the first index is the array dimension
    (from 0 to 4 - no larger arrays has ever been found); the
    second index is the dependence nature (1: d-u, 2: u-d, 3: d-d);
    both arrays are flatten according to C rule  as 5 sequences of
    3 natures;

    {\bf Note:} the sum of fields 11 to 25 should be equal to
    the sum of field 9 and 2 minus field 1.

    {\bf Note:} the fields 26 to 40 must be less than or equal to
    the corresponding fields 11 to 25

  \item[41] numbers of independences found by the test of constant;
  \item[42] numbers of independences found by the GCD test;
  \item[43] numbers of independences found by the normalize test;
  \item[44] numbers of independences found by the lexico-positive test
             for constant Di variables;
  \item[45] numbers of independences found during the projetion on Di
            variables by the elimination of equation;
  \item[46] numbers of independences found during the projetion on Di
            variables by the Fourier-Motzkin's elimination;
  \item[47] numbers of independences found during the test of
            faisability of  Di sub-system by the elimination of equation;
  \item[48] numbers of independences found during the test of
            faisability of Di sous-system by the Fourier-Motzkin's
            elimination; 
  \item[49] numbers of independences found by the test of lexico-positive
            for Di sub-system; 

    {\bf Note:} the sum of fields 41 to 49 equals field 2

  \item[50] total number of Fourier-Motzkin's pair-wise eliminations
     used; 
  \item[51] number of Fourier-Motzkin's pair-wise elimination 
    in which the system size doesn't augment after the elimination;
  \item[52-68] complexity counter table of dimension [17]. The
               complexity of one projection by F-M is the product of the
               number of positive inequalities and the number of negatives
               inequalities that contain the eliminated variable. This
    is an histogram of the products. Products which are less than 
    or equal to 4
    imply that the total number of inequalities does not increase.
    So if no larger product exists, field 50 and 51 must be equal.
\end{itemize}

The results are stored in the currentworkspace in MODULE.resulttestfast,
MODULE.resultesttestfull, or MODULE.resulttestseman according to the
test selected.

\begin{verbatim}
RICEDG_PROVIDE_STATISTICS FALSE
\end{verbatim}

Provide the statistics above and counte all array reference pairs
including these involved in call statement.

\begin{verbatim}
RICEDG_STATISTICS_ALL_ARRAYS FALSE
\end{verbatim}

\subsection{Algorithmic Dependences}

Only take into account true flow dependences (Def -- Use) during the
computation of SCC?  Note that this is different from the
CHAINS\_DATAFLOW\_DEPENDENCE\_ONLY option which doesn't compute the
whole graph.  Warning: this option potentially yields incorrect parallel
code.

\begin{verbatim}
RICE_DATAFLOW_DEPENDENCE_ONLY FALSE
\end{verbatim}

\subsection{Printout}

To print the dependence graph in a file called {\em module\_name}.{\tt dg}

\begin{verbatim}
PRINT_DEPENDENCE_GRAPH FALSE
\end{verbatim}

To print the dependence graph without the dependences on privatized
variables 

\begin{verbatim}
PRINT_DEPENDENCE_GRAPH_WITHOUT_PRIVATIZED_DEPS FALSE
\end{verbatim}

To print the dependence graph without the no loop carried dependences
 
\begin{verbatim}
PRINT_DEPENDENCE_GRAPH_WITHOUT_NOLOOPCARRIED_DEPS FALSE
\end{verbatim}

\subsection{Optimization}

The default option is to compute the dependence graph only for loops
which can be parallelized using Allen \& Kennedy algorithm.
However it is possible to
compute the dependences in any case even for loop containing test, goto,
etc...
by setting this option to TRUE.

\begin{verbatim}
COMPUTE_ALL_DEPENDENCES FALSE
\end{verbatim}

\section{Effects}

print SDFI just after computation

\begin{verbatim}
EFFECTS_PRINT_SDFI TRUE
\end{verbatim}

\section{Regions}

if {\tt MUST\_REGIONS} is true, then it computes regions using the
algorithm described in report E/181/CRI, called {\em $T^{-1}$
algorithm}. It provides more accurate regions, and preserve MUST
approximations more often. But it is less efficient. Its default value
is FALSE. EXACT\_REGIONS is true for the moment for backward
compatibility only.

\begin{verbatim}
EXACT_REGIONS TRUE
\end{verbatim}

\begin{verbatim}
MUST_REGIONS FALSE
\end{verbatim}

The default option is to compute regions without taking into account array
bounds. Both options have their advantages and drawbacks. 

\begin{verbatim}
REGIONS_WITH_ARRAY_BOUNDS FALSE
\end{verbatim}

I intend to compute disjunctions of regions. As I have already prepared basic
operators for that purpose, I created two properties to switch between regions
and disjuctions of regions. For the moment, they are always false.

\begin{verbatim}
DISJUNCT_REGIONS FALSE
\end{verbatim}

\begin{verbatim}
DISJUNCT_IN_OUT_REGIONS FALSE
\end{verbatim}


\begin{verbatim}
REGIONS_OP_STATISTICS FALSE
\end{verbatim}


\section{Static Complexity Evaluation}

The following properties control the static estimation of dynamic code
execution time.

\subsection{Debugging}

Trace the walk across a module's internal representation:

\begin{verbatim}
COMPLEXITY_TRACE_CALLS FALSE
\end{verbatim}

Trace all intermediate complexities:

\begin{verbatim}
COMPLEXITY_INTERMEDIATES FALSE
\end{verbatim}

Print the complete cost table at the beginning of the execution:

\begin{verbatim}
COMPLEXITY_PRINT_COST_TABLE FALSE
\end{verbatim}

The cost table(s) contain machine and compiler dependent information
about basic execution times, e.g. time for a load or a store.

\subsection{Fine Tuning}

It is possible to specify a list of variables which must remain
litterally in the complexity formula, although their numerical values
are known (this is OK) or although they have multiple unkown and
unrelated values during any execution (this leads to an incorrect
result).

Formal parameters and imported global variables are left unevaluated.

They have relatively high priority (FI: I do not understand this comment
by Lei).

This list should be empty by default (but is not for unknown historical
reasons):

\begin{verbatim}
COMPLEXITY_PARAMETERS "IMAX LOOP"
\end{verbatim}

Controls the printing of {\em accuracy} statistics:

\begin{itemize}

  \item 0: do not prettyprint any statistics with complexities (to give
the user a false sense of accuracy and/or to avoid clutering his/her
display); this is the default value;

  \item 1: prettyprint statistics only for loop/block/test/unstr.
statements and not for basic statements, since they should not cause
accuracy problems;

  \item 2 : prettyprint statistics for all statements

\end{itemize}

\begin{verbatim}
COMPLEXITY_PRINT_STATISTICS 0
\end{verbatim}

\subsection{Target Machine and Compiler Selection}

This property is used to select a set of basic execution times. These
times depend on the target machine, the compiler and the compilation
options used. It is shown in \cite{Z94} that fixed basic times can be
used to obtain accurate execution times, if enough basic times are
considered, and if the target machine has a simple RISC processor. For
instance, it is not possible to use only one time for a register
load. It is necessary to take into account the nature of the variable,
i.e. formal parameter, dynamic variable, global variable, and the nature
of the access, e.g. the dimension of an accessed array. The cache can be
ignored an replacer by an average hit ratio.

Different set of elementary cost tables are available:

\begin{itemize}

  \item \verb+all_1+: each basic operation cost is 1;

  \item \verb+fp_1+: only floating point operations are taken into
account and have cost unit 1; all other operations have a null cost.

\end{itemize}

In the future, we might add a sparc-2 table...

The different elementary table names are defined in
\verb+complexity-local.h+. They presently are \verb+operation+, 
\verb+memory+, \verb+index+, \verb+transcend+
and \verb+trigo+.

The different tables required are to be found in
\verb+$LIBDIR/complexity/xyz+,
where \verb+xyz+ is specified by this property:

\begin{verbatim}
COMPLEXITY_COST_TABLE "all_1"
\end{verbatim}

\subsection{Evaluation Strategy}

For the moment, we have designed two ways to to solve the complexity
combination problem.Since symbolic complexity formulae use program
variable it is necessary to specify in which store they are
evaluated. If two complexity formulae are computed relatively to two
different stores, they cannot be directly added.

First approach, which is implemented, uses the module initial store as
universal store for all formulae (but possibly for the complexity of
elementary statements).
In some way, symbolic variable are evaluated as early as possible as
soon as it is known that they won't make it in the module summary
complexity.

This first method is easy to implement when the preconditions are available
but it has at least two drawbacks:

\begin{itemize}

  \item if a variable is used in different places with the same unknown
value, each occurence will be replaced by a different unknown value
symbol (the infamous \verb+UU_xx+ symbols in formulae).

  \item since variables are replaced by numerical values as soon as
possible as early as possible, the user is shown a numerical execution
time instead of a symbolic formulae which would likely be more useful
(see property \verb+COMPLEXITY_PARAMETERS+). This is especially true
with interprocedural constant propagation.

\end{itemize}


\begin{verbatim}
COMPLEXITY_EARLY_EVALUATION TRUE
\end{verbatim}

\section{Top level control}

Print a log of the session

\begin{verbatim}
USER_LOG_P      TRUE
\end{verbatim}

What to do on user errors: go ahead (default) or core dump (debug)

\begin{verbatim}
ABORT_ON_USER_ERROR     FALSE
\end{verbatim}

\section{Call Graph}
This section is used to see the calling relations of callees.
In this section,
we use the datebase to get the graph. It is different with icfg.
ex: if A calls B twice, in callgraph, we only have ONCE A calls B;
while in icfg, we have twice B called by A.
So there is no option on the so-called callgraph except the debugging.

debugging level (should be \verb+CALLGRAPH_DEBUG_LEVEL+ and numeric!)

\begin{verbatim}
CALLGRAPH_DEBUG FALSE
\end{verbatim}

\section{Interprocedural Control Flow Graph}
This section is NOT identical to that of Callgraph. 
We use the different schemes to get the results.
We get the calling relations by the declaration, it should be correct.
But there are bugs somewhere.

print controlling IF's

\begin{verbatim}
ICFG_IFs FALSE
\end{verbatim}

print enclosing DO loops

\begin{verbatim}
ICFG_DOs FALSE
\end{verbatim}

to be destroyed

\begin{verbatim}
ICFG_CALLEES_TOPO_SORT FALSE
\end{verbatim}

\begin{verbatim}
ICFG_DECOR 0
\end{verbatim}

\begin{verbatim}
ICFG_DRAW TRUE
\end{verbatim}

Debugging level (should be \verb+ICFG_DEBUG_LEVEL+ and numeric instead
of boolean!):

\begin{verbatim}
ICFG_DEBUG FALSE
\end{verbatim}

\section{Rice (Parallelization)}

TRUE to show all parallel loops, FALSE to generate real (vector,
innermost parallel?) code

\begin{verbatim}
GENERATE_NESTED_PARALLEL_LOOPS TRUE
\end{verbatim}

\section{wp65 (PUMA project)}

\begin{verbatim}
WP65_DEBUG_LEVEL        0
\end{verbatim}

\section{Partial Atomizer}

This transformation only atomizes indirect references of array access functions.


\begin{verbatim}
ATOMIZE_INDIRECT_REF_ONLY FALSE
\end{verbatim}

\section{Distribution}

Partial distribution distributes the statements of a loop nest except
 the isolated statements,that have no dependences at the common level l,
 are gathered in the same l-th loop.

\begin{verbatim}
PARTIAL_DISTRIBUTION FALSE
\end{verbatim}

\section{HPFC {\em High Performance Fortran Compiler}}

debugging levels considered by HPFC: 
{\tt HPFC\_\{,IO,REMAPPING\}\_DEBUG\_LEVEL}.

  These booleans decide whether some computations are directly
generated in the output code, or computed thru calls to dedicated
runtime functions. The default is the direct expansion.

\begin{verbatim}
HPFC_EXPAND_COMPUTE_LOCAL_INDEX TRUE
HPFC_EXPAND_COMPUTE_COMPUTER TRUE
HPFC_EXPAND_COMPUTE_OWNER TRUE
HPFC_EXPAND_CMPLID TRUE
HPFC_NO_WARNING FALSE
NO_USER_WARNING FALSE
\end{verbatim}

   Hacks control\ldots

\begin{verbatim}
HPFC_FILTER_CALLEES FALSE
GLOBAL_EFFECTS_TRANSLATION TRUE
\end{verbatim}

  These booleans control the I/O generation.

\begin{verbatim}
HPFC_SYNCHRONIZE_IO FALSE
HPFC_IGNORE_MAY_IN_IO FALSE
\end{verbatim}

  Whether to use lazy or non-lazy communications

\begin{verbatim}
HPFC_LAZY_MESSAGES TRUE
\end{verbatim}

Whether to ignore FCD (Fabien Coelho Directives\ldots) or not. These
directives are used to instrument the code for testing purposes.

\begin{verbatim}
HPFC_IGNORE_FCD_SYNCHRO FALSE
HPFC_IGNORE_FCD_TIME FALSE
\end{verbatim}

Whether to measure and display the compilation times for remappings

\begin{verbatim}
HPFC_TIME_REMAPPINGS TRUE
\end{verbatim}

\section*{Conclusion}

Do not be surprised by strange results obtained after selecting a
property yourself!

\begin{thebibliography}{99}

\bibitem{Z94} Lei Zhou,
{\em Analyse statique et dynamique de la compl\'exite' des programmes
scientifiques}, 
Th\`ese de doctorat de l'universit\'e Pierre et Marie Curie, 14
septembre 1994. Technical Report A/255.

\end{thebibliography}

\end{document}
