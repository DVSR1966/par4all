% PIPS Project
%
% $RCSfile: properties-rc.tex,v $ ($Date: 1996/02/16 08:49:44 $, )
% version $Revision$
% got on %D%, %T%
% $Id$
%
% Description des enchainements possibles des passes et analyses de PIPS
% pour properties
%
% Derivation rules and aliases must be included in verbatim environments. 
% Nothing else should appear in a verbatim environment.
% 
% Modifications

\batchmode
\documentstyle[11pt,html]{article}
\title{Properties \\
    Low Level Tuning of PIPS}
\author{Lei Zhou \hspace{2cm} 
        Fran\c{c}ois Irigoin\thanks{E-mail: {\tt irigoin@ensmp.fr}} \vspace{1cm}\\
        Centre de Recherche en Informatique \\
        Ecole des Mines de Paris \\
        77305 Fontainebleau Cedex \\
        France \\}
\date{\today (Initial version: October 1991)}

\addtolength{\textwidth}{72pt}
\addtolength{\oddsidemargin}{-48pt}
\addtolength{\evensidemargin}{-48pt}
\addtolength{\textheight}{172pt}
\addtolength{\topmargin}{-60pt}

\begin{document}
\thispagestyle{empty}

\maketitle

% \begin{abstract}
% \end{abstract}

\section*{Introduction}

This paper describes global variables used to modify or fine tune PIPS
behavior. Since global variables are useful for some purposes, but
always dangerous, PIPS programmers are required to declare them
explictly as {\em properties}. Properties have an ASCII name and can
have boolean, integer or string values.

% The information here is machine and/or site independent.

Casual users should not use them. Properties are modified for them by
the user interface and/or the high-level functions.

Experimented users can modify properties by inserting a file called
\verb+properties.rc+ in their local directory. Of course, they cannot
declare new properties, since they would not be recognized by the PIPS
system. The local property file is read {\em after} the default property
file, \verb+Production/Lib/properties.rc+. Some user-specified property
values may be ignored because it is modified by a PIPS function before
it had a chance to have any effect. Unfortunately, there is no explicit
indication of usefulness for the properties in this report.

The default property file can be used to generate a custom version of
properties.rc. It is derived automatically from
\verb+Documentation/properties-rc.tex+.

PIPS behavior can also be altered by Shell environment variables. Their
generic names is \verb+XXXX_DEBUG_LEVEL+, where \verb+XXXX+ is a library
or a phase or an interface name (of course, there are
exceptions). Theoretically these environment variables are also declared
as properties, but this is generally forgotten by programmers. A debug
level of 0 is equivalent to no tracing. The amount of tracing increases
with the debug level. The maximum useful value is 9.

Properties are listed below on a source library basis. The outline is
close the outline for pipsmake-rc\cite{}.  Properties used in more than
one library are presented
first. Section~\ref{section-pips-infrastructure} contains information
about infrastructure, external and user interface libraries. Analyses
are grouped in Section~\ref{section-analyses}. Program transformations,
parallelization and distribution phases are listed in the next
section. User output produced by different kinds of prettyprinters are
presented in
Section~\ref{section-prettyprinters}. Section~\ref{section-feautrier} is
dedicated to libraries added by CEA to implement Feautrier's method.

Virtually every PIPS programmer contributed some lines in this
report. Inconsistencies are likely. Please report them to the PIPS team!

\section{Global Options}

Are DO loops bodies executed at least once (F-66 style), or not (Fortran~77)?
This is useful for use/def and semantics analysis (not used for regions).

\begin{verbatim}
ONE_TRIP_DO FALSE
\end{verbatim}

It is possible to display the amount of real, cpu and system times
directly spent in each phase as well as the times spent reading/writing data
structures from/to PIPS database. The default value of this property is
\verb+FALSE+. The computation of total time used to complete a
\verb+pipsmake+ request is broken down into global times, a set of phase times
which is the accumulation of the times spent in each phase, and a set of
IO times, also accumulated thru phases. 

Note that the IO times are included in the phase times.

\begin{verbatim}
LOG_TIMINGS FALSE
\end{verbatim}

It is possible to log the amount of memory used by each phase and by
each request. This is mainly useful to check if a computation can be
performed on a given machine. This memory log can also be used to track memory
leaks.

\begin{verbatim}
LOG_MEMORY_USAGE FALSE
\end{verbatim}

\section{PIPS Infrastructure}
\label{section-pips-infrastructure}

\subsection{Newgen}

Newgen offers some debugging support to check object consistency
(\verb+gen_consistent_p+ and \verb+gen_defined_p+), and for dynamic type
checking. See Newgen documentation\cite{JT89}\cite{JT90}.

\subsection{C3 Linear Library}

This library is external and offers an independent debugging system.

\subsection{Pipsmake}

Shall we log and report differences between resource read/write and
which are not declared to pipsmake

\begin{verbatim}
CHECK_RESOURCE_USAGE FALSE
\end{verbatim}

The rule activation process may delete from the database all the
derived resources from the newly activated rule

\begin{verbatim}
ACTIVATE_DEL_DERIVED_RES TRUE
\end{verbatim}

\subsection{Pipsbdm}

Shell environment variables \verb+PIPSDBM_DEBUG_LEVEL+ can be set to ?
to check object consistency when they are stored in the database, and to
? to check object consistency when they are stored or retrieved (in case
an intermediate phase has corrupted some data structure unwillingly).

\subsection{Top level control}

Print a log of the session

\begin{verbatim}
USER_LOG_P      TRUE
\end{verbatim}

What to do on user errors: go ahead (default) or core dump (debug)

\begin{verbatim}
ABORT_ON_USER_ERROR     FALSE
\end{verbatim}

\subsection{Tpips command line interface}

Shall we execute the instructions of just check the syntax

\begin{verbatim}
TPIPS_NO_EXECUTION_MODE      FALSE
\end{verbatim}

\section{Analyses}
\label{section-analyses}

\subsection{Parser}

\subsection{Chains}

Update dependency graph with RR dependency arcs.
Useful for estimation of cache memory traffic. use/def related.

\begin{verbatim}
KEEP_READ_READ_DEPENDENCE FALSE
\end{verbatim}

Do we want to mask effects in loop bodies (dangerous with current
version of Allen \& Kennedy which assumes that all the edges are
present, the ones on private variables being eventually discarded
but with a current distribution)

\begin{verbatim}
CHAINS_MASK_EFFECTS FALSE
\end{verbatim}

Do we only keep dataflow (Def -- Use) dependences in the chain graph.

\begin{verbatim}
CHAINS_DATAFLOW_DEPENDENCE_ONLY FALSE
\end{verbatim}

\subsection{Effects}

print SDFI just after computation

\begin{verbatim}
EFFECTS_PRINT_SDFI TRUE
\end{verbatim}


\subsection{Dependence Test (Ricedg)}

% Module code and list of called module names.

\subsubsection{Dependence Test Selection}

This property seems to be now obsolete. The dependence test choice is
now controlled directly and only by rules in pipsmake.rc. The procedures
called by these rules may use this property. Anyway, it is useless to
set it manually.

\begin{verbatim}
DEPENDENCE_TEST "full"
\end{verbatim}

\subsubsection{Statistics}

Provide the following counts during the dependence test. There are three
parts: numbers of dependencies and independences (fields 1-10),
dimensions of referenced arrays and dependence natures (fields 11-25)
and the same information for constant dependencies (fields 26-40),
decomposition of the dependence test in elementary steps (fields 41-49),
use and complexity of Fourier-Motzkin's pair-wise elimination (fields
50, 51 and 52-68).

\begin{itemize}

  \item[1] array reference pairs, i.e. number of tests effected
    (used to be the number of use-def, def-use and def-def pairs on arrays);

  \item[2] number of independences found (on array reference pairs);

    {\bf Note:} field 1 minus field 2 is the number of array
    dependencies. 

  \item[3] numbers of loop independent dependences between references
    in the  same statement (not useful for program transformation
    and parallelization if statements are preserved); it should
    be subtracted from field 2 to compare results with other
    parallelizers;

  \item[4] numbers of constant dependences; 

  \item[5] numbers of exact dependences;

    {\bf Note:} field 5 must be greater or equal to field 4.

  \item[6] numbers of inexact dependences involved only by the 
           elimination of equation;
  \item[7] numbers of inexact dependences involved only by the F-M
           elimination;
  \item[8] numbers of inexact dependences involved by both elimination of
           equation and F-M elimination; 

    {\bf Note:} the sum of fields 5 to 8 and field 2 equals field 1

  \item[9] number of dependences among scalar variables;
  \item[10] numbers of dependences among loop index variables;
  \item[11-40] dependence types detail table with the dimensions [5][3]
               and constant dependence detail table with the
               dimensions [5][3]; the first index is the array dimension
    (from 0 to 4 - no larger arrays has ever been found); the
    second index is the dependence nature (1: d-u, 2: u-d, 3: d-d);
    both arrays are flatten according to C rule  as 5 sequences of
    3 natures;

    {\bf Note:} the sum of fields 11 to 25 should be equal to
    the sum of field 9 and 2 minus field 1.

    {\bf Note:} the fields 26 to 40 must be less than or equal to
    the corresponding fields 11 to 25

  \item[41] numbers of independences found by the test of constant;
  \item[42] numbers of independences found by the GCD test;
  \item[43] numbers of independences found by the normalize test;
  \item[44] numbers of independences found by the lexico-positive test
             for constant Di variables;
  \item[45] numbers of independences found during the projetion on Di
            variables by the elimination of equation;
  \item[46] numbers of independences found during the projetion on Di
            variables by the Fourier-Motzkin's elimination;
  \item[47] numbers of independences found during the test of
            faisability of  Di sub-system by the elimination of equation;
  \item[48] numbers of independences found during the test of
            faisability of Di sous-system by the Fourier-Motzkin's
            elimination; 
  \item[49] numbers of independences found by the test of lexico-positive
            for Di sub-system; 

    {\bf Note:} the sum of fields 41 to 49 equals field 2

  \item[50] total number of Fourier-Motzkin's pair-wise eliminations
     used; 
  \item[51] number of Fourier-Motzkin's pair-wise elimination 
    in which the system size doesn't augment after the elimination;
  \item[52-68] complexity counter table of dimension [17]. The
               complexity of one projection by F-M is the product of the
               number of positive inequalities and the number of negatives
               inequalities that contain the eliminated variable. This
    is an histogram of the products. Products which are less than 
    or equal to 4
    imply that the total number of inequalities does not increase.
    So if no larger product exists, field 50 and 51 must be equal.
\end{itemize}

The results are stored in the currentworkspace in MODULE.resulttestfast,
MODULE.resultesttestfull, or MODULE.resulttestseman according to the
test selected.

\begin{verbatim}
RICEDG_PROVIDE_STATISTICS FALSE
\end{verbatim}

Provide the statistics above and counte all array reference pairs
including these involved in call statement.

\begin{verbatim}
RICEDG_STATISTICS_ALL_ARRAYS FALSE
\end{verbatim}

\subsubsection{Algorithmic Dependences}

Only take into account true flow dependences (Def -- Use) during the
computation of SCC?  Note that this is different from the
CHAINS\_DATAFLOW\_DEPENDENCE\_ONLY option which doesn't compute the
whole graph.  Warning: this option potentially yields incorrect parallel
code.

\begin{verbatim}
RICE_DATAFLOW_DEPENDENCE_ONLY FALSE
\end{verbatim}

\subsubsection{Printout}

To print the dependence graph in a file called {\em module\_name}.{\tt dg}

\begin{verbatim}
PRINT_DEPENDENCE_GRAPH FALSE
\end{verbatim}

To print the dependence graph without the dependences on privatized
variables 

\begin{verbatim}
PRINT_DEPENDENCE_GRAPH_WITHOUT_PRIVATIZED_DEPS FALSE
\end{verbatim}

To print the dependence graph without the non-loop-carried dependences:
 
\begin{verbatim}
PRINT_DEPENDENCE_GRAPH_WITHOUT_NOLOOPCARRIED_DEPS FALSE
\end{verbatim}

Top print the dependence graph with the dependence cones:

\begin{verbatim}
PRINT_DEPENDENCE_GRAPH_WITH_DEPENDENCE_CONES FALSE
\end{verbatim}

\subsubsection{Optimization}

The default option is to compute the dependence graph only for loops
which can be parallelized using Allen \& Kennedy algorithm.
However it is possible to
compute the dependences in any case even for loop containing test, goto,
etc...
by setting this option to TRUE.

\begin{verbatim}
COMPUTE_ALL_DEPENDENCES FALSE
\end{verbatim}

\subsection{Flinter}

No property for this library.

\subsection{Semantic Analysis}
\label{subsection-semantic-analysis}

Perform ``meet'' operations for semantics analysis.

\begin{verbatim}
SEMANTICS_FLOW_SENSITIVE FALSE
\end{verbatim}

To be refined later; basically, use callee\'s transformers instead of
callee\'s effects when computing transformers bottom-up in the call graph;
when going top-down with preconditions, should we care about unique
call site and/or perform meet operation on call site preconditions ?

\begin{verbatim}
SEMANTICS_INTERPROCEDURAL FALSE
\end{verbatim}

Go all the Halbwachs way, compute inequalities instead of sticking
to equalities; implies SEMANTICS\_FIX\_POINT and SEMANTICS\_FLOW\_SENSITIVE.

\begin{verbatim}
SEMANTICS_INEQUALITY_INVARIANT FALSE
\end{verbatim}

CPU time and memory space are cheap: compute loop fixpoint for
transformers and preconditions; this implies SEMANTICS\_FLOW\_SENSITIVE.

\begin{verbatim}
SEMANTICS_FIX_POINT FALSE
\end{verbatim}

Output semantics results on stdout

\begin{verbatim}
SEMANTICS_STDOUT FALSE
\end{verbatim}

Debug level for semantics

\begin{verbatim}
SEMANTICS_DEBUG_LEVEL 0
\end{verbatim}

\subsection{Static Complexity Evaluation}

The following properties control the static estimation of dynamic code
execution time.

\subsubsection{Debugging}

Trace the walk across a module's internal representation:

\begin{verbatim}
COMPLEXITY_TRACE_CALLS FALSE
\end{verbatim}

Trace all intermediate complexities:

\begin{verbatim}
COMPLEXITY_INTERMEDIATES FALSE
\end{verbatim}

Print the complete cost table at the beginning of the execution:

\begin{verbatim}
COMPLEXITY_PRINT_COST_TABLE FALSE
\end{verbatim}

The cost table(s) contain machine and compiler dependent information
about basic execution times, e.g. time for a load or a store.

\subsubsection{Fine Tuning}

It is possible to specify a list of variables which must remain
litterally in the complexity formula, although their numerical values
are known (this is OK) or although they have multiple unkown and
unrelated values during any execution (this leads to an incorrect
result).

Formal parameters and imported global variables are left unevaluated.

They have relatively high priority (FI: I do not understand this comment
by Lei).

This list should be empty by default (but is not for unknown historical
reasons):

\begin{verbatim}
COMPLEXITY_PARAMETERS "IMAX LOOP"
\end{verbatim}

Controls the printing of {\em accuracy} statistics:

\begin{itemize}

  \item 0: do not prettyprint any statistics with complexities (to give
the user a false sense of accuracy and/or to avoid clutering his/her
display); this is the default value;

  \item 1: prettyprint statistics only for loop/block/test/unstr.
statements and not for basic statements, since they should not cause
accuracy problems;

  \item 2 : prettyprint statistics for all statements

\end{itemize}

\begin{verbatim}
COMPLEXITY_PRINT_STATISTICS 0
\end{verbatim}

\subsubsection{Target Machine and Compiler Selection}

This property is used to select a set of basic execution times. These
times depend on the target machine, the compiler and the compilation
options used. It is shown in \cite{Z94} that fixed basic times can be
used to obtain accurate execution times, if enough basic times are
considered, and if the target machine has a simple RISC processor. For
instance, it is not possible to use only one time for a register
load. It is necessary to take into account the nature of the variable,
i.e. formal parameter, dynamic variable, global variable, and the nature
of the access, e.g. the dimension of an accessed array. The cache can be
ignored an replacer by an average hit ratio.

Different set of elementary cost tables are available:

\begin{itemize}

  \item \verb+all_1+: each basic operation cost is 1;

  \item \verb+fp_1+: only floating point operations are taken into
account and have cost unit 1; all other operations have a null cost.

\end{itemize}

In the future, we might add a sparc-2 table...

The different elementary table names are defined in
\verb+complexity-local.h+. They presently are \verb+operation+, 
\verb+memory+, \verb+index+, \verb+transcend+
and \verb+trigo+.

The different tables required are to be found in
\verb+$PIPS_LIBDIR/complexity/xyz+,
%% $
where \verb+xyz+ is specified by this property:

\begin{verbatim}
COMPLEXITY_COST_TABLE "all_1"
\end{verbatim}

\subsubsection{Evaluation Strategy}

For the moment, we have designed two ways to solve the complexity
combination problem. Since symbolic complexity formulae use program
variables it is necessary to specify in which store they are
evaluated. If two complexity formulae are computed relatively to two
different stores, they cannot be directly added.

The first approach, which is implemented, uses the module initial store
as universal store for all formulae (but possibly for the complexity of
elementary statements).  In some way, symbolic variable are evaluated as
early as possible as soon as it is known that they won't make it in the
module summary complexity.

This first method is easy to implement when the preconditions are available
but it has at least two drawbacks:

\begin{itemize}

  \item if a variable is used in different places with the same unknown
value, each occurence will be replaced by a different unknown value
symbol (the infamous \verb+UU_xx+ symbols in formulae).

  \item since variables are replaced by numerical values as soon as
possible as early as possible, the user is shown a numerical execution
time instead of a symbolic formulae which would likely be more useful
(see property \verb+COMPLEXITY_PARAMETERS+). This is especially true
with interprocedural constant propagation.

\end{itemize}

The second approach, which is not implemented, delay variable evaluation
as late as possible. Complexities are computed and given relatively to
the stores used by each statements. Two elementary complexities are combined
together using the earliest store. The two stores are related by a {\em
transformer} (see Section~\ref{subsection-semantic-analysis}). Such an
approach is used to compute {\tt MUST} regions as precisely as possible
(see Section~\ref{subsection-regions}).

A simplified version of the late evaluation was implemented. The initial
store of the procedure is the only reference store used as with the
early evaluation, but variables are not evaluated right away. They only
are evaluated when it is necessary to do so. This not an ideal solution,
but it is easy to implement and reduces considerably the number of
unknown values which have to be put in the formulae to have correct
results.


\begin{verbatim}
COMPLEXITY_EARLY_EVALUATION FALSE
\end{verbatim}

\subsection{Regions}
\label{subsection-regions}

if {\tt MUST\_REGIONS} is true, then it computes regions using the
algorithm described in report E/181/CRI, called {\em $T^{-1}$
algorithm}. It provides more accurate regions, and preserve MUST
approximations more often. But it is less efficient. Its default value
is FALSE. EXACT\_REGIONS is true for the moment for backward
compatibility only.

\begin{verbatim}
EXACT_REGIONS TRUE
\end{verbatim}

\begin{verbatim}
MUST_REGIONS FALSE
\end{verbatim}

The default option is to compute regions without taking into account array
bounds. Both options have their advantages and drawbacks. 

\begin{verbatim}
REGIONS_WITH_ARRAY_BOUNDS FALSE
\end{verbatim}

I intend to compute disjunctions of regions. As I have already prepared basic
operators for that purpose, I created two properties to switch between regions
and disjuctions of regions. For the moment, they are always false.

\begin{verbatim}
DISJUNCT_REGIONS FALSE
\end{verbatim}

\begin{verbatim}
DISJUNCT_IN_OUT_REGIONS FALSE
\end{verbatim}


\begin{verbatim}
REGIONS_OP_STATISTICS FALSE
\end{verbatim}

\section{Transformations, Parallelization, Distribution}
\label{section-transformations}


\subsection{Parallelization}

\subsubsection{Rice (Parallelization)}

TRUE to show all parallel loops, FALSE to generate real (vector,
innermost parallel?) code

\begin{verbatim}
GENERATE_NESTED_PARALLEL_LOOPS TRUE
\end{verbatim}

\subsection{Code Distribution}

\subsubsection{wp65 (PUMA project)}

\begin{verbatim}
WP65_DEBUG_LEVEL        0
\end{verbatim}

\subsubsection{HPFC {\em High Performance Fortran Compiler}}

debugging levels considered by HPFC: 
\verb+HPFC_{,DIRECTIVES,IO,REMAPPING}_DEBUG_LEVEL+.

  These booleans decide whether some computations are directly
generated in the output code, or computed thru calls to dedicated
runtime functions. The default is the direct expansion.

\begin{verbatim}
HPFC_EXPAND_COMPUTE_LOCAL_INDEX TRUE
HPFC_EXPAND_COMPUTE_COMPUTER TRUE
HPFC_EXPAND_COMPUTE_OWNER TRUE
HPFC_EXPAND_CMPLID TRUE
HPFC_NO_WARNING FALSE
NO_USER_WARNING FALSE
WARNING_ON_STAT_ERROR TRUE
\end{verbatim}

   Hacks control\ldots

\begin{verbatim}
HPFC_FILTER_CALLEES FALSE
GLOBAL_EFFECTS_TRANSLATION TRUE
\end{verbatim}

  These booleans control the I/O generation.

\begin{verbatim}
HPFC_SYNCHRONIZE_IO FALSE
HPFC_IGNORE_MAY_IN_IO FALSE
\end{verbatim}

  Whether to use lazy or non-lazy communications

\begin{verbatim}
HPFC_LAZY_MESSAGES TRUE
\end{verbatim}

Whether to ignore FCD (Fabien Coelho Directives\ldots) or not. These
directives are used to instrument the code for testing purposes.

\begin{verbatim}
HPFC_IGNORE_FCD_SYNCHRO FALSE
HPFC_IGNORE_FCD_TIME FALSE
HPFC_IGNORE_FCD_SET FALSE
\end{verbatim}

Whether to measure and display the compilation times for remappings,
and whether to generate outward redundant code for remappings. Also
whether to generate code that keeps track dynamically of live mappings. 

\begin{verbatim}
HPFC_TIME_REMAPPINGS TRUE
HPFC_REDUNDANT_SYSTEMS_FOR_REMAPS FALSE
HPFC_DYNAMIC_LIVENESS TRUE
\end{verbatim}

Whether to use the local buffer management. 1 MB of buffer is allocated.

\begin{verbatim}
HPFC_BUFFER_SIZE 1000000
HPFC_USE_BUFFERS TRUE
\end{verbatim}


\subsection{Program Transformations}


\subsubsection{Partial Atomizer}

This transformation only atomizes indirect references of array access
functions.

\begin{verbatim}
ATOMIZE_INDIRECT_REF_ONLY FALSE
\end{verbatim}

\subsubsection{Loop Distribution}

Partial distribution distributes the statements of a loop nest except
 the isolated statements,that have no dependences at the common level l,
 are gathered in the same l-th loop.

\begin{verbatim}
PARTIAL_DISTRIBUTION FALSE
\end{verbatim}

\section{Prettyprinter Options}
\label{section-prettyprinters}

\subsection{Code Prettyprinter}

\subsubsection{Layout}

When prettyprinting semantic information (preconditions, transformers and
regions) adds a line before and after each piece of information if set to
\verb+TRUE+. The resulting code is more readable, but is larger.  

\begin{verbatim}
PRETTYPRINT_LOOSE TRUE 
\end{verbatim}

\subsubsection{Target Language Selection}

Added for homogeneity reason; could be (easily) reduced to one?  In
fact, with many target machines in mind, we should have an integer flag
``architecture'', with two basic architectures, sequential and parallel.
Useless values: re-initialized in the C code.

\begin{verbatim}
PRETTYPRINT_PARALLEL FALSE

PRETTYPRINT_SEQUENTIAL TRUE
\end{verbatim}

Print parallel DO loops using FORTRAN 90 syntax. Useless value:
re-initialized in the C code.

\begin{verbatim}
PRETTYPRINT_FORTRAN90 FALSE
\end{verbatim}

Adds Cray (FMP + CFT77) compatible directives for parallelization.
Useless value: re-initialized in the C code.

\begin{verbatim}
PRETTYPRINT_CRAY FALSE
\end{verbatim}

Adds Connection Machine Fortran prettyprint.

\begin{verbatim}
PRETTYPRINT_CMFORTRAN FALSE
\end{verbatim}

Adds Cray-T3D CRAFT Fortran prettyprint.

\begin{verbatim}
PRETTYPRINT_CRAFT FALSE
\end{verbatim}

\subsubsection{Display Analysis Results}

Add statement effects as comments in output; not implemented (that way) yet.

\begin{verbatim}
PRETTYPRINT_EFFECTS FALSE
\end{verbatim}

Add statement IO-effects as comments in output; They are simulated by
a read/write action to the array TOP-LEVEL:LUNS()

\begin{verbatim}
PRETTYPRINT_IO_EFFECTS TRUE
\end{verbatim}

Transform DOALL loops into sequential loops with an opposed increment
not implemented

\begin{verbatim}
PRETTYPRINT_REVERSE_DOALL FALSE
\end{verbatim}

Print statement transformers as comments in code.

\begin{verbatim}
PRETTYPRINT_TRANSFORMER FALSE
\end{verbatim}

Print statement preconditions as comments in code.

\begin{verbatim}
PRETTYPRINT_EXECUTION_CONTEXT FALSE
\end{verbatim}

Print statement regions as comments in code.

\begin{verbatim}
PRETTYPRINT_REGION FALSE
\end{verbatim}

Print regions of scalars.

\begin{verbatim}
PRETTYPRINT_SCALAR_REGIONS FALSE
\end{verbatim}

\subsubsection{Display Iternals for Debugging}

All these debugging options should be set to FALSE for normal operation.

Print block statement.

\begin{verbatim}
PRETTYPRINT_BLOCKS FALSE
\end{verbatim}

Print unstructured statements.

\begin{verbatim}
PRETTYPRINT_UNSTRUCTURED FALSE
\end{verbatim}

Print all effects for all statements regardless of \verb+PRETTYPRINT_BLOCKS+
and \verb+PRETTYPRINT_UNSTRUCTURED+.

\begin{verbatim}
PRETTYPRINT_ALL_EFFECTS FALSE
\end{verbatim}

Print empty statement blocks (false by default):

\begin{verbatim}
PRETTYPRINT_EMPTY_BLOCKS FALSE
\end{verbatim}

Print statement ordering information (false by default):

\begin{verbatim}
PRETTYPRINT_STATEMENT_ORDERING FALSE
\end{verbatim}

Print code with DO label and CONTINUE instead of DO-ENDDO. If FALSE, all
useless CONTINUE statements are NOT prettyprinted (ie. all those in
structured parts of the code). Warning: case TRUE, generated code may be
wrong after some code transformations like distribution...

\begin{verbatim}
PRETTYPRINT_ALL_LABELS FALSE
\end{verbatim}

Print code with DO label as comment.

\begin{verbatim}
PRETTYPRINT_DO_LABEL_AS_COMMENT FALSE
\end{verbatim}

Print private variables without regard for their effective use. By
default, private variables are shown only for parallel DO loops.

\begin{verbatim}
PRETTYPRINT_ALL_PRIVATE_VARIABLES FALSE
\end{verbatim}


Regenerate all variable declarations, including those variables not
declared in the user program. By default, when possible, the user
declaration {\em text} is used to preserve comments.

\begin{verbatim}
PRETTYPRINT_ALL_DECLARATIONS FALSE
\end{verbatim}

Whether to regenerate the commons in the declarations or not.

\begin{verbatim}
PRETTYPRINT_COMMONS TRUE
\end{verbatim}

Manage internal RETURNs correctly if set to TRUE.  This results in a
slightly ugly (but correct) prettyprint, compared to a nicer (but
possibly incorrect) default one. Internal returns are converted by the
parser into GO~TO's the final and unique return.

\begin{verbatim}
PRETTYPRINT_INTERNAL_RETURN TRUE
\end{verbatim}

Print the final RETURN statement, although this is useless according to
Fortran standard. Note that comments attached to the final return are
lost if it is not printed. Note also that the final RETURN may be part
of an unstructured in which case the previous property is required.

\begin{verbatim}
PRETTYPRINT_FINAL_RETURN FALSE
\end{verbatim}

\subsubsection{FORESYS Interface}

Print transformers, preconditions and regions in a format acceptd by
Foresys and Partita.

\begin{verbatim}
PRETTYPRINT_FOR_FORESYS FALSE
\end{verbatim}

\subsubsection{HPFC Prettyprinter}

To deal specifically with the prettyprint for hpfc

\begin{verbatim}
PRETTYPRINT_HPFC FALSE
\end{verbatim}

\subsubsection{Interface to Graphics Prettyprinters}

To output a code with a hierarchical view of the control graph with
markers instead of a flat one. It purposes a display with a graph
browser such as daVinci:

\begin{verbatim}
PRETTYPRINT_UNSTRUCTURED_AS_A_GRAPH FALSE
\end{verbatim}

and to have a decorated output with the hexadecimal adresses of the
control nodes:
\begin{verbatim}
PRETTYPRINT_UNSTRUCTURED_AS_A_GRAPH_VERBOSE FALSE
\end{verbatim}

\subsection{Call Graph}

This library is used to display the calling relationship between
modules.  It is different from the interprocedural call flow graph
(ICFG). For  example: if A calls B twice, in
callgraph, there is only one edge between A and B; while in ICFG (see
next section)), there are two edges between A and B, since A contains
two call sites.  

The call graph is derived from the modules declarations.

There is no option for the callgraph prettyprinter except
for debugging.

Debugging level (should be \verb+CALLGRAPH_DEBUG_LEVEL+ and numeric!)

\begin{verbatim}
CALLGRAPH_DEBUG FALSE
\end{verbatim}

\subsection{Interprocedural Control Flow Graph}

This prettyprinter is NOT a call graph prettyprinter. Control flow
information can be displayed and every call site is shown, possibly with
some annotation like precondition or region

This prettyprinter uses the module codes in the workspace database to
build the ICFG.

Print IF statements controlling call sites:

\begin{verbatim}
ICFG_IFs FALSE
\end{verbatim}

Print DO loops enclosing call sites:

\begin{verbatim}
ICFG_DOs FALSE
\end{verbatim}

To be destroyed:

\begin{verbatim}
ICFG_CALLEES_TOPO_SORT FALSE
\end{verbatim}

\begin{verbatim}
ICFG_DECOR 0
\end{verbatim}

\begin{verbatim}
ICFG_DRAW TRUE
\end{verbatim}

Debugging level (should be \verb+ICFG_DEBUG_LEVEL+ and numeric instead
of boolean!):

\begin{verbatim}
ICFG_DEBUG FALSE
\end{verbatim}

\section{Feautrier's Method}

No properties apparently.

\section*{Conclusion}

Do not be surprised by strange results obtained after selecting a
property yourself!

\begin{thebibliography}{99}

\bibitem{JT89} P. Jouvelot, R. Triolet, 
{\em NewGen: A Language-Independent Program Generator},
July 12, 1989, 
<a href="newgen-paper/newgen-paper.html">Tech. Report A/191.</a>

\bibitem{JT90} P. Jouvelot, R. Triolet, 
{\em NewGen User Manual}. December
1990, <a href="newgen-manual/newgen-manual.html">Tech. Report A/???.</a>

\bibitem{Z94} Lei Zhou,
{\em Analyse statique et dynamique de la compl\'exite' des programmes
scientifiques}, 
Th\`ese de doctorat de l'universit\'e Pierre et Marie Curie, 14
septembre 1994. Technical Report A/255.

\end{thebibliography}

\end{document}
