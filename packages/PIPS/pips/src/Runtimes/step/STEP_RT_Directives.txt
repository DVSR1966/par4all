Runtime de STEP / directives de STEP



Ajouter des codes d'erreur aux appel à la runtime ?


1) Routine d'environnement

STEP_Init()
	initialtisation de la runtime (nombre de noeud dispo, nombre de core sur le(s) noeud(s) ?)
	effectue le MPI_INIT()
	
STEP_Finalize()
	finalisation de la runtime
	effectue le MPI_FINALIZE()

STEP_GetSize(size)
	retourne la taille de la team courante (au niveau MPI)

STEP_GetRank(rank)
	retourne le rank dans la team courante (au niveau MPI)

STEP_GetNumThreads(nb_thread)
	retourne le nombre de thread dans la team courante (au niveau OMP)

STEP_GetThreadNum(id_thread)
	retourne le rank du thread dans la team courant (au niveau OMP)

STEP_GetParallelLevel(lvl, type)
	retourne le niveau actuelle, et si MPI, OMP ou HYBRIDE

STEP_GetNumWorkchunks(nb_workchunk)
	retourne le nombre de workchunk du Worksaring courrant

STEP_GetWorkchunkNum(workchunk)
	retourne l'identifiant du workchunk courrant

STEP_GetLoopBounds(workchunk,from,to)
	retourne dans from et to les bornes min et max d'un workchung du Worksaring de boucle courrant



2) Routine de Worksharing

STEP_Parallel(type)
	création d'une nouvelle team de type MPI, OMP, ou HYBRIDE

STEP_Loop(from, to, incr, chunk_size)
	décompose l'espace d'ittération d'une boucle et stocke cette décomposition au niveau de la runtime

STEP_Section()
	?

STEP_Single()
	?

STEP_Schedule()
	détermine la règle d'assotiation workchunk <-> (noeud,thread)




3) Partage des données

STEP_ShareArray(type, array, dim, bounds, disjoint)
	déclaration du partage d'un tableau
	type : STEP_INTEGER4, STEP_COMPLEXE, ...
	array : adresse du tableau
	dim : nombre de dimention du tableau
	bounds : tableau decrivant l'espace d'indice possible
	disjoint : booleen indiquant si il y a entrelacement des sous-régions

	bounds(borne, dimension, 0) :
		borne = STEP_LOW | STEP_UP
		1<=dimension<=dim
		indique la borne inférieur ou supérieur des indices du tableau array pour la dimension dimension

	bounds(borne, dimension, workchunk) :
		indique la borne inférieur ou supérieur des indices d'une région du tableau array pour la dimension dimension

STEP_ShareScalar(type, scalar)
	déclaration du partage d'un scalair de type STEP_INTEGER4 | STEP_COMPLEXE | ...

STEP_Distribute(type, array, dim, bounds, ?)
	déclare qu'un tableau est distribué entre plusieurs noeuds

STEP_Reduction(data, operator)
 	déclare une réduction pour la donnée data (qui doit être préalablemant déclarée share par STEP_ShareArray ou STEP_ShareScalar)
	operator : STEP_ADD | STEP_MULT | ...

	effectue les initialisations au niveau de la runtime pour pouvoir gérer la réduction au niveau du worksharing courrant

STEP_Private(data)
	?



4) Communications

STEP_AllToAll(array, workchunk, algo)
	array doit avoir été préalableamnt déclaré comme partagé
	pour le worksharing courrant et fonction du schedule choisi, il est possible de déterminer pour si le noeud courrant doit faire une émission ou une réception de la sous-région de array associé à workchunk (la sous-région a été déterminé par le tableau bounds lors de l'appel à STEP_ShareArray)

STEP_OneToAll(data, algo)
	data doit être un scalair ou un tableau préalablement déclaré comme partagé

STEP_Reduct(data)
	effectue la réduction de data qui a préalablement été déclaré comme faisant l'objet d'une réduction




5) Synchronisation

boolean STEP_Master()
	retourne vrai si thread maitre du worksharing courrant


STEP_Barrier()
	synchronisation des membre de la team du worksharing courant


STEP_Flush(data1, ..., STEP_NULL)
	assure la fin des communications MPI pour les données dataX préalablement déclaré comme partagées au niveau du worksharing courrant
	STEP_Flush(STEP_NULL) assure le flush de toutes les données déclaré partagé au niveau du worksharing courant

STEP_Wait(data, acces)
	acces : R | W | RW
	data doit être un scalair ou un tableau préalablement déclaré comme partagé
	permettre de retarder les synchronisations juste avant l'acces en lecture ou en écriture de la donnée data dasn le worksharing courrant

STEP_Critical_begin(name)
	?

STEP_Critical_end(name)
	?



6) Directives

6.1) Worksharing

parallel

do [/ end do]
parallel do [/ end parallel do]

sections / end sections
parallel sections / end parallel sections
section

single / end single


6.2) Synchronisation

master / end master

flush

barrier

critical



7) Clauses

7.1) Directive parallel

private

reduction

7.2) Directive do

private, reduction (cf 7.1)

nowait

chunk_size

7.3) Directive sections




8) Idées

- recouvrement calculs/communications pour les boucles
- retarder les synchronisations des communications juste avant les accès en lecture ou écriture
- en cas d'entrelassement, factoriser le "diff" au niveau de chaque noeud et communique les couples (case, valeur)
- en cas d'entrelassement, i lest aussi possible de faire les communications par workchunk et de faire du recouvrement calcul/communication
- Decider au runtime du modèle d'éxecution individuellement pour chaque boucle (fonction du la profondeur dans le CFG le niveau d'imbrication des boucles et des bornes de boucles)

/****************************************************************************/
Modifications sur le code de la runtime step
* a mettre dans step.h (int  fstep_size_; int  step_rank_;)
* step_private.h et step.h public
* pas de symboles partagés lib/code (step_rt_nom_variable interne) accés par des fonctions *
* steprt_rank, steprt_size --> step_private.c
* steprt.h (lib) + step.h (utilisateur) (les deux inclus a partir du code fortran)
* steprt.c + steprt_(alltoall, stepdiff...etc).c 
* steprt.h C et steprt_f.h fortran
* stepalltoall : generation des decrpteur de regions C compatibles
* variable globale dans steprt_private.c qui indique le language appelant (et compiler avec l'option adéquate )
* variable globale steprt_lang indiquant le language
* expliciter les nom des arguments de fonctions
* stepalltoaal argument size -> step_comm_size array-> data_array tag -> comm_tag max_nb_request-> max_nb_requests
* stepalltoall.c ALG1 ALG2 ALG3
* region_desc[i]->> region_mpidesc[i]
* dans stepalltoall -> 0 devient COMM_TAG
 
